# Ensemble ve Early Fusion Stratejileri

Bu dokÃ¼mantasyon, greedy selection sonuÃ§larÄ±yla early fusion ve ensemble yapma stratejilerini aÃ§Ä±klar.

## ğŸ“Š Mevcut Durum

### 1. **Greedy Selection SonuÃ§larÄ±**
- **Konum**: `results/ablation/selected_features_all.json`
- **Format**: `{model_task: {model, task, classifier, selected_features, n_features}}`
- **Ã–rnek**: `{"bert_clarity": {"model": "bert", "task": "clarity", "selected_features": [...]}}`

### 2. **Top-K Feature Selection**
- **Konum**: `results/ablation/selected_features_for_early_fusion.json`
- **Format**: Task bazÄ±nda top-10 feature listesi
- **KullanÄ±m**: TÃ¼m modeller iÃ§in aynÄ± top-K feature'lar

### 3. **Final Evaluation SonuÃ§larÄ±**
- **Format**: `{model: {task: {classifier: {predictions, probabilities, metrics}}}}`
- **Metric**: `macro_f1` (imbalanced class iÃ§in ideal)

---

## ğŸ¯ Ã–nerilen Stratejiler

### **Strateji 1: Greedy-Based Early Fusion (Model-Specific)**

Her model iÃ§in greedy ile seÃ§ilmiÅŸ feature'larÄ± kullanarak early fusion yapÄ±n.

```python
from src.models.ensemble import create_greedy_fused_features
from src.storage.manager import StorageManager

# 1. Greedy-selected features'Ä± yÃ¼kle (otomatik)
X_train_fused, feature_names = create_greedy_fused_features(
    storage=storage,
    models=['bert', 'roberta', 'deberta', 'xlnet'],
    task='clarity',
    split='train',
    auto_load_greedy=True  # Otomatik olarak greedy features yÃ¼kler
)

# 2. Classifier'larÄ± eÄŸit
from src.models.classifiers import train_classifiers
results = train_classifiers(
    X_train_fused, y_train,
    X_dev_fused, y_dev,
    classifiers=classifiers
)
```

**Avantajlar:**
- âœ… Her model iÃ§in en iyi feature'larÄ± kullanÄ±r
- âœ… Model-specific optimizasyon
- âœ… Daha az feature = daha hÄ±zlÄ± training

**Dezavantajlar:**
- âš ï¸ Her model iÃ§in farklÄ± feature set'i (karÅŸÄ±laÅŸtÄ±rma zor)

---

### **Strateji 2: Top-K Model Selection + Top-K Features**

En iyi K model'i seÃ§, her birinde top-K feature kullan.

```python
from src.models.ensemble import (
    select_top_models_by_f1,
    create_topk_fused_features
)

# 1. Final evaluation sonuÃ§larÄ±ndan top-10 model seÃ§
top_models = select_top_models_by_f1(
    results=final_results,  # run_final_evaluation'dan gelen sonuÃ§lar
    task='clarity',
    top_k=10,
    metric='macro_f1'
)

# 2. Top-10 model'ler iÃ§in top-10 feature'larla early fusion
X_train_fused, feature_names = create_topk_fused_features(
    storage=storage,
    top_models=top_models,
    task='clarity',
    top_k_features=10,  # Her model iÃ§in top-10 feature
    split='train'
)
```

**Avantajlar:**
- âœ… En iyi performans gÃ¶steren modelleri kullanÄ±r
- âœ… TutarlÄ± feature set (tÃ¼m modeller iÃ§in aynÄ± top-K)
- âœ… Top-5 ve Top-10 varyasyonlarÄ± kolay

---

### **Strateji 3: Late Fusion (Ensemble) - Ã–nerilen**

Birden fazla modelin prediction'larÄ±nÄ± birleÅŸtirin.

```python
from src.models.ensemble import ensemble_from_results

# 1. Top-10 model'lerden ensemble oluÅŸtur
ensemble_result = ensemble_from_results(
    results=final_results,
    task='clarity',
    top_k=10,  # Top-10 model
    ensemble_method='weighted_mean',  # F1 score'a gÃ¶re aÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ
    metric='macro_f1'
)

# 2. Ensemble predictions ve probabilities
y_ensemble_pred = ensemble_result['predictions']
y_ensemble_proba = ensemble_result['probabilities']

# 3. Evaluate
from src.evaluation.metrics import compute_all_metrics
metrics = compute_all_metrics(
    y_true, y_ensemble_pred, label_list,
    task_name="ENSEMBLE_TOP10"
)
```

**Ensemble MetodlarÄ±:**
- `'hard_voting'`: Majority vote (sadece predictions)
- `'mean'`: Probability'leri ortalama
- `'weighted_mean'`: F1 score'a gÃ¶re aÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ ortalama â­ **Ã–nerilen**
- `'max'`: Max pooling

**Avantajlar:**
- âœ… En basit ve etkili yÃ¶ntem
- âœ… Model diversity'den faydalanÄ±r
- âœ… Imbalanced class iÃ§in weighted_mean ideal

---

### **Strateji 4: Hybrid (Early Fusion + Ensemble)**

Hem early fusion hem de ensemble kullanÄ±n.

```python
# 1. Greedy-based early fusion ile birkaÃ§ model grubu oluÅŸtur
# Grup 1: Top-5 model, top-5 features
top5_models = select_top_models_by_f1(results, task='clarity', top_k=5)
X_fused_top5 = create_topk_fused_features(storage, top5_models, task='clarity', top_k_features=5)

# Grup 2: Top-10 model, top-10 features
top10_models = select_top_models_by_f1(results, task='clarity', top_k=10)
X_fused_top10 = create_topk_fused_features(storage, top10_models, task='clarity', top_k_features=10)

# 2. Her grup iÃ§in classifier eÄŸit
results_top5 = train_classifiers(X_fused_top5, y_train, X_fused_top5_dev, y_dev)
results_top10 = train_classifiers(X_fused_top10, y_train, X_fused_top10_dev, y_dev)

# 3. GruplarÄ± ensemble et
ensemble_predictions = ensemble_predictions_voting([
    results_top5['best_classifier']['dev_pred'],
    results_top10['best_classifier']['dev_pred']
])
```

---

## ğŸ”¬ Hangi Modelleri KullanmalÄ±?

### **Paper'daki Modeller:**
- âœ… **BERT** (bert-base-uncased)
- âœ… **RoBERTa** (roberta-base)
- âœ… **DeBERTa** (microsoft/deberta-base)
- âœ… **XLNet** (xlnet-base-cased)

### **Ek Modeller (Paper'da Yok):**
- âœ… **BERT-Political**: Political domain'e fine-tune edilmiÅŸ
- âœ… **BERT-Ambiguity**: Ambiguity detection iÃ§in fine-tune edilmiÅŸ

### **Ã–neri:**
1. **Temel Ensemble**: Paper'daki 4 model (BERT, RoBERTa, DeBERTa, XLNet)
2. **Extended Ensemble**: + BERT-Political, BERT-Ambiguity (6 model)
3. **Selective Ensemble**: Top-5 veya Top-10 by macro F1

---

## ğŸ“ˆ Imbalanced Class iÃ§in Ã–neriler

### **1. Macro F1 KullanÄ±n**
```python
# DoÄŸru metric
metric = 'macro_f1'  # Her class'a eÅŸit aÄŸÄ±rlÄ±k

# YanlÄ±ÅŸ metric
metric = 'weighted_f1'  # Class frequency'ye gÃ¶re aÄŸÄ±rlÄ±k (majority class'Ä± Ã¶nceliklendirir)
```

### **2. Weighted Ensemble**
```python
# F1 score'a gÃ¶re aÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ ensemble
ensemble_method = 'weighted_mean'  # YÃ¼ksek F1'li modeller daha fazla aÄŸÄ±rlÄ±k alÄ±r
```

### **3. Class-Balanced Sampling (Opsiyonel)**
EÄŸer training sÄ±rasÄ±nda kullanmak isterseniz:
```python
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler

# SMOTE + Under-sampling kombinasyonu
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)
```

---

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### **En Basit Ensemble (Ã–nerilen):**
```python
# 1. Final evaluation Ã§alÄ±ÅŸtÄ±r
results = run_final_evaluation(
    storage=storage,
    models=['bert', 'roberta', 'deberta', 'xlnet', 'bert_political', 'bert_ambiguity'],
    tasks=['clarity', 'evasion'],
    ...
)

# 2. Top-10 ensemble
from src.models.ensemble import ensemble_from_results

for task in ['clarity', 'evasion']:
    ensemble = ensemble_from_results(
        results=results,
        task=task,
        top_k=10,
        ensemble_method='weighted_mean'
    )
    
    # 3. Evaluate
    metrics = compute_all_metrics(
        y_test, ensemble['predictions'], label_list,
        task_name=f"ENSEMBLE_TOP10_{task}"
    )
    
    print(f"{task} - Ensemble Macro F1: {metrics['macro_f1']:.4f}")
```

---

## ğŸ“ Ä°hsan ve Ece'nin Reposu

**Not**: Ä°hsan ve Ece'nin reposu bu workspace'te bulunamadÄ±. Ancak genel Ã¶neriler:

### **Paper'daki YaklaÅŸÄ±mlar:**
1. **Evasion-based Clarity**: Ä°ki aÅŸamalÄ± classification (evasion â†’ clarity mapping)
2. **Hierarchical Taxonomy**: Fine-grained labels kullanarak high-level prediction
3. **LoRA Fine-tuning**: Llama-70b gibi LLM'ler iÃ§in

### **Sizin YaklaÅŸÄ±mÄ±nÄ±z:**
- âœ… Context Tree features (paper'da yok) - **YENÄ°LÄ°K**
- âœ… Greedy feature selection (paper'da yok) - **YENÄ°LÄ°K**
- âœ… Multiple transformer models ensemble (paper'da var ama farklÄ±)

### **Ã–neri:**
Paper'daki modelleri kullanÄ±n ama **sizin feature extraction ve selection metodunuzla**:
- Paper: LLM-based (Llama, Falcon, ChatGPT)
- Siz: Transformer features + Context Tree + Greedy Selection â­

Bu kombinasyon **hem paper'daki yaklaÅŸÄ±mdan farklÄ± hem de potansiyel olarak daha iyi** olabilir.

---

## ğŸ¯ SonuÃ§ ve Ã–neriler

### **En Ä°yi Strateji (Imbalanced Class iÃ§in):**
1. âœ… **Late Fusion (Ensemble)** - `weighted_mean` method
2. âœ… **Top-10 models** by macro F1
3. âœ… **Macro F1** metric kullan

### **Alternatif Strateji:**
1. âœ… **Greedy-based Early Fusion** - Model-specific features
2. âœ… **Top-5 models** - Daha az model, daha hÄ±zlÄ±

### **Kod Ã–rnekleri:**
TÃ¼m kod Ã¶rnekleri `src/models/ensemble.py` modÃ¼lÃ¼nde mevcut.

