{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Split: Train / Dev / Test\n",
        "\n",
        "================================================================================\n",
        "PURPOSE: Split HuggingFace train split into Train/Dev, keep test split separate\n",
        "================================================================================\n",
        "\n",
        "This notebook loads the QEvasion dataset from HuggingFace, which already has\n",
        "train and test splits. The HuggingFace test split is kept untouched and will\n",
        "ONLY be used in final evaluation. Only the HuggingFace train split is divided:\n",
        "\n",
        "- **Train**: 80% of HuggingFace train split (used for training models)\n",
        "- **Dev**: 20% of HuggingFace train split (used for model/feature selection)\n",
        "- **Test**: HuggingFace test split (ONLY used in final evaluation notebook)\n",
        "\n",
        "**CRITICAL**: The HuggingFace test split is NEVER used for training, model\n",
        "selection, or any development decisions. It is only accessed in the final\n",
        "evaluation notebook (05_final_evaluation.ipynb).\n",
        "\n",
        "================================================================================\n",
        "INPUTS (What this notebook loads)\n",
        "================================================================================\n",
        "\n",
        "**From GitHub:**\n",
        "- Repository code (cloned automatically if not present)\n",
        "- Source modules from `src/` directory\n",
        "\n",
        "**From HuggingFace Hub:**\n",
        "- QEvasion dataset (`ailsntua/QEvasion`)\n",
        "  - Train split (approximately 3400 samples)\n",
        "  - Test split (308 samples, kept untouched)\n",
        "\n",
        "**From Google Drive:**\n",
        "- Nothing (this is the first notebook in the pipeline)\n",
        "\n",
        "================================================================================\n",
        "OUTPUTS (What this notebook saves)\n",
        "================================================================================\n",
        "\n",
        "**To Google Drive:**\n",
        "- Dataset splits: `splits/dataset_splits.pkl`\n",
        "  - Train split (80% of HuggingFace train split)\n",
        "  - Dev split (20% of HuggingFace train split)\n",
        "  - Test split (HuggingFace test split, untouched)\n",
        "\n",
        "**To GitHub:**\n",
        "- Split metadata: `metadata/splits.json`\n",
        "  - Train/Dev/Test sizes\n",
        "  - Timestamp and data paths\n",
        "\n",
        "**What gets passed to next notebook:**\n",
        "- Train, Dev, and Test splits saved to persistent storage\n",
        "- These splits are loaded by subsequent notebooks via `storage.load_split()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SETUP: Repository Clone, Drive Mount, and Path Configuration\n",
        "# ============================================================================\n",
        "# This cell performs minimal setup required for the notebook to run:\n",
        "# 1. Clones repository from GitHub (if not already present)\n",
        "# 2. Mounts Google Drive for persistent data storage\n",
        "# 3. Configures Python paths and initializes StorageManager\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "import requests\n",
        "import zipfile\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "# Repository configuration\n",
        "repo_dir = '/content/semeval-context-tree-modular'\n",
        "repo_url = 'https://github.com/EonTechie/semeval-context-tree-modular.git'\n",
        "zip_url = 'https://github.com/EonTechie/semeval-context-tree-modular/archive/refs/heads/main.zip'\n",
        "\n",
        "# Clone repository (if not already present)\n",
        "if not os.path.exists(repo_dir):\n",
        "    print(\"Cloning repository from GitHub...\")\n",
        "    max_retries = 2\n",
        "    clone_success = False\n",
        "    \n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            result = subprocess.run(\n",
        "                ['git', 'clone', repo_url],\n",
        "                cwd='/content',\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=60\n",
        "            )\n",
        "            if result.returncode == 0:\n",
        "                print(\"Repository cloned successfully via git\")\n",
        "                clone_success = True\n",
        "                break\n",
        "            else:\n",
        "                if attempt < max_retries - 1:\n",
        "                    time.sleep(3)\n",
        "        except Exception as e:\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(3)\n",
        "    \n",
        "    # Fallback: Download as ZIP if git clone fails\n",
        "    if not clone_success:\n",
        "        print(\"Git clone failed. Downloading repository as ZIP archive...\")\n",
        "        zip_path = '/tmp/repo.zip'\n",
        "        try:\n",
        "            response = requests.get(zip_url, stream=True, timeout=60)\n",
        "            response.raise_for_status()\n",
        "            with open(zip_path, 'wb') as f:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall('/content')\n",
        "            extracted_dir = '/content/semeval-context-tree-modular-main'\n",
        "            if os.path.exists(extracted_dir):\n",
        "                os.rename(extracted_dir, repo_dir)\n",
        "            os.remove(zip_path)\n",
        "            print(\"Repository downloaded and extracted successfully\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Failed to obtain repository: {e}\")\n",
        "\n",
        "# Mount Google Drive (if not already mounted)\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "except Exception:\n",
        "    pass  # Already mounted\n",
        "\n",
        "# Configure paths\n",
        "BASE_PATH = Path('/content/semeval-context-tree-modular')\n",
        "DATA_PATH = Path('/content/drive/MyDrive/semeval_data')\n",
        "\n",
        "# Verify repository structure exists\n",
        "if not BASE_PATH.exists():\n",
        "    raise RuntimeError(f\"Repository directory not found: {BASE_PATH}\")\n",
        "if not (BASE_PATH / 'src').exists():\n",
        "    raise RuntimeError(f\"src directory not found in repository: {BASE_PATH / 'src'}\")\n",
        "if not (BASE_PATH / 'src' / 'storage' / 'manager.py').exists():\n",
        "    raise RuntimeError(f\"Required file not found: {BASE_PATH / 'src' / 'storage' / 'manager.py'}\")\n",
        "\n",
        "# Add repository to Python path\n",
        "sys.path.insert(0, str(BASE_PATH))\n",
        "\n",
        "# Verify import works\n",
        "try:\n",
        "    from src.storage.manager import StorageManager\n",
        "except ImportError as e:\n",
        "    raise ImportError(\n",
        "        f\"Failed to import StorageManager. \"\n",
        "        f\"Repository path: {BASE_PATH}, \"\n",
        "        f\"Python path: {sys.path[:3]}, \"\n",
        "        f\"Error: {e}\"\n",
        "    )\n",
        "\n",
        "# Initialize StorageManager\n",
        "storage = StorageManager(\n",
        "    base_path=str(BASE_PATH),\n",
        "    data_path=str(DATA_PATH),\n",
        "    github_path=str(BASE_PATH)\n",
        ")\n",
        "\n",
        "print(\"Setup complete\")\n",
        "print(f\"  Repository: {BASE_PATH}\")\n",
        "print(f\"  Data storage: {DATA_PATH}\")\n",
        "print(f\"  Repository verified: src/ directory exists\")\n",
        "print(f\"  Python path configured: {BASE_PATH} added to sys.path\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# LOAD DATASET FROM HUGGINGFACE HUB\n",
        "# ============================================================================\n",
        "# Loads the QEvasion dataset from HuggingFace Hub\n",
        "# The dataset already has train and test splits - we keep test untouched\n",
        "\n",
        "from src.data.loader import load_dataset\n",
        "\n",
        "dataset = load_dataset(dataset_name=\"ailsntua/QEvasion\")\n",
        "train_raw = dataset['train']\n",
        "test_raw = dataset['test']  # HuggingFace test split - kept untouched\n",
        "\n",
        "print(f\"Dataset loaded:\")\n",
        "print(f\"  Train split: {len(train_raw)} samples\")\n",
        "print(f\"  Test split: {len(test_raw)} samples (will be used ONLY in final evaluation)\")\n",
        "print(f\"  Features: {list(train_raw.features.keys())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SPLIT TRAIN INTO TRAIN / DEV (80-20)\n",
        "# ============================================================================\n",
        "# Splits HuggingFace train split into Train (80%) and Dev (20%)\n",
        "# HuggingFace test split is kept untouched and will be used as final test\n",
        "\n",
        "from src.data.splitter import split_train_into_train_dev\n",
        "\n",
        "train_ds, dev_ds = split_train_into_train_dev(\n",
        "    train_dataset=train_raw,\n",
        "    dev_ratio=0.20,   # 20% of train data becomes dev (train/dev split: 80-20)\n",
        "    seed=42           # Fixed seed for reproducibility\n",
        ")\n",
        "\n",
        "# HuggingFace test split is kept as-is (no modification)\n",
        "test_ds = test_raw\n",
        "\n",
        "print(\"\\nFinal splits:\")\n",
        "print(f\"  Train: {len(train_ds)} samples ({len(train_ds)/len(train_raw)*100:.1f}% of train split)\")\n",
        "print(f\"  Dev: {len(dev_ds)} samples ({len(dev_ds)/len(train_raw)*100:.1f}% of train split)\")\n",
        "print(f\"  Test: {len(test_ds)} samples (HuggingFace test split - untouched)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SAVE SPLITS TO PERSISTENT STORAGE\n",
        "# ============================================================================\n",
        "# Saves the three splits to Google Drive for use in subsequent notebooks\n",
        "# Splits are saved in a format that preserves all dataset features and metadata\n",
        "\n",
        "storage.save_splits(train_ds, dev_ds, test_ds)\n",
        "\n",
        "print(\"Splits saved to persistent storage\")\n",
        "print(f\"  Train: {len(train_ds)} samples\")\n",
        "print(f\"  Dev: {len(dev_ds)} samples\")\n",
        "print(f\"  Test: {len(test_ds)} samples (HuggingFace test split)\")\n",
        "print(\"\\nIMPORTANT: Test set (HuggingFace test split) will ONLY be used in\")\n",
        "print(\"           final evaluation notebook (05_final_evaluation.ipynb).\")\n",
        "print(\"           Do not use it for training or development!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
