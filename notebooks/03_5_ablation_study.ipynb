{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFcGLZkaAsQ1"
      },
      "source": [
        "<div style=\"font-size: 10px;\">\n",
        "\n",
        "# Ablation Study: Feature Selection and Ranking\n",
        "\n",
        "================================================================================\n",
        "PURPOSE: Comprehensive feature ablation study to identify optimal feature subsets\n",
        "================================================================================\n",
        "\n",
        "This notebook performs comprehensive ablation studies on Context Tree features\n",
        "to identify the most important features for each model and task combination.\n",
        "The goal is to maximize Macro F1-score by selecting optimal feature subsets.\n",
        "\n",
        "**Scope:**\n",
        "- **3 Tasks**: Clarity, Evasion, and Hierarchical Evasion → Clarity\n",
        "- **6 Models**: bert, bert_political, bert_ambiguity, roberta, deberta, xlnet\n",
        "- **6 Classifiers**: LogisticRegression, LinearSVC, RandomForest, XGBoost, LightGBM, MLP\n",
        "- **Total Combinations**: 6 models × 6 classifiers = 36 combinations per task\n",
        "\n",
        "**Workflow:**\n",
        "1. Load features and labels from persistent storage (saved by 03_train_evaluate.ipynb)\n",
        "2. Single-Feature Ablation: Evaluate each feature individually across all 36 model×classifier combinations\n",
        "3. Statistical Aggregation: Calculate min, median, std, best (max), and runs (count) for each feature\n",
        "4. Weighted Score Calculation: Compute weighted score combining multiple statistics\n",
        "5. Feature Ranking: Rank features by weighted score (separately for each task)\n",
        "6. Top-K Feature Selection: Identify top-performing features for greedy selection\n",
        "7. Greedy Forward Selection: Iteratively add best features to maximize Macro F1\n",
        "\n",
        "**Statistical Metrics Computed:**\n",
        "- **min_f1**: Minimum Macro F1 across all 36 combinations (worst-case performance)\n",
        "- **median_f1**: Median Macro F1 across all 36 combinations (typical performance)\n",
        "- **mean_f1**: Mean Macro F1 across all 36 combinations (average performance)\n",
        "- **std_f1**: Standard deviation of Macro F1 across all 36 combinations (consistency measure)\n",
        "- **best_f1**: Maximum Macro F1 across all 36 combinations (best-case performance)\n",
        "- **runs**: Number of evaluations (should be 36 for complete data)\n",
        "\n",
        "**Weighted Score Formula:**\n",
        "The weighted score combines multiple statistics to balance average performance, consistency, and peak performance:\n",
        "```\n",
        "weighted_score = 0.5*mean_f1 + 0.3*best_f1 + 0.2*(1 - normalized_std)\n",
        "```\n",
        "where normalized_std = std_f1 / (mean_f1 + epsilon) to account for scale differences.\n",
        "\n",
        "Features are ranked by weighted_score in descending order.\n",
        "\n",
        "================================================================================\n",
        "INPUTS (What this notebook loads)\n",
        "================================================================================\n",
        "\n",
        "**From Google Drive:**\n",
        "- Feature matrices: `features/raw/X_{split}_{model}_{task}.npy`\n",
        "  - For each model (6 models)\n",
        "  - For each task (clarity, evasion)\n",
        "  - For Train and Dev splits\n",
        "- Predictions: `predictions/pred_dev_{model}_{classifier}_hierarchical_evasion_to_clarity.npy`\n",
        "  - For hierarchical task evaluation\n",
        "- Dataset splits: `splits/dataset_splits_{task}.pkl`\n",
        "  - For label extraction\n",
        "\n",
        "**From GitHub:**\n",
        "- Feature metadata: `metadata/features_{split}_{model}_{task}.json`\n",
        "  - Contains feature names (19 features)\n",
        "\n",
        "================================================================================\n",
        "OUTPUTS (What this notebook saves)\n",
        "================================================================================\n",
        "\n",
        "**To Google Drive:**\n",
        "- Ablation results: `results/ablation/single_feature_{task}.csv`\n",
        "- Feature rankings: `results/ablation/feature_ranking_{task}.csv`\n",
        "  - Includes all statistics: min, median, mean, std, best, runs, weighted_score\n",
        "- Selected features: `results/ablation/selected_features_{task}.json`\n",
        "- Greedy trajectories: `results/ablation/greedy_trajectory_{model}_{task}.csv`\n",
        "\n",
        "**To GitHub:**\n",
        "- Ablation metadata: `results/ablation_metadata_{task}.json`\n",
        "\n",
        "**What gets passed to next notebook:**\n",
        "- Feature rankings for each task (clarity, evasion, hierarchical)\n",
        "- Selected feature sets for greedy selection\n",
        "- Comprehensive statistical analysis of feature importance\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taM9AUx6AsQ5"
      },
      "source": [
        "<div style=\"font-size: 10px;\">\n",
        "\n",
        "# ============================================================================\n",
        "# SETUP: Repository Clone, Drive Mount, and Path Configuration\n",
        "# ============================================================================\n",
        "#\n",
        "# This cell performs the initial setup required for the notebook to run:\n",
        "# 1. Clones the repository from GitHub (if not already present)\n",
        "# 2. Mounts Google Drive for persistent data storage\n",
        "# 3. Configures Python paths and initializes StorageManager\n",
        "# 4. Creates necessary directories for ablation results\n",
        "#\n",
        "# The StorageManager handles loading features, predictions, and dataset splits\n",
        "# from Google Drive, and saving results back to Drive and GitHub.\n",
        "#\n",
        "# No modifications are needed in this cell unless you change repository URLs\n",
        "# or data storage paths.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxySQrihAsQ5",
        "outputId": "5cd5c140-4230-4f94-c9e2-fdf24d847818"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Setup complete\n",
            "  Repository: /content/semeval-context-tree-modular\n",
            "  Data storage: /content/drive/MyDrive/semeval_data\n",
            "  Ablation results: /content/drive/MyDrive/semeval_data/results/ablation\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# SETUP: Repository Clone, Drive Mount, and Path Configuration\n",
        "# ============================================================================\n",
        "import shutil\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "import requests\n",
        "import zipfile\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Repository configuration\n",
        "repo_dir = '/content/semeval-context-tree-modular'\n",
        "repo_url = 'https://github.com/EonTechie/semeval-context-tree-modular.git'\n",
        "zip_url = 'https://github.com/EonTechie/semeval-context-tree-modular/archive/refs/heads/main.zip'\n",
        "\n",
        "# Clone repository (if not already present)\n",
        "if not os.path.exists(repo_dir):\n",
        "    print(\"Cloning repository from GitHub...\")\n",
        "    max_retries = 2\n",
        "    clone_success = False\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            result = subprocess.run(\n",
        "                ['git', 'clone', repo_url],\n",
        "                cwd='/content',\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=60\n",
        "            )\n",
        "            if result.returncode == 0:\n",
        "                print(\"Repository cloned successfully via git\")\n",
        "                clone_success = True\n",
        "                break\n",
        "            else:\n",
        "                if attempt < max_retries - 1:\n",
        "                    time.sleep(3)\n",
        "        except Exception as e:\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(3)\n",
        "\n",
        "    # Fallback: Download as ZIP if git clone fails\n",
        "    if not clone_success:\n",
        "        print(\"Git clone failed. Downloading repository as ZIP archive...\")\n",
        "        zip_path = '/tmp/repo.zip'\n",
        "        try:\n",
        "            response = requests.get(zip_url, stream=True, timeout=60)\n",
        "            response.raise_for_status()\n",
        "            with open(zip_path, 'wb') as f:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall('/content')\n",
        "            extracted_dir = '/content/semeval-context-tree-modular-main'\n",
        "            if os.path.exists(extracted_dir):\n",
        "                os.rename(extracted_dir, repo_dir)\n",
        "            os.remove(zip_path)\n",
        "            print(\"Repository downloaded and extracted successfully\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Failed to obtain repository: {e}\")\n",
        "\n",
        "# Mount Google Drive (if not already mounted)\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "except Exception:\n",
        "    pass  # Already mounted\n",
        "\n",
        "# Configure paths\n",
        "BASE_PATH = Path('/content/semeval-context-tree-modular')\n",
        "DATA_PATH = Path('/content/drive/MyDrive/semeval_data')\n",
        "\n",
        "# Verify repository structure exists\n",
        "if not BASE_PATH.exists():\n",
        "    raise RuntimeError(f\"Repository directory not found: {BASE_PATH}\")\n",
        "if not (BASE_PATH / 'src').exists():\n",
        "    raise RuntimeError(f\"src directory not found in repository: {BASE_PATH / 'src'}\")\n",
        "if not (BASE_PATH / 'src' / 'storage' / 'manager.py').exists():\n",
        "    raise RuntimeError(f\"Required file not found: {BASE_PATH / 'src' / 'storage' / 'manager.py'}\")\n",
        "\n",
        "# Add repository to Python path\n",
        "sys.path.insert(0, str(BASE_PATH))\n",
        "\n",
        "# Verify imports work\n",
        "try:\n",
        "    from src.storage.manager import StorageManager\n",
        "    from src.models.classifiers import get_classifier_dict\n",
        "    from src.features.extraction import get_feature_names\n",
        "    from sklearn.metrics import f1_score\n",
        "    from sklearn.pipeline import Pipeline\n",
        "    from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "    from sklearn.base import clone\n",
        "except ImportError as e:\n",
        "    raise ImportError(\n",
        "        f\"Failed to import required modules. \"\n",
        "        f\"Repository path: {BASE_PATH}, \"\n",
        "        f\"Python path: {sys.path[:3]}, \"\n",
        "        f\"Error: {e}\"\n",
        "    )\n",
        "\n",
        "# Initialize StorageManager\n",
        "storage = StorageManager(\n",
        "    base_path=str(BASE_PATH),\n",
        "    data_path=str(DATA_PATH),\n",
        "    github_path=str(BASE_PATH)\n",
        ")\n",
        "\n",
        "# Create ablation results directory\n",
        "ablation_dir = DATA_PATH / 'results' / 'ablation'\n",
        "ablation_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Setup complete\")\n",
        "print(f\"  Repository: {BASE_PATH}\")\n",
        "print(f\"  Data storage: {DATA_PATH}\")\n",
        "print(f\"  Ablation results: {ablation_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dykB1ODQAsQ6",
        "outputId": "02b668ec-d516-466b-b0fd-9612df3f0c3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "CONFIGURATION\n",
            "================================================================================\n",
            "  Models: 6 models\n",
            "    ['bert', 'bert_political', 'bert_ambiguity', 'roberta', 'deberta', 'xlnet']\n",
            "  Tasks: 3 tasks\n",
            "    ['clarity', 'evasion', 'hierarchical_evasion_to_clarity']\n",
            "  Classifiers: 6 classifiers\n",
            "    ['LogisticRegression', 'LinearSVC', 'RandomForest', 'MLP', 'XGBoost', 'LightGBM']\n",
            "  Total combinations per task: 6 × 6 = 36\n",
            "  Evaluation set: Dev set (not test)\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CONFIGURE MODELS, TASKS, AND CLASSIFIERS\n",
        "# ============================================================================\n",
        "# This cell defines the models, tasks, and classifiers to be used in the ablation study.\n",
        "# All combinations (6 models × 6 classifiers = 36) will be evaluated for each task.\n",
        "# Three tasks are included: Clarity, Evasion, and Hierarchical Evasion → Clarity.\n",
        "\n",
        "# Check if get_classifier_dict is imported (from Cell 1 - Setup)\n",
        "if 'get_classifier_dict' not in globals():\n",
        "    raise NameError(\n",
        "        \"get_classifier_dict not found. Please run Cell 1 (Setup) first.\\n\"\n",
        "        \"Cell 1 imports get_classifier_dict from src.models.classifiers.\"\n",
        "    )\n",
        "\n",
        "MODELS = ['bert', 'bert_political', 'bert_ambiguity', 'roberta', 'deberta', 'xlnet']\n",
        "TASKS = ['clarity', 'evasion', 'hierarchical_evasion_to_clarity']  # 3 tasks\n",
        "\n",
        "# Label mappings for each task\n",
        "CLARITY_LABELS = ['Ambivalent', 'Clear Non-Reply', 'Clear Reply']\n",
        "EVASION_LABELS = ['Claims ignorance', 'Clarification', 'Declining to answer',\n",
        "                  'Deflection', 'Dodging', 'Explicit',\n",
        "                  'General', 'Implicit', 'Partial/half-answer']\n",
        "\n",
        "# Initialize classifiers with fixed random seed for reproducibility\n",
        "# Includes MLP (Multi-Layer Perceptron) as requested\n",
        "classifiers = get_classifier_dict(random_state=42)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"CONFIGURATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"  Models: {len(MODELS)} models\")\n",
        "print(f\"    {MODELS}\")\n",
        "print(f\"  Tasks: {len(TASKS)} tasks\")\n",
        "print(f\"    {TASKS}\")\n",
        "print(f\"  Classifiers: {len(classifiers)} classifiers\")\n",
        "print(f\"    {list(classifiers.keys())}\")\n",
        "print(f\"  Total combinations per task: {len(MODELS)} × {len(classifiers)} = {len(MODELS) * len(classifiers)}\")\n",
        "print(f\"  Evaluation set: Dev set (not test)\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0ynXbYIAsQ7"
      },
      "outputs": [],
      "source": [
        "# ============================================================================# SINGLE-FEATURE ABLATION STUDY# ============================================================================# This cell performs single-feature ablation: evaluates each of the 19 Context Tree# features individually across all model×classifier combinations (36 combinations per task).# # For each feature, we train a classifier using only that feature and evaluate on the# dev set. This helps identify which features are most informative for each task.## Process:# 1. For each task (clarity, evasion, hierarchical_evasion_to_clarity)# 2. For each model (6 models)# 3. For each classifier (6 classifiers, including MLP)# 4. For each feature (19 features)# 5. Train classifier on single feature and evaluate Macro F1 on dev set## Total evaluations: 3 tasks × 6 models × 6 classifiers × 19 features = 2,052 evaluationsdef eval_single_feature(X_train, X_dev, y_train, y_dev, feature_idx, clf):    \"\"\"    Evaluate a single feature using a classifier.        This function trains a classifier using only one feature and evaluates its    performance on the dev set. StandardScaler is applied to normalize the    single feature before classification.        Args:        X_train: Training feature matrix (N, F) where F is total number of features        X_dev: Dev feature matrix (M, F)        y_train: Training labels (N,)        y_dev: Dev labels (M,)        feature_idx: Index of the feature to evaluate (0 to F-1)        clf: Classifier instance (will be cloned to avoid state issues)        Returns:        Macro F1 score on dev set (float)    \"\"\"    # Select only the specified feature (single column)    X_train_f = X_train[:, [feature_idx]]    X_dev_f = X_dev[:, [feature_idx]]        # Pipeline with scaling (critical for single features to work properly)    # StandardScaler normalizes the feature to have zero mean and unit variance    pipe = Pipeline([        (\"scaler\", StandardScaler()),        (\"clf\", clone(clf))  # Clone to avoid modifying the original classifier    ])        # Train on single feature and evaluate on dev set    pipe.fit(X_train_f, y_train)    pred = pipe.predict(X_dev_f)    macro_f1 = f1_score(y_dev, pred, average='macro')        return macro_f1# Check if required variables are defined (from Cell 2 - Configuration)if 'TASKS' not in globals() or 'MODELS' not in globals() or 'classifiers' not in globals():    raise NameError(        \"Required variables not defined. Please run Cell 2 (Configuration) first.\\n\"        \"Cell 2 defines: TASKS, MODELS, CLARITY_LABELS, EVASION_LABELS, and classifiers.\"    )# Check if storage is defined (from Cell 1 - Setup)if 'storage' not in globals():    raise NameError(        \"storage not found. Please run Cell 1 (Setup) first.\\n\"        \"Cell 1 initializes StorageManager as 'storage'.\"    )print(\"=\"*80)print(\"SINGLE-FEATURE ABLATION STUDY\")print(\"=\"*80)print(\"Evaluating each feature individually across all model×task×classifier combinations\")print(f\"Total evaluations: {len(TASKS)} tasks × {len(MODELS)} models × {len(classifiers)} classifiers × 19 features\")print(\"This may take 15-30 minutes depending on your hardware...\\n\")# Store all ablation results# Each entry contains: model, task, classifier, feature, feature_idx, macro_f1ablation_results = []for task in TASKS:    print(f\"\\n{'='*80}\")    print(f\"TASK: {task.upper()}\")    print(f\"{'='*80}\")        # Select appropriate label list and dataset key based on task    if task == 'clarity':        label_list = CLARITY_LABELS        label_key = 'clarity_label'        task_for_split = 'clarity'    elif task == 'evasion':        label_list = EVASION_LABELS        label_key = 'evasion_label'        task_for_split = 'evasion'    else:  # hierarchical_evasion_to_clarity        # For hierarchical task, we need to load evasion dev set to get clarity labels        # (hierarchical uses evasion predictions mapped to clarity labels)        label_list = CLARITY_LABELS        label_key = 'clarity_label'        # We'll load from evasion dev set (same filtered samples)        task_for_split = 'evasion'            # Load task-specific splits    # For hierarchical task, we load evasion split (which has clarity labels)    train_ds = storage.load_split('train', task=task_for_split)    dev_ds = storage.load_split('dev', task=task_for_split)        # Extract labels    y_train = np.array([train_ds[i][label_key] for i in range(len(train_ds))])    y_dev = np.array([dev_ds[i][label_key] for i in range(len(dev_ds))])        print(f\"  Train: {len(y_train)} samples\")    print(f\"  Dev: {len(y_dev)} samples\")        # Get feature names directly from extraction module (same for all models)    # This avoids dependency on metadata files in GitHub    # Feature names are the same across all models (19 Context Tree features)    feature_names = get_feature_names()    n_features = len(feature_names)        print(f\"  Features: {n_features} features\")    print(f\"  Feature names: {feature_names}\\n\")        # For hierarchical task, we need to use evasion features    # (hierarchical approach uses evasion predictions, so we evaluate on evasion features)    feature_task = 'evasion' if task == 'hierarchical_evasion_to_clarity' else task        # For each model    for model in MODELS:        print(f\"  Model: {model}\")                # Load features        # For hierarchical task, use evasion features (since we're evaluating        # how well evasion features predict clarity via hierarchical mapping)        try:            X_train = storage.load_features(model, feature_task, 'train')            X_dev = storage.load_features(model, feature_task, 'dev')        except FileNotFoundError:            print(f\"    ⚠ Features not found for {model} × {feature_task}, skipping...\")            continue                # Verify feature count matches        if X_train.shape[1] != n_features:            print(f\"    ⚠ Feature count mismatch: expected {n_features}, got {X_train.shape[1]}, skipping...\")            continue                # For each classifier        for clf_name, clf in classifiers.items():            print(f\"    Classifier: {clf_name}\")                        # Evaluate each feature individually            for feature_idx, feature_name in enumerate(feature_names):                try:                    macro_f1 = eval_single_feature(                        X_train, X_dev,                        y_train, y_dev,                        feature_idx, clf                    )                                        ablation_results.append({                        'model': model,                        'task': task,                        'classifier': clf_name,                        'feature': feature_name,                        'feature_idx': feature_idx,                        'macro_f1': float(macro_f1)                    })                except Exception as e:                    print(f\"      ⚠ Error evaluating feature {feature_name}: {e}\")                    continueprint(f\"\\n{'='*80}\")print(\"SINGLE-FEATURE ABLATION COMPLETE\")print(f\"{'='*80}\")print(f\"Total evaluations completed: {len(ablation_results)}\")print(f\"Expected: {len(TASKS)} tasks × {len(MODELS)} models × {len(classifiers)} classifiers × {n_features} features = {len(TASKS) * len(MODELS) * len(classifiers) * n_features}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfHOjnknAsQ7"
      },
      "source": [
        "<div style=\"font-size: 10px;\">\n",
        "\n",
        "# ============================================================================\n",
        "# SINGLE-FEATURE ABLATION STUDY\n",
        "# ============================================================================\n",
        "#\n",
        "# This section performs single-feature ablation: evaluates each of the 19 Context Tree\n",
        "# features individually across all model×classifier combinations.\n",
        "#\n",
        "# **What this cell does:**\n",
        "# - For each task (clarity, evasion, hierarchical_evasion_to_clarity)\n",
        "# - For each model (6 models)\n",
        "# - For each classifier (6 classifiers, including MLP)\n",
        "# - For each feature (19 features)\n",
        "# - Trains a classifier using only that single feature\n",
        "# - Evaluates Macro F1 on the dev set\n",
        "#\n",
        "# **Total evaluations:** 3 tasks × 6 models × 6 classifiers × 19 features = 2,052 evaluations\n",
        "#\n",
        "# **Expected runtime:** 15-30 minutes depending on hardware\n",
        "#\n",
        "# **Output:** List of ablation results with model, task, classifier, feature, and macro_f1\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e87290c65ab341028cc46efa061dd92e",
            "61cd2983714c4de19e23cf0ebccf3bf7",
            "43ef14ff1b7b4d39b52ffeef01c9011b",
            "8f16a3198e974ab2bfe791079dfd9b3b",
            "38528e129cbd45ce91cea03e6e5953bc",
            "dcbb1ee8eb6f4ce48180e7a997b6cc38",
            "555a88e30a5c4e9196095efe4c0b4ea0",
            "96064cb2673d4bf1bd9a0ff01ff63205",
            "84302eb33b7840f7bf8d20ad5c589ea5",
            "42a79d6f8882465fa9866b15eb9ce81e",
            "a336a14b773b4d95b9162e47df6f22e5",
            "38fe52bb09f94075ac9bfbbe45bb02da",
            "d193e338cc7545a6b202447c364988c3",
            "39e5dca4040742ac8a89b237d2303ced",
            "e30e385fed6e4c4db6fa8bda5707d5f5",
            "363b2c98af3444dfb6467de3598398d4",
            "3f635f3e0e6244aaa863a9646086b211",
            "6719a3c49bf943298038c62ce33a4f4d",
            "2c09e45fe43f43c2b4a8c794750ea7a2",
            "4d8e076c6bcc4a0d900e1cad531c40c7",
            "3a4e85d2bac243b9b57fb2fecfbcec1a",
            "70112c968462433d9e35ad5737687681",
            "73bba36cddd94a9e91afa76bd2b44970",
            "8466fbb6b29d4494aac001d28921d712",
            "1781ffaadfe7409eb86e5994ac53a050",
            "2623523db15e493cbc5409988c48cdb1",
            "37183fa1dc8b4043a66d9f2d8fd7516d",
            "bfc331f6108848e8b1acf8a51f58d055",
            "dad466652e174de2b33098b626ccf317",
            "b92edb0584e34267a7f7bd1231be0407",
            "7bba2d336b384b26a8e7b01389e888d1",
            "c0d4b42e91924177961a506255d3aef0",
            "b36ea57888f746dbad806a989627d337",
            "888169b663534d01987d3c09cd72a9b9",
            "e64f3172842544deadba8c61a536475a",
            "e09f13b47ee84c6eae1040ba99fd8a1a",
            "4be75f7853454c25a9214ebfa6137b4c",
            "fc711d7141644d868b3329c366d2f81f",
            "e48f0ffb0d204099a9c857376aaea2a1",
            "499dee00f2644f92bb6817af99746dac",
            "b253cbbdafca452bae08b726aa097657",
            "0a16f0ba0eb142d08195828d9637ac90",
            "f298e6707d4f495eb121e1c573140113",
            "7edc7ebb30714b05816a3703c9490280"
          ]
        },
        "id": "ngEkh_OeAsQ7",
        "outputId": "7c8773b5-fe08-4224-a15a-5cb4f85b15a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "SINGLE-FEATURE ABLATION STUDY\n",
            "================================================================================\n",
            "Evaluating each feature individually across all model×task×classifier combinations\n",
            "Total evaluations: 3 tasks × 6 models × 6 classifiers × 19 features\n",
            "This may take 15-30 minutes depending on your hardware...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "TASK: CLARITY\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e87290c65ab341028cc46efa061dd92e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "data/train-00000-of-00001.parquet:   0%|          | 0.00/3.90M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38fe52bb09f94075ac9bfbbe45bb02da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "data/test-00000-of-00001.parquet:   0%|          | 0.00/259k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73bba36cddd94a9e91afa76bd2b44970",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/3448 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "888169b663534d01987d3c09cd72a9b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/308 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train: 2758 samples\n",
            "  Dev: 690 samples\n",
            "  Features: 19 features\n",
            "  Feature names: ['question_model_token_count', 'answer_model_token_count', 'attention_mass_q_to_a_per_qtoken', 'attention_mass_a_to_q_per_atoken', 'focus_token_to_answer_strength', 'answer_token_to_focus_strength', 'focus_token_coverage_ratio', 'tfidf_cosine_similarity_q_a', 'content_word_jaccard_q_a', 'question_content_coverage_in_answer', 'answer_content_word_ratio', 'answer_digit_groups_per_word', 'refusal_pattern_match_count', 'clarification_pattern_match_count', 'answer_question_mark_count', 'answer_word_count', 'answer_is_short_question', 'answer_negation_ratio', 'answer_hedge_ratio']\n",
            "\n",
            "  Model: bert\n",
            "    Classifier: LogisticRegression\n",
            "    Classifier: LinearSVC\n",
            "    Classifier: RandomForest\n",
            "    Classifier: MLP\n",
            "    Classifier: XGBoost\n",
            "    Classifier: LightGBM\n",
            "  Model: bert_political\n",
            "    Classifier: LogisticRegression\n",
            "    Classifier: LinearSVC\n",
            "    Classifier: RandomForest\n",
            "    Classifier: MLP\n",
            "    Classifier: XGBoost\n",
            "    Classifier: LightGBM\n",
            "  Model: bert_ambiguity\n",
            "    Classifier: LogisticRegression\n",
            "    Classifier: LinearSVC\n",
            "    Classifier: RandomForest\n",
            "    Classifier: MLP\n",
            "    Classifier: XGBoost\n",
            "    Classifier: LightGBM\n",
            "  Model: roberta\n",
            "    Classifier: LogisticRegression\n",
            "    Classifier: LinearSVC\n",
            "    Classifier: RandomForest\n",
            "    Classifier: MLP\n",
            "    Classifier: XGBoost\n",
            "    Classifier: LightGBM\n",
            "  Model: deberta\n",
            "    Classifier: LogisticRegression\n",
            "    Classifier: LinearSVC\n",
            "    Classifier: RandomForest\n",
            "    Classifier: MLP\n",
            "    Classifier: XGBoost\n",
            "    Classifier: LightGBM\n",
            "  Model: xlnet\n",
            "    Classifier: LogisticRegression\n",
            "    Classifier: LinearSVC\n",
            "    Classifier: RandomForest\n",
            "    Classifier: MLP\n",
            "    Classifier: XGBoost\n",
            "    Classifier: LightGBM\n",
            "\n",
            "================================================================================\n",
            "TASK: EVASION\n",
            "================================================================================\n",
            "  Train: 2758 samples\n",
            "  Dev: 690 samples\n",
            "  Features: 19 features\n",
            "  Feature names: ['question_model_token_count', 'answer_model_token_count', 'attention_mass_q_to_a_per_qtoken', 'attention_mass_a_to_q_per_atoken', 'focus_token_to_answer_strength', 'answer_token_to_focus_strength', 'focus_token_coverage_ratio', 'tfidf_cosine_similarity_q_a', 'content_word_jaccard_q_a', 'question_content_coverage_in_answer', 'answer_content_word_ratio', 'answer_digit_groups_per_word', 'refusal_pattern_match_count', 'clarification_pattern_match_count', 'answer_question_mark_count', 'answer_word_count', 'answer_is_short_question', 'answer_negation_ratio', 'answer_hedge_ratio']\n",
            "\n",
            "  Model: bert\n",
            "    Classifier: LogisticRegression\n",
            "    Classifier: LinearSVC\n",
            "    Classifier: RandomForest\n",
            "    Classifier: MLP\n",
            "    Classifier: XGBoost\n",
            "    Classifier: LightGBM\n",
            "  Model: bert_political\n",
            "    Classifier: LogisticRegression\n",
            "    Classifier: LinearSVC\n",
            "    Classifier: RandomForest\n",
            "    Classifier: MLP\n",
            "    Classifier: XGBoost\n",
            "    Classifier: LightGBM\n",
            "  Model: bert_ambiguity\n",
            "    Classifier: LogisticRegression\n",
            "    Classifier: LinearSVC\n",
            "    Classifier: RandomForest\n",
            "    Classifier: MLP\n",
            "    Classifier: XGBoost\n",
            "    Classifier: LightGBM\n",
            "  Model: roberta\n",
            "    Classifier: LogisticRegression\n",
            "    Classifier: LinearSVC\n",
            "    Classifier: RandomForest\n",
            "    Classifier: MLP\n",
            "    Classifier: XGBoost\n",
            "    Classifier: LightGBM\n",
            "  Model: deberta\n",
            "    Classifier: LogisticRegression\n",
            "    Classifier: LinearSVC\n",
            "    Classifier: RandomForest\n",
            "    Classifier: MLP\n",
            "    Classifier: XGBoost\n",
            "    Classifier: LightGBM\n",
            "  Model: xlnet\n",
            "    Classifier: LogisticRegression\n",
            "    Classifier: LinearSVC\n",
            "    Classifier: RandomForest\n",
            "    Classifier: MLP\n",
            "    Classifier: XGBoost\n",
            "    Classifier: LightGBM\n",
            "\n",
            "================================================================================\n",
            "TASK: HIERARCHICAL_EVASION_TO_CLARITY\n",
            "================================================================================\n",
            "  Train: 2758 samples\n",
            "  Dev: 690 samples\n",
            "  Features: 19 features\n",
            "  Feature names: ['question_model_token_count', 'answer_model_token_count', 'attention_mass_q_to_a_per_qtoken', 'attention_mass_a_to_q_per_atoken', 'focus_token_to_answer_strength', 'answer_token_to_focus_strength', 'focus_token_coverage_ratio', 'tfidf_cosine_similarity_q_a', 'content_word_jaccard_q_a', 'question_content_coverage_in_answer', 'answer_content_word_ratio', 'answer_digit_groups_per_word', 'refusal_pattern_match_count', 'clarification_pattern_match_count', 'answer_question_mark_count', 'answer_word_count', 'answer_is_short_question', 'answer_negation_ratio', 'answer_hedge_ratio']\n",
            "\n",
            "  Model: bert\n",
            "    Classifier: LogisticRegression\n",
            "    Classifier: LinearSVC\n",
            "    Classifier: RandomForest\n",
            "    Classifier: MLP\n",
            "    Classifier: XGBoost\n",
            "    Classifier: LightGBM\n",
            "  Model: bert_political\n",
            "    Classifier: LogisticRegression\n",
            "    Classifier: LinearSVC\n",
            "    Classifier: RandomForest\n",
            "    Classifier: MLP\n",
            "    Classifier: XGBoost\n",
            "    Classifier: LightGBM\n",
            "  Model: bert_ambiguity\n",
            "    Classifier: LogisticRegression\n",
            "    Classifier: LinearSVC\n",
            "    Classifier: RandomForest\n",
            "    Classifier: MLP\n",
            "    Classifier: XGBoost\n",
            "    Classifier: LightGBM\n",
            "  Model: roberta\n",
            "    Classifier: LogisticRegression\n",
            "    Classifier: LinearSVC\n",
            "    Classifier: RandomForest\n",
            "    Classifier: MLP\n",
            "    Classifier: XGBoost\n",
            "    Classifier: LightGBM\n",
            "  Model: deberta\n",
            "    Classifier: LogisticRegression\n",
            "    Classifier: LinearSVC\n",
            "    Classifier: RandomForest\n",
            "    Classifier: MLP\n",
            "    Classifier: XGBoost\n",
            "    Classifier: LightGBM\n",
            "  Model: xlnet\n",
            "    Classifier: LogisticRegression\n",
            "    Classifier: LinearSVC\n",
            "    Classifier: RandomForest\n",
            "    Classifier: MLP\n",
            "    Classifier: XGBoost\n",
            "    Classifier: LightGBM\n",
            "\n",
            "================================================================================\n",
            "SINGLE-FEATURE ABLATION COMPLETE\n",
            "================================================================================\n",
            "Total evaluations completed: 2052\n",
            "Expected: 3 tasks × 6 models × 6 classifiers × 19 features = 2052\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# SINGLE-FEATURE ABLATION STUDY\n",
        "# ============================================================================\n",
        "# This cell performs single-feature ablation: evaluates each of the 19 Context Tree\n",
        "# features individually across all model×classifier combinations (36 combinations per task).\n",
        "#\n",
        "# For each feature, we train a classifier using only that feature and evaluate on the\n",
        "# dev set. This helps identify which features are most informative for each task.\n",
        "#\n",
        "# Process:\n",
        "# 1. For each task (clarity, evasion, hierarchical_evasion_to_clarity)\n",
        "# 2. For each model (6 models)\n",
        "# 3. For each classifier (6 classifiers, including MLP)\n",
        "# 4. For each feature (19 features)\n",
        "# 5. Train classifier on single feature and evaluate Macro F1 on dev set\n",
        "#\n",
        "# Total evaluations: 3 tasks × 6 models × 6 classifiers × 19 features = 2,052 evaluations\n",
        "\n",
        "def eval_single_feature(X_train, X_dev, y_train, y_dev, feature_idx, clf):\n",
        "    \"\"\"\n",
        "    Evaluate a single feature using a classifier.\n",
        "\n",
        "    This function trains a classifier using only one feature and evaluates its\n",
        "    performance on the dev set. StandardScaler is applied to normalize the\n",
        "    single feature before classification.\n",
        "\n",
        "    Args:\n",
        "        X_train: Training feature matrix (N, F) where F is total number of features\n",
        "        X_dev: Dev feature matrix (M, F)\n",
        "        y_train: Training labels (N,)\n",
        "        y_dev: Dev labels (M,)\n",
        "        feature_idx: Index of the feature to evaluate (0 to F-1)\n",
        "        clf: Classifier instance (will be cloned to avoid state issues)\n",
        "\n",
        "    Returns:\n",
        "        Macro F1 score on dev set (float)\n",
        "    \"\"\"\n",
        "    # Encode labels to numeric (required for MLP, XGBoost, LightGBM)\n",
        "    # This matches the approach in siparismaili01 notebook\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "    y_dev_encoded = label_encoder.transform(y_dev)\n",
        "\n",
        "    # Select only the specified feature (single column)\n",
        "    X_train_f = X_train[:, [feature_idx]]\n",
        "    X_dev_f = X_dev[:, [feature_idx]]\n",
        "\n",
        "    # Pipeline with scaling (critical for single features to work properly)\n",
        "    # StandardScaler normalizes the feature to have zero mean and unit variance\n",
        "    pipe = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"clf\", clone(clf))  # Clone to avoid modifying the original classifier\n",
        "    ])\n",
        "\n",
        "    # Train on single feature and evaluate on dev set\n",
        "    pipe.fit(X_train_f, y_train_encoded)\n",
        "    pred = pipe.predict(X_dev_f)\n",
        "    macro_f1 = f1_score(y_dev_encoded, pred, average='macro')\n",
        "\n",
        "    return macro_f1\n",
        "\n",
        "# Check if required variables are defined (from Cell 2 - Configuration)\n",
        "if 'TASKS' not in globals() or 'MODELS' not in globals() or 'classifiers' not in globals():\n",
        "    raise NameError(\n",
        "        \"Required variables not defined. Please run Cell 2 (Configuration) first.\\n\"\n",
        "        \"Cell 2 defines: TASKS, MODELS, CLARITY_LABELS, EVASION_LABELS, and classifiers.\"\n",
        "    )\n",
        "\n",
        "# Check if storage is defined (from Cell 1 - Setup)\n",
        "if 'storage' not in globals():\n",
        "    raise NameError(\n",
        "        \"storage not found. Please run Cell 1 (Setup) first.\\n\"\n",
        "        \"Cell 1 initializes StorageManager as 'storage'.\"\n",
        "    )\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SINGLE-FEATURE ABLATION STUDY\")\n",
        "print(\"=\"*80)\n",
        "print(\"Evaluating each feature individually across all model×task×classifier combinations\")\n",
        "print(f\"Total evaluations: {len(TASKS)} tasks × {len(MODELS)} models × {len(classifiers)} classifiers × 19 features\")\n",
        "print(\"This may take 15-30 minutes depending on your hardware...\\n\")\n",
        "\n",
        "# Store all ablation results\n",
        "# Each entry contains: model, task, classifier, feature, feature_idx, macro_f1\n",
        "ablation_results = []\n",
        "\n",
        "for task in TASKS:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"TASK: {task.upper()}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Select appropriate label list and dataset key based on task\n",
        "    if task == 'clarity':\n",
        "        label_list = CLARITY_LABELS\n",
        "        label_key = 'clarity_label'\n",
        "        task_for_split = 'clarity'\n",
        "    elif task == 'evasion':\n",
        "        label_list = EVASION_LABELS\n",
        "        label_key = 'evasion_label'\n",
        "        task_for_split = 'evasion'\n",
        "    else:  # hierarchical_evasion_to_clarity\n",
        "        # For hierarchical task, we need to load evasion dev set to get clarity labels\n",
        "        # (hierarchical uses evasion predictions mapped to clarity labels)\n",
        "        label_list = CLARITY_LABELS\n",
        "        label_key = 'clarity_label'\n",
        "        # We'll load from evasion dev set (same filtered samples)\n",
        "        task_for_split = 'evasion'\n",
        "\n",
        "\n",
        "\n",
        "    # Load task-specific splits\n",
        "    # For hierarchical task, we load evasion split (which has clarity labels)\n",
        "    train_ds = storage.load_split('train', task=task_for_split)\n",
        "    dev_ds = storage.load_split('dev', task=task_for_split)\n",
        "\n",
        "    # Extract labels\n",
        "    y_train = np.array([train_ds[i][label_key] for i in range(len(train_ds))])\n",
        "    y_dev = np.array([dev_ds[i][label_key] for i in range(len(dev_ds))])\n",
        "\n",
        "    print(f\"  Train: {len(y_train)} samples\")\n",
        "    print(f\"  Dev: {len(y_dev)} samples\")\n",
        "\n",
        "    # Get feature names directly from extraction module (same for all models)\n",
        "    # This avoids dependency on metadata files in GitHub\n",
        "    # Feature names are the same across all models (19 Context Tree features)\n",
        "    feature_names = get_feature_names()\n",
        "    n_features = len(feature_names)\n",
        "\n",
        "    print(f\"  Features: {n_features} features\")\n",
        "    print(f\"  Feature names: {feature_names}\\n\")\n",
        "\n",
        "    # For hierarchical task, we need to use evasion features\n",
        "    # (hierarchical approach uses evasion predictions, so we evaluate on evasion features)\n",
        "    feature_task = 'evasion' if task == 'hierarchical_evasion_to_clarity' else task\n",
        "\n",
        "    # For each model\n",
        "    for model in MODELS:\n",
        "        print(f\"  Model: {model}\")\n",
        "\n",
        "        # Load features\n",
        "        # For hierarchical task, use evasion features (since we're evaluating\n",
        "        # how well evasion features predict clarity via hierarchical mapping)\n",
        "        try:\n",
        "            X_train = storage.load_features(model, feature_task, 'train')\n",
        "            X_dev = storage.load_features(model, feature_task, 'dev')\n",
        "        except FileNotFoundError:\n",
        "            print(f\"    ⚠ Features not found for {model} × {feature_task}, skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Verify feature count matches\n",
        "        if X_train.shape[1] != n_features:\n",
        "            print(f\"    ⚠ Feature count mismatch: expected {n_features}, got {X_train.shape[1]}, skipping...\")\n",
        "            continue\n",
        "\n",
        "        # For each classifier\n",
        "        for clf_name, clf in classifiers.items():\n",
        "            print(f\"    Classifier: {clf_name}\")\n",
        "\n",
        "            # Evaluate each feature individually\n",
        "            for feature_idx, feature_name in enumerate(feature_names):\n",
        "                try:\n",
        "                    macro_f1 = eval_single_feature(\n",
        "                        X_train, X_dev,\n",
        "                        y_train, y_dev,\n",
        "                        feature_idx, clf\n",
        "                    )\n",
        "\n",
        "                    ablation_results.append({\n",
        "                        'model': model,\n",
        "                        'task': task,\n",
        "                        'classifier': clf_name,\n",
        "                        'feature': feature_name,\n",
        "                        'feature_idx': feature_idx,\n",
        "                        'macro_f1': float(macro_f1)\n",
        "                    })\n",
        "                except Exception as e:\n",
        "                    print(f\"      ⚠ Error evaluating feature {feature_name}: {e}\")\n",
        "                    continue\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"SINGLE-FEATURE ABLATION COMPLETE\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"Total evaluations completed: {len(ablation_results)}\")\n",
        "print(f\"Expected: {len(TASKS)} tasks × {len(MODELS)} models × {len(classifiers)} classifiers × {n_features} features = {len(TASKS) * len(MODELS) * len(classifiers) * n_features}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XdFJ7sjAsQ8"
      },
      "source": [
        "<div style=\"font-size: 10px;\">\n",
        "\n",
        "# ============================================================================\n",
        "# FEATURE RANKING AND STATISTICAL ANALYSIS\n",
        "# ============================================================================\n",
        "#\n",
        "# This section performs comprehensive statistical analysis of the ablation results\n",
        "# and ranks features by a weighted score. This is a GLOBAL analysis that aggregates\n",
        "# results across all 36 model×classifier combinations to identify features that work\n",
        "# well across different models and classifiers.\n",
        "#\n",
        "# **What this cell does:**\n",
        "# 1. Aggregates results across all 36 model×classifier combinations for each feature\n",
        "# 2. Computes statistics: min, median, mean, std, best (max), and runs (count)\n",
        "# 3. Calculates normalized_std = std_f1 / mean_f1 (scale-normalized consistency)\n",
        "# 4. Calculates weighted_score = 0.5*mean + 0.3*best + 0.2*(1 - normalized_std)\n",
        "# 5. Ranks features by weighted_score (separately for each task)\n",
        "# 6. Displays top 15 features with all statistics\n",
        "# 7. Saves complete rankings to CSV files\n",
        "# 8. Selects top-K features for Early Fusion (to be used across all models)\n",
        "#\n",
        "# **Statistics computed:**\n",
        "# - min_f1: Worst-case performance across 36 combinations\n",
        "# - median_f1: Typical performance (robust to outliers)\n",
        "# - mean_f1: Average performance\n",
        "# - std_f1: Consistency measure (lower is better)\n",
        "# - best_f1: Best-case performance (peak potential)\n",
        "# - runs: Number of evaluations (should be 36 for complete data)\n",
        "#\n",
        "# **Weighted Score Formula:**\n",
        "# weighted_score = 0.5*mean_f1 + 0.3*best_f1 + 0.2*(1 - normalized_std)\n",
        "#\n",
        "# This formula balances average performance (50%), peak performance (30%), and\n",
        "# consistency (20%). Features with high mean, high best, and low std score highest.\n",
        "#\n",
        "# **Why Global Analysis?**\n",
        "# We use global ranking (not model-specific) to avoid overfitting and noise accumulation.\n",
        "# The selected features will be used across all models in Early Fusion, ensuring\n",
        "# consistency and better generalization.\n",
        "#\n",
        "# **Output:**\n",
        "# - Feature rankings saved separately for clarity, evasion, and hierarchical tasks\n",
        "# - Top-K features selected for Early Fusion (saved to JSON)\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "76inZ54eAsQ8",
        "outputId": "0aedb396-2bef-46c0-d549-2b1c5dbdb2e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "FEATURE RANKING AND STATISTICAL ANALYSIS\n",
            "================================================================================\n",
            "Total ablation results: 2052 evaluations\n",
            "Expected per task: 6 models × 6 classifiers × 19 features = 684\n",
            "\n",
            "================================================================================\n",
            "SAVING RAW ABLATION RESULTS\n",
            "================================================================================\n",
            "  Saved clarity: 684 evaluations → /content/drive/MyDrive/semeval_data/results/ablation/single_feature_clarity.csv\n",
            "  Saved evasion: 684 evaluations → /content/drive/MyDrive/semeval_data/results/ablation/single_feature_evasion.csv\n",
            "  Saved hierarchical_evasion_to_clarity: 684 evaluations → /content/drive/MyDrive/semeval_data/results/ablation/single_feature_hierarchical_evasion_to_clarity.csv\n",
            "\n",
            "================================================================================\n",
            "STATISTICAL AGGREGATION AND FEATURE RANKING\n",
            "================================================================================\n",
            "Computing statistics across all 36 model×classifier combinations...\n",
            "\n",
            "================================================================================\n",
            "TASK: CLARITY - FEATURE RANKING\n",
            "================================================================================\n",
            "\n",
            "Top 15 Features (ranked by weighted_score):\n",
            "Weighted Score Formula: 0.5*mean + 0.3*best + 0.2*(1 - normalized_std)\n",
            "\n",
            "Columns:\n",
            "  - min_f1: Minimum Macro F1 across 36 combinations (worst-case)\n",
            "  - median_f1: Median Macro F1 (typical performance)\n",
            "  - mean_f1: Mean Macro F1 (average performance)\n",
            "  - std_f1: Standard deviation (lower = more consistent)\n",
            "  - best_f1: Maximum Macro F1 (best-case)\n",
            "  - runs: Number of evaluations (should be 36)\n",
            "  - normalized_std: std_f1 / mean_f1 (scale-normalized consistency)\n",
            "  - weighted_score: Combined score for ranking\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"    print(f\\\"  - Top {TOP_K_FEATURES} features per task (to be used across all models in Early Fusion)\\\")\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"feature\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"answer_hedge_ratio\",\n          \"question_model_token_count\",\n          \"attention_mass_q_to_a_per_qtoken\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009559727033361411,\n        \"min\": 0.2465,\n        \"max\": 0.2799,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.2517,\n          0.2591,\n          0.2661\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0315067611791501,\n        \"min\": 0.2671,\n        \"max\": 0.3666,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.3042,\n          0.2889,\n          0.3576\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02422933483747885,\n        \"min\": 0.2811,\n        \"max\": 0.358,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.3234,\n          0.2982,\n          0.3524\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008985533346652802,\n        \"min\": 0.0403,\n        \"max\": 0.0688,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.0523,\n          0.0411,\n          0.0648\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.043294108254170204,\n        \"min\": 0.3593,\n        \"max\": 0.4895,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.4013,\n          0.38,\n          0.4895\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"runs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 36,\n        \"max\": 36,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          36\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"normalized_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02171742113954557,\n        \"min\": 0.1224,\n        \"max\": 0.2085,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.1691\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weighted_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.021495596448265094,\n        \"min\": 0.4209,\n        \"max\": 0.4863,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.4412\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-312643d6-6c28-44e8-b574-da5e91d2e156\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>min_f1</th>\n",
              "      <th>median_f1</th>\n",
              "      <th>mean_f1</th>\n",
              "      <th>std_f1</th>\n",
              "      <th>best_f1</th>\n",
              "      <th>runs</th>\n",
              "      <th>normalized_std</th>\n",
              "      <th>weighted_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>attention_mass_q_to_a_per_qtoken</td>\n",
              "      <td>0.2489</td>\n",
              "      <td>0.3576</td>\n",
              "      <td>0.3524</td>\n",
              "      <td>0.0648</td>\n",
              "      <td>0.4895</td>\n",
              "      <td>36</td>\n",
              "      <td>0.1838</td>\n",
              "      <td>0.4863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>focus_token_to_answer_strength</td>\n",
              "      <td>0.2591</td>\n",
              "      <td>0.3416</td>\n",
              "      <td>0.3488</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.4695</td>\n",
              "      <td>36</td>\n",
              "      <td>0.1714</td>\n",
              "      <td>0.4810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>answer_token_to_focus_strength</td>\n",
              "      <td>0.2492</td>\n",
              "      <td>0.3430</td>\n",
              "      <td>0.3488</td>\n",
              "      <td>0.0583</td>\n",
              "      <td>0.4641</td>\n",
              "      <td>36</td>\n",
              "      <td>0.1671</td>\n",
              "      <td>0.4802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer_model_token_count</td>\n",
              "      <td>0.2496</td>\n",
              "      <td>0.3666</td>\n",
              "      <td>0.3580</td>\n",
              "      <td>0.0547</td>\n",
              "      <td>0.4322</td>\n",
              "      <td>36</td>\n",
              "      <td>0.1529</td>\n",
              "      <td>0.4781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>answer_word_count</td>\n",
              "      <td>0.2496</td>\n",
              "      <td>0.3516</td>\n",
              "      <td>0.3440</td>\n",
              "      <td>0.0470</td>\n",
              "      <td>0.4021</td>\n",
              "      <td>36</td>\n",
              "      <td>0.1367</td>\n",
              "      <td>0.4653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>attention_mass_a_to_q_per_atoken</td>\n",
              "      <td>0.2496</td>\n",
              "      <td>0.3189</td>\n",
              "      <td>0.3298</td>\n",
              "      <td>0.0688</td>\n",
              "      <td>0.4699</td>\n",
              "      <td>36</td>\n",
              "      <td>0.2085</td>\n",
              "      <td>0.4642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>answer_negation_ratio</td>\n",
              "      <td>0.2799</td>\n",
              "      <td>0.3361</td>\n",
              "      <td>0.3294</td>\n",
              "      <td>0.0403</td>\n",
              "      <td>0.3950</td>\n",
              "      <td>36</td>\n",
              "      <td>0.1224</td>\n",
              "      <td>0.4587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>question_content_coverage_in_answer</td>\n",
              "      <td>0.2661</td>\n",
              "      <td>0.3132</td>\n",
              "      <td>0.3243</td>\n",
              "      <td>0.0522</td>\n",
              "      <td>0.4246</td>\n",
              "      <td>36</td>\n",
              "      <td>0.1611</td>\n",
              "      <td>0.4573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>answer_content_word_ratio</td>\n",
              "      <td>0.2687</td>\n",
              "      <td>0.3048</td>\n",
              "      <td>0.3205</td>\n",
              "      <td>0.0579</td>\n",
              "      <td>0.4315</td>\n",
              "      <td>36</td>\n",
              "      <td>0.1807</td>\n",
              "      <td>0.4536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>answer_hedge_ratio</td>\n",
              "      <td>0.2530</td>\n",
              "      <td>0.3042</td>\n",
              "      <td>0.3093</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.4013</td>\n",
              "      <td>36</td>\n",
              "      <td>0.1691</td>\n",
              "      <td>0.4412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>answer_is_short_question</td>\n",
              "      <td>0.2517</td>\n",
              "      <td>0.3593</td>\n",
              "      <td>0.3234</td>\n",
              "      <td>0.0515</td>\n",
              "      <td>0.3593</td>\n",
              "      <td>36</td>\n",
              "      <td>0.1591</td>\n",
              "      <td>0.4377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>question_model_token_count</td>\n",
              "      <td>0.2496</td>\n",
              "      <td>0.2889</td>\n",
              "      <td>0.2921</td>\n",
              "      <td>0.0411</td>\n",
              "      <td>0.3800</td>\n",
              "      <td>36</td>\n",
              "      <td>0.1406</td>\n",
              "      <td>0.4319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>tfidf_cosine_similarity_q_a</td>\n",
              "      <td>0.2496</td>\n",
              "      <td>0.2931</td>\n",
              "      <td>0.2982</td>\n",
              "      <td>0.0452</td>\n",
              "      <td>0.3737</td>\n",
              "      <td>36</td>\n",
              "      <td>0.1516</td>\n",
              "      <td>0.4309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>focus_token_coverage_ratio</td>\n",
              "      <td>0.2496</td>\n",
              "      <td>0.2807</td>\n",
              "      <td>0.2955</td>\n",
              "      <td>0.0411</td>\n",
              "      <td>0.3639</td>\n",
              "      <td>36</td>\n",
              "      <td>0.1390</td>\n",
              "      <td>0.4291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>content_word_jaccard_q_a</td>\n",
              "      <td>0.2465</td>\n",
              "      <td>0.2671</td>\n",
              "      <td>0.2811</td>\n",
              "      <td>0.0422</td>\n",
              "      <td>0.3677</td>\n",
              "      <td>36</td>\n",
              "      <td>0.1501</td>\n",
              "      <td>0.4209</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-312643d6-6c28-44e8-b574-da5e91d2e156')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-312643d6-6c28-44e8-b574-da5e91d2e156 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-312643d6-6c28-44e8-b574-da5e91d2e156');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f9374111-043a-474c-a775-aaad23870b35\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9374111-043a-474c-a775-aaad23870b35')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f9374111-043a-474c-a775-aaad23870b35 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                feature  min_f1  median_f1  mean_f1  std_f1  \\\n",
              "10     attention_mass_q_to_a_per_qtoken  0.2489     0.3576   0.3524  0.0648   \n",
              "14       focus_token_to_answer_strength  0.2591     0.3416   0.3488  0.0598   \n",
              "7        answer_token_to_focus_strength  0.2492     0.3430   0.3488  0.0583   \n",
              "4              answer_model_token_count  0.2496     0.3666   0.3580  0.0547   \n",
              "8                     answer_word_count  0.2496     0.3516   0.3440  0.0470   \n",
              "9      attention_mass_a_to_q_per_atoken  0.2496     0.3189   0.3298  0.0688   \n",
              "5                 answer_negation_ratio  0.2799     0.3361   0.3294  0.0403   \n",
              "15  question_content_coverage_in_answer  0.2661     0.3132   0.3243  0.0522   \n",
              "0             answer_content_word_ratio  0.2687     0.3048   0.3205  0.0579   \n",
              "2                    answer_hedge_ratio  0.2530     0.3042   0.3093  0.0523   \n",
              "3              answer_is_short_question  0.2517     0.3593   0.3234  0.0515   \n",
              "16           question_model_token_count  0.2496     0.2889   0.2921  0.0411   \n",
              "18          tfidf_cosine_similarity_q_a  0.2496     0.2931   0.2982  0.0452   \n",
              "13           focus_token_coverage_ratio  0.2496     0.2807   0.2955  0.0411   \n",
              "12             content_word_jaccard_q_a  0.2465     0.2671   0.2811  0.0422   \n",
              "\n",
              "    best_f1  runs  normalized_std  weighted_score  \n",
              "10   0.4895    36          0.1838          0.4863  \n",
              "14   0.4695    36          0.1714          0.4810  \n",
              "7    0.4641    36          0.1671          0.4802  \n",
              "4    0.4322    36          0.1529          0.4781  \n",
              "8    0.4021    36          0.1367          0.4653  \n",
              "9    0.4699    36          0.2085          0.4642  \n",
              "5    0.3950    36          0.1224          0.4587  \n",
              "15   0.4246    36          0.1611          0.4573  \n",
              "0    0.4315    36          0.1807          0.4536  \n",
              "2    0.4013    36          0.1691          0.4412  \n",
              "3    0.3593    36          0.1591          0.4377  \n",
              "16   0.3800    36          0.1406          0.4319  \n",
              "18   0.3737    36          0.1516          0.4309  \n",
              "13   0.3639    36          0.1390          0.4291  \n",
              "12   0.3677    36          0.1501          0.4209  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  ✓ Saved complete ranking: /content/drive/MyDrive/semeval_data/results/ablation/feature_ranking_clarity.csv\n",
            "    Total features ranked: 19\n",
            "    Expected runs per feature: 36 (6 models × 6 classifiers)\n",
            "\n",
            "================================================================================\n",
            "TASK: EVASION - FEATURE RANKING\n",
            "================================================================================\n",
            "\n",
            "Top 15 Features (ranked by weighted_score):\n",
            "Weighted Score Formula: 0.5*mean + 0.3*best + 0.2*(1 - normalized_std)\n",
            "\n",
            "Columns:\n",
            "  - min_f1: Minimum Macro F1 across 36 combinations (worst-case)\n",
            "  - median_f1: Median Macro F1 (typical performance)\n",
            "  - mean_f1: Mean Macro F1 (average performance)\n",
            "  - std_f1: Standard deviation (lower = more consistent)\n",
            "  - best_f1: Maximum Macro F1 (best-case)\n",
            "  - runs: Number of evaluations (should be 36)\n",
            "  - normalized_std: std_f1 / mean_f1 (scale-normalized consistency)\n",
            "  - weighted_score: Combined score for ranking\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"    print(f\\\"  - Top {TOP_K_FEATURES} features per task (to be used across all models in Early Fusion)\\\")\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"feature\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"answer_hedge_ratio\",\n          \"answer_word_count\",\n          \"answer_token_to_focus_strength\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01252390856379452,\n        \"min\": 0.035,\n        \"max\": 0.0842,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.0356,\n          0.0573,\n          0.0517\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012155002889267257,\n        \"min\": 0.1109,\n        \"max\": 0.1509,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.1343,\n          0.1328,\n          0.139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04852100379757007,\n        \"min\": 0.0937,\n        \"max\": 0.2507,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.1636,\n          0.1516,\n          0.2507\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07690812391294903,\n        \"min\": 0.0247,\n        \"max\": 0.2593,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.1253,\n          0.097,\n          0.2541\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23250171264090158,\n        \"min\": 0.1109,\n        \"max\": 0.8083,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.3917,\n          0.3209,\n          0.8075\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"runs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 36,\n        \"max\": 36,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          36\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"normalized_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22960784788313274,\n        \"min\": 0.2639,\n        \"max\": 1.0679,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7659\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weighted_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0520722090215208,\n        \"min\": 0.2273,\n        \"max\": 0.3649,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.2461\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-fe6376a0-777b-4c2e-9f6f-4908ecb92bdc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>min_f1</th>\n",
              "      <th>median_f1</th>\n",
              "      <th>mean_f1</th>\n",
              "      <th>std_f1</th>\n",
              "      <th>best_f1</th>\n",
              "      <th>runs</th>\n",
              "      <th>normalized_std</th>\n",
              "      <th>weighted_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>answer_token_to_focus_strength</td>\n",
              "      <td>0.0517</td>\n",
              "      <td>0.1390</td>\n",
              "      <td>0.2507</td>\n",
              "      <td>0.2541</td>\n",
              "      <td>0.8075</td>\n",
              "      <td>36</td>\n",
              "      <td>1.0135</td>\n",
              "      <td>0.3649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>attention_mass_q_to_a_per_qtoken</td>\n",
              "      <td>0.0842</td>\n",
              "      <td>0.1509</td>\n",
              "      <td>0.2492</td>\n",
              "      <td>0.2520</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>36</td>\n",
              "      <td>1.0113</td>\n",
              "      <td>0.3623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>attention_mass_a_to_q_per_atoken</td>\n",
              "      <td>0.0524</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.2453</td>\n",
              "      <td>0.2528</td>\n",
              "      <td>0.7967</td>\n",
              "      <td>36</td>\n",
              "      <td>1.0308</td>\n",
              "      <td>0.3555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>focus_token_to_answer_strength</td>\n",
              "      <td>0.0503</td>\n",
              "      <td>0.1383</td>\n",
              "      <td>0.2428</td>\n",
              "      <td>0.2593</td>\n",
              "      <td>0.8083</td>\n",
              "      <td>36</td>\n",
              "      <td>1.0679</td>\n",
              "      <td>0.3503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>answer_content_word_ratio</td>\n",
              "      <td>0.0600</td>\n",
              "      <td>0.1458</td>\n",
              "      <td>0.1901</td>\n",
              "      <td>0.1534</td>\n",
              "      <td>0.4810</td>\n",
              "      <td>36</td>\n",
              "      <td>0.8069</td>\n",
              "      <td>0.2780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>answer_model_token_count</td>\n",
              "      <td>0.0595</td>\n",
              "      <td>0.1312</td>\n",
              "      <td>0.1649</td>\n",
              "      <td>0.1109</td>\n",
              "      <td>0.3955</td>\n",
              "      <td>36</td>\n",
              "      <td>0.6722</td>\n",
              "      <td>0.2667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>answer_negation_ratio</td>\n",
              "      <td>0.0600</td>\n",
              "      <td>0.1463</td>\n",
              "      <td>0.1777</td>\n",
              "      <td>0.1340</td>\n",
              "      <td>0.4250</td>\n",
              "      <td>36</td>\n",
              "      <td>0.7540</td>\n",
              "      <td>0.2656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>tfidf_cosine_similarity_q_a</td>\n",
              "      <td>0.0434</td>\n",
              "      <td>0.1288</td>\n",
              "      <td>0.1706</td>\n",
              "      <td>0.1470</td>\n",
              "      <td>0.4644</td>\n",
              "      <td>36</td>\n",
              "      <td>0.8614</td>\n",
              "      <td>0.2523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>content_word_jaccard_q_a</td>\n",
              "      <td>0.0600</td>\n",
              "      <td>0.1301</td>\n",
              "      <td>0.1560</td>\n",
              "      <td>0.1055</td>\n",
              "      <td>0.3465</td>\n",
              "      <td>36</td>\n",
              "      <td>0.6763</td>\n",
              "      <td>0.2467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>answer_hedge_ratio</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.1343</td>\n",
              "      <td>0.1636</td>\n",
              "      <td>0.1253</td>\n",
              "      <td>0.3917</td>\n",
              "      <td>36</td>\n",
              "      <td>0.7659</td>\n",
              "      <td>0.2461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>question_content_coverage_in_answer</td>\n",
              "      <td>0.0719</td>\n",
              "      <td>0.1138</td>\n",
              "      <td>0.1367</td>\n",
              "      <td>0.0619</td>\n",
              "      <td>0.2275</td>\n",
              "      <td>36</td>\n",
              "      <td>0.4530</td>\n",
              "      <td>0.2460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>answer_word_count</td>\n",
              "      <td>0.0573</td>\n",
              "      <td>0.1328</td>\n",
              "      <td>0.1516</td>\n",
              "      <td>0.0970</td>\n",
              "      <td>0.3209</td>\n",
              "      <td>36</td>\n",
              "      <td>0.6396</td>\n",
              "      <td>0.2442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>question_model_token_count</td>\n",
              "      <td>0.0550</td>\n",
              "      <td>0.1152</td>\n",
              "      <td>0.1308</td>\n",
              "      <td>0.0677</td>\n",
              "      <td>0.2425</td>\n",
              "      <td>36</td>\n",
              "      <td>0.5175</td>\n",
              "      <td>0.2346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>answer_digit_groups_per_word</td>\n",
              "      <td>0.0356</td>\n",
              "      <td>0.1300</td>\n",
              "      <td>0.1452</td>\n",
              "      <td>0.1019</td>\n",
              "      <td>0.3190</td>\n",
              "      <td>36</td>\n",
              "      <td>0.7018</td>\n",
              "      <td>0.2279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>answer_is_short_question</td>\n",
              "      <td>0.0586</td>\n",
              "      <td>0.1109</td>\n",
              "      <td>0.0937</td>\n",
              "      <td>0.0247</td>\n",
              "      <td>0.1109</td>\n",
              "      <td>36</td>\n",
              "      <td>0.2639</td>\n",
              "      <td>0.2273</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe6376a0-777b-4c2e-9f6f-4908ecb92bdc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fe6376a0-777b-4c2e-9f6f-4908ecb92bdc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fe6376a0-777b-4c2e-9f6f-4908ecb92bdc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-28288a66-c25e-492f-9e52-8d006f10572e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-28288a66-c25e-492f-9e52-8d006f10572e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-28288a66-c25e-492f-9e52-8d006f10572e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                feature  min_f1  median_f1  mean_f1  std_f1  \\\n",
              "26       answer_token_to_focus_strength  0.0517     0.1390   0.2507  0.2541   \n",
              "29     attention_mass_q_to_a_per_qtoken  0.0842     0.1509   0.2492  0.2520   \n",
              "28     attention_mass_a_to_q_per_atoken  0.0524     0.1444   0.2453  0.2528   \n",
              "33       focus_token_to_answer_strength  0.0503     0.1383   0.2428  0.2593   \n",
              "19            answer_content_word_ratio  0.0600     0.1458   0.1901  0.1534   \n",
              "23             answer_model_token_count  0.0595     0.1312   0.1649  0.1109   \n",
              "24                answer_negation_ratio  0.0600     0.1463   0.1777  0.1340   \n",
              "37          tfidf_cosine_similarity_q_a  0.0434     0.1288   0.1706  0.1470   \n",
              "31             content_word_jaccard_q_a  0.0600     0.1301   0.1560  0.1055   \n",
              "21                   answer_hedge_ratio  0.0350     0.1343   0.1636  0.1253   \n",
              "34  question_content_coverage_in_answer  0.0719     0.1138   0.1367  0.0619   \n",
              "27                    answer_word_count  0.0573     0.1328   0.1516  0.0970   \n",
              "35           question_model_token_count  0.0550     0.1152   0.1308  0.0677   \n",
              "20         answer_digit_groups_per_word  0.0356     0.1300   0.1452  0.1019   \n",
              "22             answer_is_short_question  0.0586     0.1109   0.0937  0.0247   \n",
              "\n",
              "    best_f1  runs  normalized_std  weighted_score  \n",
              "26   0.8075    36          1.0135          0.3649  \n",
              "29   0.8000    36          1.0113          0.3623  \n",
              "28   0.7967    36          1.0308          0.3555  \n",
              "33   0.8083    36          1.0679          0.3503  \n",
              "19   0.4810    36          0.8069          0.2780  \n",
              "23   0.3955    36          0.6722          0.2667  \n",
              "24   0.4250    36          0.7540          0.2656  \n",
              "37   0.4644    36          0.8614          0.2523  \n",
              "31   0.3465    36          0.6763          0.2467  \n",
              "21   0.3917    36          0.7659          0.2461  \n",
              "34   0.2275    36          0.4530          0.2460  \n",
              "27   0.3209    36          0.6396          0.2442  \n",
              "35   0.2425    36          0.5175          0.2346  \n",
              "20   0.3190    36          0.7018          0.2279  \n",
              "22   0.1109    36          0.2639          0.2273  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  ✓ Saved complete ranking: /content/drive/MyDrive/semeval_data/results/ablation/feature_ranking_evasion.csv\n",
            "    Total features ranked: 19\n",
            "    Expected runs per feature: 36 (6 models × 6 classifiers)\n",
            "\n",
            "================================================================================\n",
            "TASK: HIERARCHICAL_EVASION_TO_CLARITY - FEATURE RANKING\n",
            "================================================================================\n",
            "\n",
            "Top 15 Features (ranked by weighted_score):\n",
            "Weighted Score Formula: 0.5*mean + 0.3*best + 0.2*(1 - normalized_std)\n",
            "\n",
            "Columns:\n",
            "  - min_f1: Minimum Macro F1 across 36 combinations (worst-case)\n",
            "  - median_f1: Median Macro F1 (typical performance)\n",
            "  - mean_f1: Mean Macro F1 (average performance)\n",
            "  - std_f1: Standard deviation (lower = more consistent)\n",
            "  - best_f1: Maximum Macro F1 (best-case)\n",
            "  - runs: Number of evaluations (should be 36)\n",
            "  - normalized_std: std_f1 / mean_f1 (scale-normalized consistency)\n",
            "  - weighted_score: Combined score for ranking\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"    print(f\\\"  - Top {TOP_K_FEATURES} features per task (to be used across all models in Early Fusion)\\\")\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"feature\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"question_content_coverage_in_answer\",\n          \"content_word_jaccard_q_a\",\n          \"answer_token_to_focus_strength\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011803328828282791,\n        \"min\": 0.2265,\n        \"max\": 0.2685,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.2269,\n          0.2446,\n          0.2685\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03254767638550005,\n        \"min\": 0.2553,\n        \"max\": 0.3514,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.2874,\n          0.2832,\n          0.3483\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.050500790187122904,\n        \"min\": 0.2634,\n        \"max\": 0.4159,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.3038,\n          0.2993,\n          0.4151\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06375935561603041,\n        \"min\": 0.0213,\n        \"max\": 0.2114,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.0576,\n          0.0838,\n          0.2051\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19126876254059239,\n        \"min\": 0.313,\n        \"max\": 0.8639,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.4225,\n          0.4703,\n          0.863\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"runs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 36,\n        \"max\": 36,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          36\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"normalized_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1380063714885243,\n        \"min\": 0.0713,\n        \"max\": 0.5349,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.1897\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weighted_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05597780427480673,\n        \"min\": 0.4101,\n        \"max\": 0.5676,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.4407\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d4781802-744e-4374-908b-76b366d737da\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>min_f1</th>\n",
              "      <th>median_f1</th>\n",
              "      <th>mean_f1</th>\n",
              "      <th>std_f1</th>\n",
              "      <th>best_f1</th>\n",
              "      <th>runs</th>\n",
              "      <th>normalized_std</th>\n",
              "      <th>weighted_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>answer_token_to_focus_strength</td>\n",
              "      <td>0.2269</td>\n",
              "      <td>0.3483</td>\n",
              "      <td>0.4151</td>\n",
              "      <td>0.2051</td>\n",
              "      <td>0.8630</td>\n",
              "      <td>36</td>\n",
              "      <td>0.4940</td>\n",
              "      <td>0.5676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>focus_token_to_answer_strength</td>\n",
              "      <td>0.2269</td>\n",
              "      <td>0.3424</td>\n",
              "      <td>0.4159</td>\n",
              "      <td>0.2082</td>\n",
              "      <td>0.8639</td>\n",
              "      <td>36</td>\n",
              "      <td>0.5006</td>\n",
              "      <td>0.5670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>attention_mass_q_to_a_per_qtoken</td>\n",
              "      <td>0.2269</td>\n",
              "      <td>0.3361</td>\n",
              "      <td>0.4132</td>\n",
              "      <td>0.2052</td>\n",
              "      <td>0.8564</td>\n",
              "      <td>36</td>\n",
              "      <td>0.4967</td>\n",
              "      <td>0.5642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>attention_mass_a_to_q_per_atoken</td>\n",
              "      <td>0.2269</td>\n",
              "      <td>0.3289</td>\n",
              "      <td>0.3953</td>\n",
              "      <td>0.2114</td>\n",
              "      <td>0.8565</td>\n",
              "      <td>36</td>\n",
              "      <td>0.5349</td>\n",
              "      <td>0.5476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>answer_model_token_count</td>\n",
              "      <td>0.2269</td>\n",
              "      <td>0.3366</td>\n",
              "      <td>0.3606</td>\n",
              "      <td>0.1079</td>\n",
              "      <td>0.5564</td>\n",
              "      <td>36</td>\n",
              "      <td>0.2993</td>\n",
              "      <td>0.4874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>answer_negation_ratio</td>\n",
              "      <td>0.2446</td>\n",
              "      <td>0.3514</td>\n",
              "      <td>0.3592</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.5551</td>\n",
              "      <td>36</td>\n",
              "      <td>0.2943</td>\n",
              "      <td>0.4873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>answer_content_word_ratio</td>\n",
              "      <td>0.2269</td>\n",
              "      <td>0.3219</td>\n",
              "      <td>0.3495</td>\n",
              "      <td>0.1313</td>\n",
              "      <td>0.6038</td>\n",
              "      <td>36</td>\n",
              "      <td>0.3755</td>\n",
              "      <td>0.4808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>answer_word_count</td>\n",
              "      <td>0.2269</td>\n",
              "      <td>0.3211</td>\n",
              "      <td>0.3371</td>\n",
              "      <td>0.1076</td>\n",
              "      <td>0.5169</td>\n",
              "      <td>36</td>\n",
              "      <td>0.3191</td>\n",
              "      <td>0.4598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>answer_hedge_ratio</td>\n",
              "      <td>0.2438</td>\n",
              "      <td>0.2853</td>\n",
              "      <td>0.3180</td>\n",
              "      <td>0.0945</td>\n",
              "      <td>0.5091</td>\n",
              "      <td>36</td>\n",
              "      <td>0.2970</td>\n",
              "      <td>0.4523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>question_content_coverage_in_answer</td>\n",
              "      <td>0.2381</td>\n",
              "      <td>0.2874</td>\n",
              "      <td>0.3038</td>\n",
              "      <td>0.0576</td>\n",
              "      <td>0.4225</td>\n",
              "      <td>36</td>\n",
              "      <td>0.1897</td>\n",
              "      <td>0.4407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>tfidf_cosine_similarity_q_a</td>\n",
              "      <td>0.2269</td>\n",
              "      <td>0.2738</td>\n",
              "      <td>0.3008</td>\n",
              "      <td>0.0943</td>\n",
              "      <td>0.4928</td>\n",
              "      <td>36</td>\n",
              "      <td>0.3136</td>\n",
              "      <td>0.4355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>content_word_jaccard_q_a</td>\n",
              "      <td>0.2265</td>\n",
              "      <td>0.2832</td>\n",
              "      <td>0.2993</td>\n",
              "      <td>0.0838</td>\n",
              "      <td>0.4703</td>\n",
              "      <td>36</td>\n",
              "      <td>0.2800</td>\n",
              "      <td>0.4348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>question_model_token_count</td>\n",
              "      <td>0.2269</td>\n",
              "      <td>0.2606</td>\n",
              "      <td>0.2908</td>\n",
              "      <td>0.0726</td>\n",
              "      <td>0.4453</td>\n",
              "      <td>36</td>\n",
              "      <td>0.2497</td>\n",
              "      <td>0.4290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>answer_is_short_question</td>\n",
              "      <td>0.2685</td>\n",
              "      <td>0.3130</td>\n",
              "      <td>0.2982</td>\n",
              "      <td>0.0213</td>\n",
              "      <td>0.3130</td>\n",
              "      <td>36</td>\n",
              "      <td>0.0713</td>\n",
              "      <td>0.4287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>focus_token_coverage_ratio</td>\n",
              "      <td>0.2269</td>\n",
              "      <td>0.2553</td>\n",
              "      <td>0.2634</td>\n",
              "      <td>0.0341</td>\n",
              "      <td>0.3475</td>\n",
              "      <td>36</td>\n",
              "      <td>0.1293</td>\n",
              "      <td>0.4101</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4781802-744e-4374-908b-76b366d737da')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d4781802-744e-4374-908b-76b366d737da button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d4781802-744e-4374-908b-76b366d737da');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-11cdf9f9-2805-4d9c-986b-f0bcfd6d69ca\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-11cdf9f9-2805-4d9c-986b-f0bcfd6d69ca')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-11cdf9f9-2805-4d9c-986b-f0bcfd6d69ca button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                feature  min_f1  median_f1  mean_f1  std_f1  \\\n",
              "45       answer_token_to_focus_strength  0.2269     0.3483   0.4151  0.2051   \n",
              "52       focus_token_to_answer_strength  0.2269     0.3424   0.4159  0.2082   \n",
              "48     attention_mass_q_to_a_per_qtoken  0.2269     0.3361   0.4132  0.2052   \n",
              "47     attention_mass_a_to_q_per_atoken  0.2269     0.3289   0.3953  0.2114   \n",
              "42             answer_model_token_count  0.2269     0.3366   0.3606  0.1079   \n",
              "43                answer_negation_ratio  0.2446     0.3514   0.3592  0.1057   \n",
              "38            answer_content_word_ratio  0.2269     0.3219   0.3495  0.1313   \n",
              "46                    answer_word_count  0.2269     0.3211   0.3371  0.1076   \n",
              "40                   answer_hedge_ratio  0.2438     0.2853   0.3180  0.0945   \n",
              "53  question_content_coverage_in_answer  0.2381     0.2874   0.3038  0.0576   \n",
              "56          tfidf_cosine_similarity_q_a  0.2269     0.2738   0.3008  0.0943   \n",
              "50             content_word_jaccard_q_a  0.2265     0.2832   0.2993  0.0838   \n",
              "54           question_model_token_count  0.2269     0.2606   0.2908  0.0726   \n",
              "41             answer_is_short_question  0.2685     0.3130   0.2982  0.0213   \n",
              "51           focus_token_coverage_ratio  0.2269     0.2553   0.2634  0.0341   \n",
              "\n",
              "    best_f1  runs  normalized_std  weighted_score  \n",
              "45   0.8630    36          0.4940          0.5676  \n",
              "52   0.8639    36          0.5006          0.5670  \n",
              "48   0.8564    36          0.4967          0.5642  \n",
              "47   0.8565    36          0.5349          0.5476  \n",
              "42   0.5564    36          0.2993          0.4874  \n",
              "43   0.5551    36          0.2943          0.4873  \n",
              "38   0.6038    36          0.3755          0.4808  \n",
              "46   0.5169    36          0.3191          0.4598  \n",
              "40   0.5091    36          0.2970          0.4523  \n",
              "53   0.4225    36          0.1897          0.4407  \n",
              "56   0.4928    36          0.3136          0.4355  \n",
              "50   0.4703    36          0.2800          0.4348  \n",
              "54   0.4453    36          0.2497          0.4290  \n",
              "41   0.3130    36          0.0713          0.4287  \n",
              "51   0.3475    36          0.1293          0.4101  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  ✓ Saved complete ranking: /content/drive/MyDrive/semeval_data/results/ablation/feature_ranking_hierarchical_evasion_to_clarity.csv\n",
            "    Total features ranked: 19\n",
            "    Expected runs per feature: 36 (6 models × 6 classifiers)\n",
            "\n",
            "================================================================================\n",
            "TOP-K FEATURE SELECTION FOR EARLY FUSION\n",
            "================================================================================\n",
            "Selecting top-K features for each task (to be used in Early Fusion)\n",
            "\n",
            "  CLARITY - Top 10 Features:\n",
            "     1. attention_mass_q_to_a_per_qtoken\n",
            "        weighted_score=0.4863, mean_f1=0.3524, best_f1=0.4895\n",
            "     2. focus_token_to_answer_strength\n",
            "        weighted_score=0.4810, mean_f1=0.3488, best_f1=0.4695\n",
            "     3. answer_token_to_focus_strength\n",
            "        weighted_score=0.4802, mean_f1=0.3488, best_f1=0.4641\n",
            "     4. answer_model_token_count\n",
            "        weighted_score=0.4781, mean_f1=0.3580, best_f1=0.4322\n",
            "     5. answer_word_count\n",
            "        weighted_score=0.4653, mean_f1=0.3440, best_f1=0.4021\n",
            "     6. attention_mass_a_to_q_per_atoken\n",
            "        weighted_score=0.4642, mean_f1=0.3298, best_f1=0.4699\n",
            "     7. answer_negation_ratio\n",
            "        weighted_score=0.4587, mean_f1=0.3294, best_f1=0.3950\n",
            "     8. question_content_coverage_in_answer\n",
            "        weighted_score=0.4573, mean_f1=0.3243, best_f1=0.4246\n",
            "     9. answer_content_word_ratio\n",
            "        weighted_score=0.4536, mean_f1=0.3205, best_f1=0.4315\n",
            "    10. answer_hedge_ratio\n",
            "        weighted_score=0.4412, mean_f1=0.3093, best_f1=0.4013\n",
            "\n",
            "  EVASION - Top 10 Features:\n",
            "     1. answer_token_to_focus_strength\n",
            "        weighted_score=0.3649, mean_f1=0.2507, best_f1=0.8075\n",
            "     2. attention_mass_q_to_a_per_qtoken\n",
            "        weighted_score=0.3623, mean_f1=0.2492, best_f1=0.8000\n",
            "     3. attention_mass_a_to_q_per_atoken\n",
            "        weighted_score=0.3555, mean_f1=0.2453, best_f1=0.7967\n",
            "     4. focus_token_to_answer_strength\n",
            "        weighted_score=0.3503, mean_f1=0.2428, best_f1=0.8083\n",
            "     5. answer_content_word_ratio\n",
            "        weighted_score=0.2780, mean_f1=0.1901, best_f1=0.4810\n",
            "     6. answer_model_token_count\n",
            "        weighted_score=0.2667, mean_f1=0.1649, best_f1=0.3955\n",
            "     7. answer_negation_ratio\n",
            "        weighted_score=0.2656, mean_f1=0.1777, best_f1=0.4250\n",
            "     8. tfidf_cosine_similarity_q_a\n",
            "        weighted_score=0.2523, mean_f1=0.1706, best_f1=0.4644\n",
            "     9. content_word_jaccard_q_a\n",
            "        weighted_score=0.2467, mean_f1=0.1560, best_f1=0.3465\n",
            "    10. answer_hedge_ratio\n",
            "        weighted_score=0.2461, mean_f1=0.1636, best_f1=0.3917\n",
            "\n",
            "  HIERARCHICAL_EVASION_TO_CLARITY - Top 10 Features:\n",
            "     1. answer_token_to_focus_strength\n",
            "        weighted_score=0.5676, mean_f1=0.4151, best_f1=0.8630\n",
            "     2. focus_token_to_answer_strength\n",
            "        weighted_score=0.5670, mean_f1=0.4159, best_f1=0.8639\n",
            "     3. attention_mass_q_to_a_per_qtoken\n",
            "        weighted_score=0.5642, mean_f1=0.4132, best_f1=0.8564\n",
            "     4. attention_mass_a_to_q_per_atoken\n",
            "        weighted_score=0.5476, mean_f1=0.3953, best_f1=0.8565\n",
            "     5. answer_model_token_count\n",
            "        weighted_score=0.4874, mean_f1=0.3606, best_f1=0.5564\n",
            "     6. answer_negation_ratio\n",
            "        weighted_score=0.4873, mean_f1=0.3592, best_f1=0.5551\n",
            "     7. answer_content_word_ratio\n",
            "        weighted_score=0.4808, mean_f1=0.3495, best_f1=0.6038\n",
            "     8. answer_word_count\n",
            "        weighted_score=0.4598, mean_f1=0.3371, best_f1=0.5169\n",
            "     9. answer_hedge_ratio\n",
            "        weighted_score=0.4523, mean_f1=0.3180, best_f1=0.5091\n",
            "    10. question_content_coverage_in_answer\n",
            "        weighted_score=0.4407, mean_f1=0.3038, best_f1=0.4225\n",
            "\n",
            "================================================================================\n",
            "FEATURE RANKING COMPLETE\n",
            "================================================================================\n",
            "Rankings saved separately for each task:\n",
            "  - clarity: /content/drive/MyDrive/semeval_data/results/ablation/feature_ranking_clarity.csv\n",
            "  - evasion: /content/drive/MyDrive/semeval_data/results/ablation/feature_ranking_evasion.csv\n",
            "  - hierarchical_evasion_to_clarity: /content/drive/MyDrive/semeval_data/results/ablation/feature_ranking_hierarchical_evasion_to_clarity.csv\n",
            "\n",
            "Top-K features for Early Fusion saved:\n",
            "  - /content/drive/MyDrive/semeval_data/results/ablation/selected_features_for_early_fusion.json\n",
            "  - Top 10 features per task (to be used across all models in Early Fusion)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# FEATURE RANKING AND STATISTICAL ANALYSIS\n",
        "# ============================================================================\n",
        "# This cell performs comprehensive statistical analysis and ranking of features\n",
        "# based on the single-feature ablation results from Cell 3.\n",
        "#\n",
        "# For each task, we aggregate results across all 36 model×classifier combinations\n",
        "# and compute the following statistics for each feature:\n",
        "# - min_f1: Minimum Macro F1 (worst-case performance)\n",
        "# - median_f1: Median Macro F1 (typical performance)\n",
        "# - mean_f1: Mean Macro F1 (average performance)\n",
        "# - std_f1: Standard deviation (consistency measure - lower is better)\n",
        "# - best_f1: Maximum Macro F1 (best-case performance)\n",
        "# - runs: Number of evaluations (should be 36 for complete data)\n",
        "#\n",
        "# Features are then ranked by a weighted score that combines multiple statistics:\n",
        "# weighted_score = 0.5*mean_f1 + 0.3*best_f1 + 0.2*(1 - normalized_std)\n",
        "#\n",
        "# This ranking is performed separately for each of the 3 tasks.\n",
        "\n",
        "# Check if ablation_results exists (from Cell 4 - Single-Feature Ablation)\n",
        "if 'ablation_results' not in globals():\n",
        "    raise NameError(\n",
        "        \"ablation_results not found. Please run Cell 4 (Single-Feature Ablation) first.\\n\"\n",
        "        \"Cell 4 performs the ablation study and creates ablation_results list.\"\n",
        "    )\n",
        "\n",
        "# Check if storage and ablation_dir are defined (from Cell 1 - Setup)\n",
        "if 'storage' not in globals():\n",
        "    raise NameError(\n",
        "        \"storage not found. Please run Cell 1 (Setup) first.\\n\"\n",
        "        \"Cell 1 initializes StorageManager as 'storage'.\"\n",
        "    )\n",
        "if 'ablation_dir' not in globals():\n",
        "    raise NameError(\n",
        "        \"ablation_dir not found. Please run Cell 1 (Setup) first.\\n\"\n",
        "        \"Cell 1 creates ablation_dir directory.\"\n",
        "    )\n",
        "\n",
        "df_ablation = pd.DataFrame(ablation_results)\n",
        "\n",
        "if len(df_ablation) == 0:\n",
        "    print(\"⚠ No ablation results found. Make sure Cell 4 completed successfully.\")\n",
        "    print(\"  You need to run Cell 4 (Single-Feature Ablation) first.\")\n",
        "else:\n",
        "    print(\"=\"*80)\n",
        "    print(\"FEATURE RANKING AND STATISTICAL ANALYSIS\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Total ablation results: {len(df_ablation)} evaluations\")\n",
        "    print(f\"Expected per task: {len(MODELS)} models × {len(classifiers)} classifiers × 19 features = {len(MODELS) * len(classifiers) * 19}\")\n",
        "\n",
        "    # Save raw ablation results for each task\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"SAVING RAW ABLATION RESULTS\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    for task in TASKS:\n",
        "        df_task = df_ablation[df_ablation['task'] == task]\n",
        "        if len(df_task) > 0:\n",
        "            csv_path = ablation_dir / f'single_feature_{task}.csv'\n",
        "            df_task.to_csv(csv_path, index=False)\n",
        "            print(f\"  Saved {task}: {len(df_task)} evaluations → {csv_path}\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # STATISTICAL AGGREGATION AND WEIGHTED SCORE CALCULATION\n",
        "    # ========================================================================\n",
        "    # Aggregate results across all 36 model×classifier combinations for each feature\n",
        "    # Compute comprehensive statistics and calculate weighted score for ranking\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"STATISTICAL AGGREGATION AND FEATURE RANKING\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(\"Computing statistics across all 36 model×classifier combinations...\")\n",
        "\n",
        "    # Calculate comprehensive statistics for each feature×task combination\n",
        "    # Using 'median' in addition to mean/std/min/max to get more robust statistics\n",
        "    df_stats = df_ablation.groupby(['task', 'feature'])['macro_f1'].agg([\n",
        "        'min',      # Minimum F1 (worst-case)\n",
        "        'median',   # Median F1 (typical performance)\n",
        "        'mean',     # Mean F1 (average performance)\n",
        "        'std',      # Standard deviation (consistency)\n",
        "        'max',      # Maximum F1 (best-case, same as best_f1)\n",
        "        'count'     # Number of evaluations (should be 36)\n",
        "    ]).reset_index()\n",
        "\n",
        "    # Rename columns for clarity\n",
        "    df_stats.columns = ['task', 'feature', 'min_f1', 'median_f1', 'mean_f1', 'std_f1', 'best_f1', 'runs']\n",
        "\n",
        "    # Calculate weighted score\n",
        "    # Formula: weighted_score = 0.5*mean + 0.3*best + 0.2*(1 - normalized_std)\n",
        "    # This balances:\n",
        "    # - Average performance (50% weight)\n",
        "    # - Peak performance (30% weight)\n",
        "    # - Consistency (20% weight, lower std = higher score)\n",
        "    #\n",
        "    # Normalize std by mean to account for scale differences:\n",
        "    # normalized_std = std_f1 / (mean_f1 + epsilon)\n",
        "    # where epsilon prevents division by zero\n",
        "    EPSILON = 1e-6\n",
        "    df_stats['normalized_std'] = df_stats['std_f1'] / (df_stats['mean_f1'] + EPSILON)\n",
        "\n",
        "    # Calculate weighted score\n",
        "    # Higher is better: we want high mean, high best, and low std (high 1-normalized_std)\n",
        "    df_stats['weighted_score'] = (\n",
        "        0.5 * df_stats['mean_f1'] +\n",
        "        0.3 * df_stats['best_f1'] +\n",
        "        0.2 * (1 - df_stats['normalized_std'])\n",
        "    )\n",
        "\n",
        "    # Sort by weighted_score (descending) for ranking\n",
        "    # Secondary sort by mean_f1 for tie-breaking\n",
        "    df_stats = df_stats.sort_values(['weighted_score', 'mean_f1'], ascending=False)\n",
        "\n",
        "    # ========================================================================\n",
        "    # DISPLAY AND SAVE RANKINGS FOR EACH TASK\n",
        "    # ========================================================================\n",
        "\n",
        "    for task in TASKS:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"TASK: {task.upper()} - FEATURE RANKING\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        df_task = df_stats[df_stats['task'] == task].copy()\n",
        "\n",
        "        if len(df_task) == 0:\n",
        "            print(f\"  ⚠ No results found for task: {task}\")\n",
        "            continue\n",
        "\n",
        "        # Round all numeric columns for display\n",
        "        numeric_cols = ['min_f1', 'median_f1', 'mean_f1', 'std_f1', 'best_f1', 'runs', 'normalized_std', 'weighted_score']\n",
        "        df_task[numeric_cols] = df_task[numeric_cols].round(4)\n",
        "\n",
        "        # Display top 15 features with all statistics\n",
        "        print(f\"\\nTop 15 Features (ranked by weighted_score):\")\n",
        "        print(\"Weighted Score Formula: 0.5*mean + 0.3*best + 0.2*(1 - normalized_std)\")\n",
        "        print(\"\\nColumns:\")\n",
        "        print(\"  - min_f1: Minimum Macro F1 across 36 combinations (worst-case)\")\n",
        "        print(\"  - median_f1: Median Macro F1 (typical performance)\")\n",
        "        print(\"  - mean_f1: Mean Macro F1 (average performance)\")\n",
        "        print(\"  - std_f1: Standard deviation (lower = more consistent)\")\n",
        "        print(\"  - best_f1: Maximum Macro F1 (best-case)\")\n",
        "        print(\"  - runs: Number of evaluations (should be 36)\")\n",
        "        print(\"  - normalized_std: std_f1 / mean_f1 (scale-normalized consistency)\")\n",
        "        print(\"  - weighted_score: Combined score for ranking\\n\")\n",
        "\n",
        "        display(df_task[['feature', 'min_f1', 'median_f1', 'mean_f1', 'std_f1', 'best_f1', 'runs', 'normalized_std', 'weighted_score']].head(15))\n",
        "\n",
        "        # Save complete ranking to CSV\n",
        "        csv_path = ablation_dir / f'feature_ranking_{task}.csv'\n",
        "        df_task.to_csv(csv_path, index=False)\n",
        "        print(f\"\\n  ✓ Saved complete ranking: {csv_path}\")\n",
        "        print(f\"    Total features ranked: {len(df_task)}\")\n",
        "        print(f\"    Expected runs per feature: 36 (6 models × 6 classifiers)\")\n",
        "\n",
        "        # Verify data completeness\n",
        "        incomplete = df_task[df_task['runs'] < 36]\n",
        "        if len(incomplete) > 0:\n",
        "            print(f\"    ⚠ Warning: {len(incomplete)} features have incomplete data (< 36 runs)\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # TOP-K FEATURE SELECTION FOR EARLY FUSION\n",
        "    # ========================================================================\n",
        "    # Select top-K features for each task to use in Early Fusion\n",
        "    # These features will be used across all models in Early Fusion\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"TOP-K FEATURE SELECTION FOR EARLY FUSION\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(\"Selecting top-K features for each task (to be used in Early Fusion)\")\n",
        "\n",
        "    TOP_K_FEATURES = 10  # Number of top features to select for Early Fusion\n",
        "\n",
        "    selected_features_for_fusion = {}\n",
        "\n",
        "    for task in TASKS:\n",
        "        df_task = df_stats[df_stats['task'] == task].copy()\n",
        "\n",
        "        if len(df_task) == 0:\n",
        "            print(f\"  ⚠ No ranking data found for task: {task}\")\n",
        "            continue\n",
        "\n",
        "        # Select top-K features by weighted_score\n",
        "        top_k_features = df_task.head(TOP_K_FEATURES)['feature'].tolist()\n",
        "\n",
        "        selected_features_for_fusion[task] = {\n",
        "            'top_k': TOP_K_FEATURES,\n",
        "            'features': top_k_features,\n",
        "            'ranking': df_task.head(TOP_K_FEATURES)[['feature', 'weighted_score', 'mean_f1', 'best_f1', 'std_f1']].to_dict('records')\n",
        "        }\n",
        "\n",
        "        print(f\"\\n  {task.upper()} - Top {TOP_K_FEATURES} Features:\")\n",
        "        for i, feat in enumerate(top_k_features, 1):\n",
        "            row = df_task[df_task['feature'] == feat].iloc[0]\n",
        "            print(f\"    {i:2d}. {feat}\")\n",
        "            print(f\"        weighted_score={row['weighted_score']:.4f}, mean_f1={row['mean_f1']:.4f}, best_f1={row['best_f1']:.4f}\")\n",
        "\n",
        "    # Save selected features for Early Fusion\n",
        "    import json\n",
        "    fusion_features_path = ablation_dir / 'selected_features_for_early_fusion.json'\n",
        "    with open(fusion_features_path, 'w') as f:\n",
        "        json.dump(selected_features_for_fusion, f, indent=2)\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"FEATURE RANKING COMPLETE\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(\"Rankings saved separately for each task:\")\n",
        "    for task in TASKS:\n",
        "        print(f\"  - {task}: {ablation_dir / f'feature_ranking_{task}.csv'}\")\n",
        "    print(f\"\\nTop-K features for Early Fusion saved:\")\n",
        "    print(f\"  - {fusion_features_path}\")\n",
        "    print(f\"  - Top {TOP_K_FEATURES} features per task (to be used across all models in Early Fusion)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LojjIATHCvcP"
      },
      "source": [
        "<div style=\"font-size: 10px;\">\n",
        "\n",
        "# ============================================================================\n",
        "# GREEDY FORWARD SELECTION (OPTIONAL)\n",
        "# ============================================================================\n",
        "#\n",
        "# This section performs greedy forward selection: iteratively adds features that\n",
        "# maximize Macro F1 on the dev set.\n",
        "#\n",
        "# **What this cell does:**\n",
        "# 1. Starts with top-K features (by weighted_score from Cell 4)\n",
        "# 2. For each iteration, tries adding each remaining feature\n",
        "# 3. Selects the feature that gives the highest Macro F1 improvement\n",
        "# 4. Continues until no improvement or max_features reached\n",
        "# 5. Saves selected feature sets and trajectories\n",
        "#\n",
        "# **Process:**\n",
        "# - For each task (clarity, evasion, hierarchical)\n",
        "# - For each model (6 models)\n",
        "# - Uses the best classifier for that model×task combination\n",
        "# - Starts with top 5 features by weighted_score\n",
        "# - Iteratively adds up to 15 features total\n",
        "#\n",
        "# **Output:**\n",
        "# - Selected feature sets for each model×task combination\n",
        "# - Trajectories showing feature count vs Macro F1 progression\n",
        "# - All results saved to Google Drive\n",
        "#\n",
        "# **Note:** This cell requires Cell 4 (Feature Ranking) to complete first.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lrkz-JLDCWPy",
        "outputId": "d2a87767-e4ef-4d42-b50d-b1456c12dac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "GREEDY FORWARD SELECTION\n",
            "================================================================================\n",
            "Starting with top-K features from weighted score ranking (Cell 6)\n",
            "\n",
            "\n",
            "================================================================================\n",
            "TASK: CLARITY - GREEDY FORWARD SELECTION\n",
            "================================================================================\n",
            "  Top 5 seed features (by weighted_score):\n",
            "    1. attention_mass_q_to_a_per_qtoken\n",
            "       weighted_score=0.4863, mean=0.3524, best=0.4895, std=0.0648\n",
            "    2. focus_token_to_answer_strength\n",
            "       weighted_score=0.4810, mean=0.3488, best=0.4695, std=0.0598\n",
            "    3. answer_token_to_focus_strength\n",
            "       weighted_score=0.4802, mean=0.3488, best=0.4641, std=0.0583\n",
            "    4. answer_model_token_count\n",
            "       weighted_score=0.4781, mean=0.3580, best=0.4322, std=0.0547\n",
            "    5. answer_word_count\n",
            "       weighted_score=0.4653, mean=0.3440, best=0.4021, std=0.0470\n",
            "\n",
            "  BERT × RandomForest:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Greedy selection:  27%|██▋       | 4/15 [00:23<01:04,  5.85s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Selected 9 features\n",
            "    Final Macro F1: 0.5294\n",
            "    Saved trajectory: /content/drive/MyDrive/semeval_data/results/ablation/greedy_trajectory_bert_clarity.csv\n",
            "\n",
            "  BERT_POLITICAL × RandomForest:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Greedy selection:  27%|██▋       | 4/15 [00:23<01:04,  5.83s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Selected 9 features\n",
            "    Final Macro F1: 0.5294\n",
            "    Saved trajectory: /content/drive/MyDrive/semeval_data/results/ablation/greedy_trajectory_bert_political_clarity.csv\n",
            "\n",
            "  BERT_AMBIGUITY × RandomForest:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Greedy selection:  27%|██▋       | 4/15 [00:23<01:04,  5.86s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Selected 9 features\n",
            "    Final Macro F1: 0.5294\n",
            "    Saved trajectory: /content/drive/MyDrive/semeval_data/results/ablation/greedy_trajectory_bert_ambiguity_clarity.csv\n",
            "\n",
            "  ROBERTA × RandomForest:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Greedy selection:  20%|██        | 3/15 [00:19<01:17,  6.46s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Selected 8 features\n",
            "    Final Macro F1: 0.5367\n",
            "    Saved trajectory: /content/drive/MyDrive/semeval_data/results/ablation/greedy_trajectory_roberta_clarity.csv\n",
            "\n",
            "  DEBERTA × RandomForest:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Greedy selection:  13%|█▎        | 2/15 [00:15<01:37,  7.53s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Selected 7 features\n",
            "    Final Macro F1: 0.5166\n",
            "    Saved trajectory: /content/drive/MyDrive/semeval_data/results/ablation/greedy_trajectory_deberta_clarity.csv\n",
            "\n",
            "  XLNET × RandomForest:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Greedy selection:  27%|██▋       | 4/15 [00:23<01:04,  5.87s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Selected 9 features\n",
            "    Final Macro F1: 0.5169\n",
            "    Saved trajectory: /content/drive/MyDrive/semeval_data/results/ablation/greedy_trajectory_xlnet_clarity.csv\n",
            "\n",
            "================================================================================\n",
            "TASK: EVASION - GREEDY FORWARD SELECTION\n",
            "================================================================================\n",
            "  Top 5 seed features (by weighted_score):\n",
            "    1. answer_token_to_focus_strength\n",
            "       weighted_score=0.3649, mean=0.2507, best=0.8075, std=0.2541\n",
            "    2. attention_mass_q_to_a_per_qtoken\n",
            "       weighted_score=0.3623, mean=0.2492, best=0.8000, std=0.2520\n",
            "    3. attention_mass_a_to_q_per_atoken\n",
            "       weighted_score=0.3555, mean=0.2453, best=0.7967, std=0.2528\n",
            "    4. focus_token_to_answer_strength\n",
            "       weighted_score=0.3503, mean=0.2428, best=0.8083, std=0.2593\n",
            "    5. answer_content_word_ratio\n",
            "       weighted_score=0.2780, mean=0.1901, best=0.4810, std=0.1534\n",
            "\n",
            "  BERT × RandomForest:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Greedy selection:  13%|█▎        | 2/15 [00:15<01:41,  7.80s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Selected 7 features\n",
            "    Final Macro F1: 0.7961\n",
            "    Saved trajectory: /content/drive/MyDrive/semeval_data/results/ablation/greedy_trajectory_bert_evasion.csv\n",
            "\n",
            "  BERT_POLITICAL × RandomForest:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Greedy selection:  13%|█▎        | 2/15 [00:15<01:41,  7.79s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Selected 7 features\n",
            "    Final Macro F1: 0.7961\n",
            "    Saved trajectory: /content/drive/MyDrive/semeval_data/results/ablation/greedy_trajectory_bert_political_evasion.csv\n",
            "\n",
            "  BERT_AMBIGUITY × RandomForest:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Greedy selection:  13%|█▎        | 2/15 [00:15<01:42,  7.91s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Selected 7 features\n",
            "    Final Macro F1: 0.7961\n",
            "    Saved trajectory: /content/drive/MyDrive/semeval_data/results/ablation/greedy_trajectory_bert_ambiguity_evasion.csv\n",
            "\n",
            "  ROBERTA × RandomForest:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Greedy selection:   7%|▋         | 1/15 [00:10<02:32, 10.91s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Selected 6 features\n",
            "    Final Macro F1: 0.7988\n",
            "    Saved trajectory: /content/drive/MyDrive/semeval_data/results/ablation/greedy_trajectory_roberta_evasion.csv\n",
            "\n",
            "  DEBERTA × RandomForest:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Greedy selection:   7%|▋         | 1/15 [00:10<02:32, 10.91s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Selected 6 features\n",
            "    Final Macro F1: 0.7921\n",
            "    Saved trajectory: /content/drive/MyDrive/semeval_data/results/ablation/greedy_trajectory_deberta_evasion.csv\n",
            "\n",
            "  XLNET × RandomForest:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Greedy selection:   0%|          | 0/15 [00:05<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Selected 5 features\n",
            "    Final Macro F1: 0.8095\n",
            "    Saved trajectory: /content/drive/MyDrive/semeval_data/results/ablation/greedy_trajectory_xlnet_evasion.csv\n",
            "\n",
            "================================================================================\n",
            "TASK: HIERARCHICAL_EVASION_TO_CLARITY - GREEDY FORWARD SELECTION\n",
            "================================================================================\n",
            "  Top 5 seed features (by weighted_score):\n",
            "    1. answer_token_to_focus_strength\n",
            "       weighted_score=0.5676, mean=0.4151, best=0.8630, std=0.2051\n",
            "    2. focus_token_to_answer_strength\n",
            "       weighted_score=0.5670, mean=0.4159, best=0.8639, std=0.2082\n",
            "    3. attention_mass_q_to_a_per_qtoken\n",
            "       weighted_score=0.5642, mean=0.4132, best=0.8564, std=0.2052\n",
            "    4. attention_mass_a_to_q_per_atoken\n",
            "       weighted_score=0.5476, mean=0.3953, best=0.8565, std=0.2114\n",
            "    5. answer_model_token_count\n",
            "       weighted_score=0.4874, mean=0.3606, best=0.5564, std=0.1079\n",
            "\n",
            "  BERT × RandomForest:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Greedy selection:   7%|▋         | 1/15 [00:10<02:26, 10.47s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Selected 6 features\n",
            "    Final Macro F1: 0.8546\n",
            "    Saved trajectory: /content/drive/MyDrive/semeval_data/results/ablation/greedy_trajectory_bert_hierarchical_evasion_to_clarity.csv\n",
            "\n",
            "  BERT_POLITICAL × RandomForest:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Greedy selection:   7%|▋         | 1/15 [00:10<02:26, 10.45s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Selected 6 features\n",
            "    Final Macro F1: 0.8546\n",
            "    Saved trajectory: /content/drive/MyDrive/semeval_data/results/ablation/greedy_trajectory_bert_political_hierarchical_evasion_to_clarity.csv\n",
            "\n",
            "  BERT_AMBIGUITY × RandomForest:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Greedy selection:   7%|▋         | 1/15 [00:10<02:26, 10.45s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Selected 6 features\n",
            "    Final Macro F1: 0.8546\n",
            "    Saved trajectory: /content/drive/MyDrive/semeval_data/results/ablation/greedy_trajectory_bert_ambiguity_hierarchical_evasion_to_clarity.csv\n",
            "\n",
            "  ROBERTA × RandomForest:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Greedy selection:   7%|▋         | 1/15 [00:10<02:25, 10.41s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Selected 6 features\n",
            "    Final Macro F1: 0.8546\n",
            "    Saved trajectory: /content/drive/MyDrive/semeval_data/results/ablation/greedy_trajectory_roberta_hierarchical_evasion_to_clarity.csv\n",
            "\n",
            "  DEBERTA × RandomForest:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Greedy selection:  13%|█▎        | 2/15 [00:15<01:38,  7.55s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Selected 7 features\n",
            "    Final Macro F1: 0.8514\n",
            "    Saved trajectory: /content/drive/MyDrive/semeval_data/results/ablation/greedy_trajectory_deberta_hierarchical_evasion_to_clarity.csv\n",
            "\n",
            "  XLNET × RandomForest:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Greedy selection:   7%|▋         | 1/15 [00:10<02:25, 10.41s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Selected 6 features\n",
            "    Final Macro F1: 0.8644\n",
            "    Saved trajectory: /content/drive/MyDrive/semeval_data/results/ablation/greedy_trajectory_xlnet_hierarchical_evasion_to_clarity.csv\n",
            "\n",
            "================================================================================\n",
            "Saved selected features: /content/drive/MyDrive/semeval_data/results/ablation/selected_features_all.json\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "ABLATION STUDY COMPLETE\n",
            "================================================================================\n",
            "\n",
            "Summary:\n",
            "  ✓ Single-feature ablation completed\n",
            "  ✓ Feature rankings generated\n",
            "  ✓ Greedy forward selection completed\n",
            "  ✓ All results saved to Google Drive\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# GREEDY FORWARD SELECTION (OPTIONAL - FOR TOP FEATURES)\n",
        "# ============================================================================\n",
        "# Iteratively adds features that maximize Macro F1 on dev set\n",
        "# Starts with top-K features from single-feature ablation\n",
        "\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "def greedy_forward_selection(X_train, X_dev, y_train, y_dev, feature_names,\n",
        "                            seed_features, clf, max_features=None):\n",
        "    \"\"\"\n",
        "    Greedy forward selection: iteratively add best feature\n",
        "\n",
        "    Args:\n",
        "        X_train: Training features\n",
        "        X_dev: Dev features\n",
        "        y_train: Training labels\n",
        "        y_dev: Dev labels\n",
        "        feature_names: List of feature names\n",
        "        seed_features: Initial feature set (list of feature names)\n",
        "        clf: Classifier instance\n",
        "        max_features: Maximum number of features to select (None = all)\n",
        "\n",
        "    Returns:\n",
        "        selected_features: List of selected feature names\n",
        "        trajectory: List of (n_features, macro_f1) tuples\n",
        "    \"\"\"\n",
        "    # Encode labels to numeric (required for MLP, XGBoost, LightGBM)\n",
        "    # This matches the approach in siparismaili01 notebook\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "    y_dev_encoded = label_encoder.transform(y_dev)\n",
        "\n",
        "    selected_indices = [feature_names.index(f) for f in seed_features]\n",
        "    available_indices = [i for i in range(len(feature_names)) if i not in selected_indices]\n",
        "\n",
        "    trajectory = []\n",
        "\n",
        "    # Evaluate initial set\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_dev_selected = X_dev[:, selected_indices]\n",
        "\n",
        "    pipe = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"clf\", clone(clf))\n",
        "    ])\n",
        "    pipe.fit(X_train_selected, y_train_encoded)\n",
        "    pred = pipe.predict(X_dev_selected)\n",
        "    current_f1 = f1_score(y_dev_encoded, pred, average='macro')\n",
        "    trajectory.append((len(selected_indices), current_f1))\n",
        "\n",
        "    # Greedy selection\n",
        "    max_iter = max_features if max_features else len(available_indices)\n",
        "\n",
        "    for iteration in tqdm(range(max_iter), desc=\"Greedy selection\"):\n",
        "        best_f1 = current_f1\n",
        "        best_idx = None\n",
        "\n",
        "        # Try each available feature\n",
        "        for idx in available_indices:\n",
        "            candidate_indices = selected_indices + [idx]\n",
        "            X_train_candidate = X_train[:, candidate_indices]\n",
        "            X_dev_candidate = X_dev[:, candidate_indices]\n",
        "\n",
        "            pipe = Pipeline([\n",
        "                (\"scaler\", StandardScaler()),\n",
        "                (\"clf\", clone(clf))\n",
        "            ])\n",
        "            pipe.fit(X_train_candidate, y_train_encoded)\n",
        "            pred = pipe.predict(X_dev_candidate)\n",
        "            candidate_f1 = f1_score(y_dev_encoded, pred, average='macro')\n",
        "\n",
        "            if candidate_f1 > best_f1:\n",
        "                best_f1 = candidate_f1\n",
        "                best_idx = idx\n",
        "\n",
        "        # If no improvement, stop\n",
        "        if best_idx is None:\n",
        "            break\n",
        "\n",
        "        # Add best feature\n",
        "        selected_indices.append(best_idx)\n",
        "        available_indices.remove(best_idx)\n",
        "        current_f1 = best_f1\n",
        "        trajectory.append((len(selected_indices), current_f1))\n",
        "\n",
        "    selected_features = [feature_names[i] for i in selected_indices]\n",
        "    return selected_features, trajectory\n",
        "\n",
        "# Check if required variables are defined\n",
        "if 'df_stats' not in globals():\n",
        "    raise NameError(\n",
        "        \"df_stats not found. Please run Cell 6 (Feature Ranking) first.\\n\"\n",
        "        \"Cell 6 performs statistical analysis and creates df_stats DataFrame.\"\n",
        "    )\n",
        "if 'df_ablation' not in globals():\n",
        "    raise NameError(\n",
        "        \"df_ablation not found. Please run Cell 6 (Feature Ranking) first.\\n\"\n",
        "        \"Cell 6 creates df_ablation DataFrame from ablation_results.\"\n",
        "    )\n",
        "if 'TASKS' not in globals() or 'MODELS' not in globals() or 'classifiers' not in globals():\n",
        "    raise NameError(\n",
        "        \"Required variables not defined. Please run Cell 2 (Configuration) first.\"\n",
        "    )\n",
        "if 'storage' not in globals() or 'ablation_dir' not in globals():\n",
        "    raise NameError(\n",
        "        \"storage or ablation_dir not found. Please run Cell 1 (Setup) first.\"\n",
        "    )\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"GREEDY FORWARD SELECTION\")\n",
        "print(\"=\"*80)\n",
        "print(\"Starting with top-K features from weighted score ranking (Cell 6)\\n\")\n",
        "\n",
        "TOP_K_SEED = 5  # Start with top 5 features\n",
        "MAX_FEATURES = 15  # Maximum features to select\n",
        "\n",
        "selected_features_dict = {}\n",
        "greedy_trajectories = {}\n",
        "\n",
        "for task in TASKS:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"TASK: {task.upper()} - GREEDY FORWARD SELECTION\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Get top-K features for this task (from Cell 4, ranked by weighted_score)\n",
        "    df_task_stats = df_stats[df_stats['task'] == task].copy()\n",
        "\n",
        "    if len(df_task_stats) == 0:\n",
        "        print(f\"  ⚠ No ranking data found for task: {task}\")\n",
        "        continue\n",
        "\n",
        "    # Select top-K features by weighted_score\n",
        "    top_k_features = df_task_stats.head(TOP_K_SEED)['feature'].tolist()\n",
        "\n",
        "    print(f\"  Top {TOP_K_SEED} seed features (by weighted_score):\")\n",
        "    for i, feat in enumerate(top_k_features, 1):\n",
        "        row = df_task_stats[df_task_stats['feature'] == feat].iloc[0]\n",
        "        print(f\"    {i}. {feat}\")\n",
        "        print(f\"       weighted_score={row['weighted_score']:.4f}, mean={row['mean_f1']:.4f}, best={row['best_f1']:.4f}, std={row['std_f1']:.4f}\")\n",
        "\n",
        "    # Determine which task to use for loading data\n",
        "    if task == 'hierarchical_evasion_to_clarity':\n",
        "        # Hierarchical task: use evasion features but evaluate against clarity labels\n",
        "        # (hierarchical approach maps evasion predictions to clarity)\n",
        "        data_task = 'evasion'  # Use evasion features and splits\n",
        "        label_key = 'clarity_label'  # But evaluate against clarity labels\n",
        "    elif task == 'clarity':\n",
        "        data_task = 'clarity'\n",
        "        label_key = 'clarity_label'\n",
        "    else:  # evasion\n",
        "        data_task = 'evasion'\n",
        "        label_key = 'evasion_label'\n",
        "\n",
        "    # Load task-specific splits\n",
        "    train_ds = storage.load_split('train', task=data_task)\n",
        "    dev_ds = storage.load_split('dev', task=data_task)\n",
        "\n",
        "    # Extract labels\n",
        "    y_train = np.array([train_ds[i][label_key] for i in range(len(train_ds))])\n",
        "    y_dev = np.array([dev_ds[i][label_key] for i in range(len(dev_ds))])\n",
        "\n",
        "    # Get feature names directly from extraction module (same for all tasks and models)\n",
        "    # This avoids dependency on metadata files in GitHub\n",
        "    feature_names = get_feature_names()\n",
        "\n",
        "    # For each model, use the best classifier for this model×task\n",
        "    for model in MODELS:\n",
        "        try:\n",
        "            X_train = storage.load_features(model, data_task, 'train')\n",
        "            X_dev = storage.load_features(model, data_task, 'dev')\n",
        "        except FileNotFoundError:\n",
        "            print(f\"  ⚠ Features not found for {model} × {data_task}, skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Find best classifier for this model×task from ablation results\n",
        "        df_model_task = df_ablation[\n",
        "            (df_ablation['task'] == task) &\n",
        "            (df_ablation['model'] == model)\n",
        "        ]\n",
        "\n",
        "        if len(df_model_task) == 0:\n",
        "            continue\n",
        "\n",
        "        # Get best classifier (by mean F1 across all features)\n",
        "        best_clf = df_model_task.groupby('classifier')['macro_f1'].mean().idxmax()\n",
        "        clf = classifiers[best_clf]\n",
        "\n",
        "        print(f\"\\n  {model.upper()} × {best_clf}:\")\n",
        "\n",
        "        # Run greedy selection\n",
        "        selected_features, trajectory = greedy_forward_selection(\n",
        "            X_train, X_dev, y_train, y_dev,\n",
        "            feature_names, top_k_features, clf,\n",
        "            max_features=MAX_FEATURES\n",
        "        )\n",
        "\n",
        "        selected_features_dict[f\"{model}_{task}\"] = {\n",
        "            'model': model,\n",
        "            'task': task,\n",
        "            'classifier': best_clf,\n",
        "            'selected_features': selected_features,\n",
        "            'n_features': len(selected_features)\n",
        "        }\n",
        "\n",
        "        greedy_trajectories[f\"{model}_{task}\"] = trajectory\n",
        "\n",
        "        print(f\"    Selected {len(selected_features)} features\")\n",
        "        print(f\"    Final Macro F1: {trajectory[-1][1]:.4f}\")\n",
        "\n",
        "        # Save trajectory\n",
        "        df_traj = pd.DataFrame(trajectory, columns=['n_features', 'macro_f1'])\n",
        "        csv_path = ablation_dir / f'greedy_trajectory_{model}_{task}.csv'\n",
        "        df_traj.to_csv(csv_path, index=False)\n",
        "        print(f\"    Saved trajectory: {csv_path}\")\n",
        "\n",
        "# Save selected features\n",
        "if selected_features_dict:\n",
        "    json_path = ablation_dir / 'selected_features_all.json'\n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump(selected_features_dict, f, indent=2)\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Saved selected features: {json_path}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ABLATION STUDY COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nSummary:\")\n",
        "print(\"  ✓ Single-feature ablation completed\")\n",
        "print(\"  ✓ Feature rankings generated\")\n",
        "print(\"  ✓ Greedy forward selection completed\")\n",
        "print(\"  ✓ All results saved to Google Drive\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAtARjpUvUsB",
        "outputId": "dfc0284b-9b84-4f1f-e232-ed26786171d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SAVING ABLATION RESULTS TO PERSISTENT STORAGE\n",
            "================================================================================\n",
            "Note: Existing files will NOT be overwritten\n",
            "\n",
            "1. Saving ablation_results (raw data) to JSON...\n",
            "  Saved to Drive: /content/drive/MyDrive/semeval_data/results/ablation/ablation_results_clarity.json (684 evaluations)\n",
            "  Saved to GitHub: /content/semeval-context-tree-modular/results/ablation/ablation_results_clarity.json\n",
            "  Saved to Drive: /content/drive/MyDrive/semeval_data/results/ablation/ablation_results_evasion.json (684 evaluations)\n",
            "  Saved to GitHub: /content/semeval-context-tree-modular/results/ablation/ablation_results_evasion.json\n",
            "  Saved to Drive: /content/drive/MyDrive/semeval_data/results/ablation/ablation_results_hierarchical_evasion_to_clarity.json (684 evaluations)\n",
            "  Saved to GitHub: /content/semeval-context-tree-modular/results/ablation/ablation_results_hierarchical_evasion_to_clarity.json\n",
            "\n",
            "2. Saving df_ablation (all ablation results) to CSV...\n",
            "  Saved to Drive: /content/drive/MyDrive/semeval_data/results/ablation/ablation_results_all.csv (2052 rows)\n",
            "  Saved to GitHub: /content/semeval-context-tree-modular/results/ablation/ablation_results_all.csv\n",
            "\n",
            "3. Saving df_stats (feature statistics) to CSV...\n",
            "  Saved to Drive: /content/drive/MyDrive/semeval_data/results/ablation/feature_stats_all.csv (57 rows)\n",
            "  Saved to GitHub: /content/semeval-context-tree-modular/results/ablation/feature_stats_all.csv\n",
            "\n",
            "4. Copying selected_features_for_early_fusion.json to GitHub...\n",
            "  Saved to GitHub: /content/semeval-context-tree-modular/results/ablation/selected_features_for_early_fusion.json (copied from Drive)\n",
            "\n",
            "================================================================================\n",
            "ABLATION RESULTS SAVED TO PERSISTENT STORAGE\n",
            "================================================================================\n",
            "\n",
            "Summary:\n",
            "  - New files saved to Drive + GitHub\n",
            "  - Existing files skipped (not overwritten)\n",
            "\n",
            "Saved files:\n",
            "  - ablation_results_{task}.json -> Drive + GitHub (if new)\n",
            "  - ablation_results_all.csv -> Drive + GitHub (if new)\n",
            "  - feature_stats_all.csv -> Drive + GitHub (if new)\n",
            "  - selected_features_for_early_fusion.json -> GitHub (if new)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# SAVE ABLATION RESULTS TO BOTH DRIVE AND GITHUB\n",
        "# ============================================================================\n",
        "# Save memory-resident data (ablation_results, df_ablation, df_stats) to\n",
        "# both Google Drive and GitHub for persistence and version control\n",
        "# Only saves if files don't already exist (prevents overwriting)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SAVING ABLATION RESULTS TO PERSISTENT STORAGE\")\n",
        "print(\"=\"*80)\n",
        "print(\"Note: Existing files will NOT be overwritten\\n\")\n",
        "\n",
        "# Create GitHub results/ablation directory (if not exists)\n",
        "github_ablation_dir = BASE_PATH / 'results' / 'ablation'\n",
        "github_ablation_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1. Save ablation_results as JSON (both GitHub and Drive)\n",
        "print(\"1. Saving ablation_results (raw data) to JSON...\")\n",
        "for task in TASKS:\n",
        "    task_results = [r for r in ablation_results if r['task'] == task]\n",
        "    if task_results:\n",
        "        # Save to Drive (only if not exists)\n",
        "        json_path_drive = ablation_dir / f'ablation_results_{task}.json'\n",
        "        if not json_path_drive.exists():\n",
        "            with open(json_path_drive, 'w') as f:\n",
        "                json.dump(task_results, f, indent=2)\n",
        "            print(f\"  Saved to Drive: {json_path_drive} ({len(task_results)} evaluations)\")\n",
        "        else:\n",
        "            print(f\"  Skipped (Drive): {json_path_drive} (already exists)\")\n",
        "\n",
        "        # Save to GitHub (only if not exists)\n",
        "        json_path_github = github_ablation_dir / f'ablation_results_{task}.json'\n",
        "        if not json_path_github.exists():\n",
        "            with open(json_path_github, 'w') as f:\n",
        "                json.dump(task_results, f, indent=2)\n",
        "            print(f\"  Saved to GitHub: {json_path_github}\")\n",
        "        else:\n",
        "            print(f\"  Skipped (GitHub): {json_path_github} (already exists)\")\n",
        "\n",
        "# 2. Save df_ablation as CSV (both GitHub and Drive)\n",
        "print(\"\\n2. Saving df_ablation (all ablation results) to CSV...\")\n",
        "csv_path_drive = ablation_dir / 'ablation_results_all.csv'\n",
        "if not csv_path_drive.exists():\n",
        "    df_ablation.to_csv(csv_path_drive, index=False)\n",
        "    print(f\"  Saved to Drive: {csv_path_drive} ({len(df_ablation)} rows)\")\n",
        "else:\n",
        "    print(f\"  Skipped (Drive): {csv_path_drive} (already exists)\")\n",
        "\n",
        "csv_path_github = github_ablation_dir / 'ablation_results_all.csv'\n",
        "if not csv_path_github.exists():\n",
        "    df_ablation.to_csv(csv_path_github, index=False)\n",
        "    print(f\"  Saved to GitHub: {csv_path_github}\")\n",
        "else:\n",
        "    print(f\"  Skipped (GitHub): {csv_path_github} (already exists)\")\n",
        "\n",
        "# 3. Save df_stats as CSV (both GitHub and Drive)\n",
        "print(\"\\n3. Saving df_stats (feature statistics) to CSV...\")\n",
        "csv_path_drive = ablation_dir / 'feature_stats_all.csv'\n",
        "if not csv_path_drive.exists():\n",
        "    df_stats.to_csv(csv_path_drive, index=False)\n",
        "    print(f\"  Saved to Drive: {csv_path_drive} ({len(df_stats)} rows)\")\n",
        "else:\n",
        "    print(f\"  Skipped (Drive): {csv_path_drive} (already exists)\")\n",
        "\n",
        "csv_path_github = github_ablation_dir / 'feature_stats_all.csv'\n",
        "if not csv_path_github.exists():\n",
        "    df_stats.to_csv(csv_path_github, index=False)\n",
        "    print(f\"  Saved to GitHub: {csv_path_github}\")\n",
        "else:\n",
        "    print(f\"  Skipped (GitHub): {csv_path_github} (already exists)\")\n",
        "\n",
        "# 4. Also save selected_features_for_early_fusion.json to GitHub (only if not exists)\n",
        "print(\"\\n4. Copying selected_features_for_early_fusion.json to GitHub...\")\n",
        "fusion_json_github = github_ablation_dir / 'selected_features_for_early_fusion.json'\n",
        "fusion_json_drive = ablation_dir / 'selected_features_for_early_fusion.json'\n",
        "if fusion_json_drive.exists():\n",
        "    if not fusion_json_github.exists():\n",
        "        import shutil\n",
        "        shutil.copy(fusion_json_drive, fusion_json_github)\n",
        "        print(f\"  Saved to GitHub: {fusion_json_github} (copied from Drive)\")\n",
        "    else:\n",
        "        print(f\"  Skipped (GitHub): {fusion_json_github} (already exists)\")\n",
        "else:\n",
        "    print(f\"  Warning: Not found in Drive: {fusion_json_drive}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ABLATION RESULTS SAVED TO PERSISTENT STORAGE\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nSummary:\")\n",
        "print(\"  - New files saved to Drive + GitHub\")\n",
        "print(\"  - Existing files skipped (not overwritten)\")\n",
        "print(\"\\nSaved files:\")\n",
        "print(\"  - ablation_results_{task}.json -> Drive + GitHub (if new)\")\n",
        "print(\"  - ablation_results_all.csv -> Drive + GitHub (if new)\")\n",
        "print(\"  - feature_stats_all.csv -> Drive + GitHub (if new)\")\n",
        "print(\"  - selected_features_for_early_fusion.json -> GitHub (if new)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26XIGjRjwHqX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "H100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a16f0ba0eb142d08195828d9637ac90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1781ffaadfe7409eb86e5994ac53a050": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b92edb0584e34267a7f7bd1231be0407",
            "max": 3448,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7bba2d336b384b26a8e7b01389e888d1",
            "value": 3448
          }
        },
        "2623523db15e493cbc5409988c48cdb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0d4b42e91924177961a506255d3aef0",
            "placeholder": "​",
            "style": "IPY_MODEL_b36ea57888f746dbad806a989627d337",
            "value": " 3448/3448 [00:00&lt;00:00, 51243.93 examples/s]"
          }
        },
        "2c09e45fe43f43c2b4a8c794750ea7a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "363b2c98af3444dfb6467de3598398d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37183fa1dc8b4043a66d9f2d8fd7516d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38528e129cbd45ce91cea03e6e5953bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38fe52bb09f94075ac9bfbbe45bb02da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d193e338cc7545a6b202447c364988c3",
              "IPY_MODEL_39e5dca4040742ac8a89b237d2303ced",
              "IPY_MODEL_e30e385fed6e4c4db6fa8bda5707d5f5"
            ],
            "layout": "IPY_MODEL_363b2c98af3444dfb6467de3598398d4"
          }
        },
        "39e5dca4040742ac8a89b237d2303ced": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c09e45fe43f43c2b4a8c794750ea7a2",
            "max": 258928,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d8e076c6bcc4a0d900e1cad531c40c7",
            "value": 258928
          }
        },
        "3a4e85d2bac243b9b57fb2fecfbcec1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f635f3e0e6244aaa863a9646086b211": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42a79d6f8882465fa9866b15eb9ce81e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43ef14ff1b7b4d39b52ffeef01c9011b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96064cb2673d4bf1bd9a0ff01ff63205",
            "max": 3898012,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_84302eb33b7840f7bf8d20ad5c589ea5",
            "value": 3898012
          }
        },
        "499dee00f2644f92bb6817af99746dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4be75f7853454c25a9214ebfa6137b4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f298e6707d4f495eb121e1c573140113",
            "placeholder": "​",
            "style": "IPY_MODEL_7edc7ebb30714b05816a3703c9490280",
            "value": " 308/308 [00:00&lt;00:00, 19212.17 examples/s]"
          }
        },
        "4d8e076c6bcc4a0d900e1cad531c40c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "555a88e30a5c4e9196095efe4c0b4ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61cd2983714c4de19e23cf0ebccf3bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcbb1ee8eb6f4ce48180e7a997b6cc38",
            "placeholder": "​",
            "style": "IPY_MODEL_555a88e30a5c4e9196095efe4c0b4ea0",
            "value": "data/train-00000-of-00001.parquet: 100%"
          }
        },
        "6719a3c49bf943298038c62ce33a4f4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70112c968462433d9e35ad5737687681": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73bba36cddd94a9e91afa76bd2b44970": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8466fbb6b29d4494aac001d28921d712",
              "IPY_MODEL_1781ffaadfe7409eb86e5994ac53a050",
              "IPY_MODEL_2623523db15e493cbc5409988c48cdb1"
            ],
            "layout": "IPY_MODEL_37183fa1dc8b4043a66d9f2d8fd7516d"
          }
        },
        "7bba2d336b384b26a8e7b01389e888d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7edc7ebb30714b05816a3703c9490280": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84302eb33b7840f7bf8d20ad5c589ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8466fbb6b29d4494aac001d28921d712": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfc331f6108848e8b1acf8a51f58d055",
            "placeholder": "​",
            "style": "IPY_MODEL_dad466652e174de2b33098b626ccf317",
            "value": "Generating train split: 100%"
          }
        },
        "888169b663534d01987d3c09cd72a9b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e64f3172842544deadba8c61a536475a",
              "IPY_MODEL_e09f13b47ee84c6eae1040ba99fd8a1a",
              "IPY_MODEL_4be75f7853454c25a9214ebfa6137b4c"
            ],
            "layout": "IPY_MODEL_fc711d7141644d868b3329c366d2f81f"
          }
        },
        "8f16a3198e974ab2bfe791079dfd9b3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42a79d6f8882465fa9866b15eb9ce81e",
            "placeholder": "​",
            "style": "IPY_MODEL_a336a14b773b4d95b9162e47df6f22e5",
            "value": " 3.90M/3.90M [00:00&lt;00:00, 6.51MB/s]"
          }
        },
        "96064cb2673d4bf1bd9a0ff01ff63205": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a336a14b773b4d95b9162e47df6f22e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b253cbbdafca452bae08b726aa097657": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b36ea57888f746dbad806a989627d337": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b92edb0584e34267a7f7bd1231be0407": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfc331f6108848e8b1acf8a51f58d055": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0d4b42e91924177961a506255d3aef0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d193e338cc7545a6b202447c364988c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f635f3e0e6244aaa863a9646086b211",
            "placeholder": "​",
            "style": "IPY_MODEL_6719a3c49bf943298038c62ce33a4f4d",
            "value": "data/test-00000-of-00001.parquet: 100%"
          }
        },
        "dad466652e174de2b33098b626ccf317": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcbb1ee8eb6f4ce48180e7a997b6cc38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e09f13b47ee84c6eae1040ba99fd8a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b253cbbdafca452bae08b726aa097657",
            "max": 308,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a16f0ba0eb142d08195828d9637ac90",
            "value": 308
          }
        },
        "e30e385fed6e4c4db6fa8bda5707d5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a4e85d2bac243b9b57fb2fecfbcec1a",
            "placeholder": "​",
            "style": "IPY_MODEL_70112c968462433d9e35ad5737687681",
            "value": " 259k/259k [00:00&lt;00:00, 842kB/s]"
          }
        },
        "e48f0ffb0d204099a9c857376aaea2a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e64f3172842544deadba8c61a536475a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e48f0ffb0d204099a9c857376aaea2a1",
            "placeholder": "​",
            "style": "IPY_MODEL_499dee00f2644f92bb6817af99746dac",
            "value": "Generating test split: 100%"
          }
        },
        "e87290c65ab341028cc46efa061dd92e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61cd2983714c4de19e23cf0ebccf3bf7",
              "IPY_MODEL_43ef14ff1b7b4d39b52ffeef01c9011b",
              "IPY_MODEL_8f16a3198e974ab2bfe791079dfd9b3b"
            ],
            "layout": "IPY_MODEL_38528e129cbd45ce91cea03e6e5953bc"
          }
        },
        "f298e6707d4f495eb121e1c573140113": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc711d7141644d868b3329c366d2f81f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
