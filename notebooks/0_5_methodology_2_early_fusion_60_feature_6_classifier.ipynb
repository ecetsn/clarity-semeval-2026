{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100",
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "595a6f4c1cf64ca6ad22da4c5523cbb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_883db3b211d841818ab6512ce56f9bc6",
       "IPY_MODEL_423a35617b304a3aaa7d57da3e7da660",
       "IPY_MODEL_10a5bc0fd4854e1785950d6ac38cd135"
      ],
      "layout": "IPY_MODEL_24a1c963bd9b4ad295732471ea8b4914"
     }
    },
    "883db3b211d841818ab6512ce56f9bc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d528cd9cb02426f9e9bc47f0e6ee1d8",
      "placeholder": "​",
      "style": "IPY_MODEL_877eaa49e8894e548346de241fe77761",
      "value": "config.json: 100%"
     }
    },
    "423a35617b304a3aaa7d57da3e7da660": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5831fb88481340a689b2078d736857f3",
      "max": 929,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dc6c350903c34fcf8adf8a1b14ca3d0b",
      "value": 929
     }
    },
    "10a5bc0fd4854e1785950d6ac38cd135": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07abeb03ae514b62a6e79bfa401605cf",
      "placeholder": "​",
      "style": "IPY_MODEL_1873891befbf41abb88dbfb049abb56a",
      "value": " 929/929 [00:00&lt;00:00, 125kB/s]"
     }
    },
    "24a1c963bd9b4ad295732471ea8b4914": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d528cd9cb02426f9e9bc47f0e6ee1d8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "877eaa49e8894e548346de241fe77761": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5831fb88481340a689b2078d736857f3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc6c350903c34fcf8adf8a1b14ca3d0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "07abeb03ae514b62a6e79bfa401605cf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1873891befbf41abb88dbfb049abb56a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c84ffb9c1f3840a68ac10f67229afbc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0483de4d60464457a2e241bbb8409c07",
       "IPY_MODEL_8851926b5be244648026ad629c08feb5",
       "IPY_MODEL_18eee26ddd9542c99d62c610bc4d9317"
      ],
      "layout": "IPY_MODEL_8170b7ca271a41069e1c3c3a3165eb59"
     }
    },
    "0483de4d60464457a2e241bbb8409c07": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8130cf37e09496da725d625f99ed33c",
      "placeholder": "​",
      "style": "IPY_MODEL_62b57c476fce4736943394f584bbd134",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "8851926b5be244648026ad629c08feb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2bf03b46f5b4380a93f8fe42dc8d010",
      "max": 501045531,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_997af15b332e42fdae49e20d2f2337e2",
      "value": 501045531
     }
    },
    "18eee26ddd9542c99d62c610bc4d9317": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e437e038a46849ff9df089819f937fde",
      "placeholder": "​",
      "style": "IPY_MODEL_73f648703abb482987d3b67f022a4101",
      "value": " 501M/501M [00:01&lt;00:00, 643MB/s]"
     }
    },
    "8170b7ca271a41069e1c3c3a3165eb59": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8130cf37e09496da725d625f99ed33c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62b57c476fce4736943394f584bbd134": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f2bf03b46f5b4380a93f8fe42dc8d010": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "997af15b332e42fdae49e20d2f2337e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e437e038a46849ff9df089819f937fde": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73f648703abb482987d3b67f022a4101": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f26dc19eb50b4cbda31e098215320a07": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e8192601aba7496f893fab4da34169c4",
       "IPY_MODEL_8f01f8574c8d44f08f14745d7712eef6",
       "IPY_MODEL_5e5e2b06348c4b2f9cac3e3af1b91199"
      ],
      "layout": "IPY_MODEL_b0870904fac94923a4c5a48f5a8e27b5"
     }
    },
    "e8192601aba7496f893fab4da34169c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e47a74d35be49609a20222ae994f303",
      "placeholder": "​",
      "style": "IPY_MODEL_fa4d0bf9ca574338970ba583446b12d9",
      "value": "vocab.json: "
     }
    },
    "8f01f8574c8d44f08f14745d7712eef6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d77570bb82b04af4ad6ffceb51084f9c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ff4a85b3b2164963bee1f4d3f9672558",
      "value": 1
     }
    },
    "5e5e2b06348c4b2f9cac3e3af1b91199": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_139a7bd24bee4dff881af342c62225fe",
      "placeholder": "​",
      "style": "IPY_MODEL_7f1f5635f89247c7b6f2aa7dd633fd82",
      "value": " 899k/? [00:00&lt;00:00, 29.6MB/s]"
     }
    },
    "b0870904fac94923a4c5a48f5a8e27b5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e47a74d35be49609a20222ae994f303": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa4d0bf9ca574338970ba583446b12d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d77570bb82b04af4ad6ffceb51084f9c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "ff4a85b3b2164963bee1f4d3f9672558": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "139a7bd24bee4dff881af342c62225fe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f1f5635f89247c7b6f2aa7dd633fd82": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "376f0c724feb4eaab2c18c00f55e54e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6024a5a1c5924736b96f91abdf70ee58",
       "IPY_MODEL_740bd74b66b24901a64bf1194b8074b4",
       "IPY_MODEL_89387f802dca4e539a6d8a6711235109"
      ],
      "layout": "IPY_MODEL_fce28a5248384edf9ee692d3f3c13233"
     }
    },
    "6024a5a1c5924736b96f91abdf70ee58": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcdb78f17b1c45568b42417da71e44a2",
      "placeholder": "​",
      "style": "IPY_MODEL_e989ad22bd404eb59faaa8f6f5030b69",
      "value": "model.safetensors: 100%"
     }
    },
    "740bd74b66b24901a64bf1194b8074b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b9a308b8b5b4eb69621582e549d389e",
      "max": 500982668,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_38998247c0ef4edabab14aeddc98c5c7",
      "value": 500982668
     }
    },
    "89387f802dca4e539a6d8a6711235109": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_270509501a50407a931b5baf15a79af7",
      "placeholder": "​",
      "style": "IPY_MODEL_7cfee1d0f8ff462da5acea38999220e8",
      "value": " 501M/501M [00:01&lt;00:00, 350MB/s]"
     }
    },
    "fce28a5248384edf9ee692d3f3c13233": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcdb78f17b1c45568b42417da71e44a2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e989ad22bd404eb59faaa8f6f5030b69": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b9a308b8b5b4eb69621582e549d389e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38998247c0ef4edabab14aeddc98c5c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "270509501a50407a931b5baf15a79af7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7cfee1d0f8ff462da5acea38999220e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58db8a9d25db43fcad21b91aeb2b7bab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_740fd78f33944b96b5785d64386a183a",
       "IPY_MODEL_d5136317d2b642eb9273fc849441a39a",
       "IPY_MODEL_f1a1a102985b431cb0793d5d11dc96f0"
      ],
      "layout": "IPY_MODEL_17a728013ae447ef976740e652df274a"
     }
    },
    "740fd78f33944b96b5785d64386a183a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a456764f3e4f46d1821125b99a76458c",
      "placeholder": "​",
      "style": "IPY_MODEL_7608d9b823b247dfbf93d0913f4aa8dc",
      "value": "merges.txt: "
     }
    },
    "d5136317d2b642eb9273fc849441a39a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e4734693f9a499db8f34c17e021ccd1",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ff76a1e539aa4beba070f4e96a419e16",
      "value": 1
     }
    },
    "f1a1a102985b431cb0793d5d11dc96f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b691b567d1e04343b6539fbb2cfc682a",
      "placeholder": "​",
      "style": "IPY_MODEL_8f3cb10e87034a478ec9824071d4b28f",
      "value": " 456k/? [00:00&lt;00:00, 35.0MB/s]"
     }
    },
    "17a728013ae447ef976740e652df274a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a456764f3e4f46d1821125b99a76458c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7608d9b823b247dfbf93d0913f4aa8dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e4734693f9a499db8f34c17e021ccd1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "ff76a1e539aa4beba070f4e96a419e16": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b691b567d1e04343b6539fbb2cfc682a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f3cb10e87034a478ec9824071d4b28f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "24a728d83b6e48e1a059bdfaa5d68fbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_40d353797e2248f6a62456ec75cc0da0",
       "IPY_MODEL_3e3ea2b2bea7432fae3d7b767976e0ad",
       "IPY_MODEL_40af848de66d43e082d7c279948651fc"
      ],
      "layout": "IPY_MODEL_6a7af5056677440eb34bce9658ee3c96"
     }
    },
    "40d353797e2248f6a62456ec75cc0da0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_682add40bea74677b90e7a0ab3be5b8e",
      "placeholder": "​",
      "style": "IPY_MODEL_4af5771259004b64887de995813bf51f",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "3e3ea2b2bea7432fae3d7b767976e0ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_daa2b6af03de40f0ad5c13b5f2555801",
      "max": 239,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_33006c8a2f244b0aad981e2da7c8d4a5",
      "value": 239
     }
    },
    "40af848de66d43e082d7c279948651fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93f8b65aea4e4dcf9419f7d61acd1d71",
      "placeholder": "​",
      "style": "IPY_MODEL_c100461e14ac42c88d7594cb2f8b56d4",
      "value": " 239/239 [00:00&lt;00:00, 33.1kB/s]"
     }
    },
    "6a7af5056677440eb34bce9658ee3c96": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "682add40bea74677b90e7a0ab3be5b8e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4af5771259004b64887de995813bf51f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "daa2b6af03de40f0ad5c13b5f2555801": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33006c8a2f244b0aad981e2da7c8d4a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "93f8b65aea4e4dcf9419f7d61acd1d71": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c100461e14ac42c88d7594cb2f8b56d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kNByhMnJy7a5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "282fb25d-c897-4a7f-86a8-6a5437bd2660"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "================================================================================\n",
      "STEP 0: CLEANING CACHE (GitHub + PyTorch)\n",
      "================================================================================\n",
      "  ✓ No old repository found (clean state)\n",
      "\n",
      "Cleaning Python import cache...\n",
      "\n",
      "Reinstalling PyTorch to fix potential import errors...\n",
      "  ✓ Uninstalled old PyTorch\n",
      "  ✓ Reinstalled PyTorch with CUDA support\n",
      "\n",
      "✓ Cache cleaning complete\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "STEP 1: CLONING REPOSITORY FROM GITHUB\n",
      "================================================================================\n",
      "Cloning repository from GitHub...\n",
      "  ✓ Repository cloned successfully via git\n",
      "\n",
      "================================================================================\n",
      "STEP 2: MOUNTING GOOGLE DRIVE\n",
      "================================================================================\n",
      "Mounted at /content/drive\n",
      "  ✓ Google Drive mounted\n",
      "\n",
      "================================================================================\n",
      "STEP 3: CONFIGURING PATHS AND VERIFYING REPOSITORY\n",
      "================================================================================\n",
      "  ✓ Repository structure verified\n",
      "  ✓ Repository added to Python path\n",
      "\n",
      "================================================================================\n",
      "STEP 4: IMPORTING MODULES AND INITIALIZING\n",
      "================================================================================\n",
      "  ✓ StorageManager imported\n",
      "  ✓ fuse_attention_features imported\n",
      "  ✓ get_classifier_dict imported\n",
      "  ✓ StorageManager initialized\n",
      "\n",
      "================================================================================\n",
      "SETUP COMPLETE\n",
      "================================================================================\n",
      "  Repository: /content/semeval-context-tree-modular\n",
      "  Data storage: /content/drive/MyDrive/semeval_data\n",
      "\n",
      "NOTE: Data splits will be loaded per-task (task-specific splits)\n",
      "      Clarity and Evasion have different splits due to majority voting\n"
     ]
    }
   ],
   "source": [
    "# STEP 1\n",
    "# ==============\n",
    "# ============================================================================\n",
    "# SETUP: Repository Clone, Drive Mount, and Path Configuration\n",
    "# ============================================================================\n",
    "# This cell performs minimal setup required for the notebook to run:\n",
    "# 1. Cleans GitHub cache (removes old repository to ensure fresh clone)\n",
    "# 2. Cleans PyTorch cache (fixes import errors)\n",
    "# 3. Clones repository from GitHub (if not already present)\n",
    "# 4. Mounts Google Drive for persistent data storage\n",
    "# 5. Configures Python paths and initializes StorageManager\n",
    "# 6. Loads data splits and features created in previous notebooks\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import zipfile\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from google.colab import drive\n",
    "import numpy as np\n",
    "\n",
    "# ========================================================================\n",
    "# STEP 0: Clean GitHub and PyTorch Cache (Ensure Fresh Environment)\n",
    "# ========================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 0: CLEANING CACHE (GitHub + PyTorch)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "repo_dir = '/content/semeval-context-tree-modular'\n",
    "\n",
    "# Remove old repository if exists (ensures fresh clone)\n",
    "if os.path.exists(repo_dir):\n",
    "    print(f\"Removing old repository: {repo_dir}\")\n",
    "    try:\n",
    "        shutil.rmtree(repo_dir)\n",
    "        print(\"  ✓ Old repository removed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Warning: Could not remove old repository: {e}\")\n",
    "        try:\n",
    "            subprocess.run(['rm', '-rf', repo_dir], check=True, timeout=10)\n",
    "            print(\"  ✓ Old repository removed via subprocess\")\n",
    "        except Exception as e2:\n",
    "            print(f\"   Warning: Alternative removal also failed: {e2}\")\n",
    "else:\n",
    "    print(\"  ✓ No old repository found (clean state)\")\n",
    "\n",
    "# Clean Python import cache (remove cached modules)\n",
    "print(\"\\nCleaning Python import cache...\")\n",
    "modules_to_remove = [key for key in list(sys.modules.keys()) if key.startswith('src.') or key.startswith('torch')]\n",
    "if modules_to_remove:\n",
    "    for module_name in modules_to_remove:\n",
    "        try:\n",
    "            del sys.modules[module_name]\n",
    "        except:\n",
    "            pass\n",
    "    print(f\"  ✓ Removed {len(modules_to_remove)} cached modules (src.* and torch.*)\")\n",
    "\n",
    "# Remove __pycache__ directories\n",
    "import glob\n",
    "pycache_dirs = glob.glob('/content/**/__pycache__', recursive=True)\n",
    "if pycache_dirs:\n",
    "    for pycache_dir in pycache_dirs:\n",
    "        try:\n",
    "            shutil.rmtree(pycache_dir)\n",
    "        except:\n",
    "            pass\n",
    "    print(f\"  ✓ Cleaned {len(pycache_dirs)} __pycache__ directories\")\n",
    "\n",
    "# CRITICAL: Reinstall PyTorch to fix \"ValueError: module functions cannot set METH_CLASS or METH_STATIC\"\n",
    "print(\"\\nReinstalling PyTorch to fix potential import errors...\")\n",
    "try:\n",
    "    # Uninstall PyTorch first\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', 'torch', 'torchvision', 'torchaudio'],\n",
    "                   capture_output=True, timeout=30)\n",
    "    print(\"  ✓ Uninstalled old PyTorch\")\n",
    "\n",
    "    # Reinstall PyTorch (with CUDA support for Colab)\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'torch', 'torchvision', 'torchaudio', '--index-url',\n",
    "                    'https://download.pytorch.org/whl/cu118'],\n",
    "                   capture_output=True, timeout=120)\n",
    "    print(\"  ✓ Reinstalled PyTorch with CUDA support\")\n",
    "except Exception as e:\n",
    "    print(f\"   Warning: PyTorch reinstall failed: {e}\")\n",
    "    print(\"  Continuing anyway (may cause issues if PyTorch is corrupted)\")\n",
    "\n",
    "print(\"\\n✓ Cache cleaning complete\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ========================================================================\n",
    "# STEP 1: Clone Repository from GitHub\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: CLONING REPOSITORY FROM GITHUB\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Repository configuration\n",
    "repo_url = 'https://github.com/EonTechie/semeval-context-tree-modular.git'\n",
    "zip_url = 'https://github.com/EonTechie/semeval-context-tree-modular/archive/refs/heads/main.zip'\n",
    "\n",
    "# Clone repository (fresh clone after cache cleaning)\n",
    "print(\"Cloning repository from GitHub...\")\n",
    "max_retries = 2\n",
    "clone_success = False\n",
    "\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['git', 'clone', repo_url],\n",
    "            cwd='/content',\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=60\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            print(\"  ✓ Repository cloned successfully via git\")\n",
    "            clone_success = True\n",
    "            break\n",
    "        else:\n",
    "            print(f\"   Git clone attempt {attempt + 1} failed: {result.stderr[:200]}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(3)\n",
    "    except Exception as e:\n",
    "        print(f\"   Git clone attempt {attempt + 1} exception: {str(e)[:200]}\")\n",
    "        if attempt < max_retries - 1:\n",
    "            time.sleep(3)\n",
    "\n",
    "# Fallback: Download as ZIP if git clone fails\n",
    "if not clone_success:\n",
    "    print(\"\\nGit clone failed. Downloading repository as ZIP archive...\")\n",
    "    zip_path = '/tmp/repo.zip'\n",
    "    try:\n",
    "        response = requests.get(zip_url, stream=True, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        with open(zip_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall('/content')\n",
    "        extracted_dir = '/content/semeval-context-tree-modular-main'\n",
    "        if os.path.exists(extracted_dir):\n",
    "            os.rename(extracted_dir, repo_dir)\n",
    "        os.remove(zip_path)\n",
    "        print(\"  ✓ Repository downloaded and extracted successfully\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to obtain repository: {e}\")\n",
    "\n",
    "# ========================================================================\n",
    "# STEP 2: Mount Google Drive\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: MOUNTING GOOGLE DRIVE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Mount Google Drive (if not already mounted)\n",
    "try:\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "    print(\"  ✓ Google Drive mounted\")\n",
    "except Exception:\n",
    "    print(\"  ✓ Google Drive already mounted\")\n",
    "    pass  # Already mounted\n",
    "\n",
    "# ========================================================================\n",
    "# STEP 3: Configure Paths and Verify Repository\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: CONFIGURING PATHS AND VERIFYING REPOSITORY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Configure paths\n",
    "BASE_PATH = Path('/content/semeval-context-tree-modular')\n",
    "DATA_PATH = Path('/content/drive/MyDrive/semeval_data')\n",
    "\n",
    "# Verify repository structure exists\n",
    "if not BASE_PATH.exists():\n",
    "    raise RuntimeError(f\"Repository directory not found: {BASE_PATH}\")\n",
    "if not (BASE_PATH / 'src').exists():\n",
    "    raise RuntimeError(f\"src directory not found in repository: {BASE_PATH / 'src'}\")\n",
    "if not (BASE_PATH / 'src' / 'storage' / 'manager.py').exists():\n",
    "    raise RuntimeError(f\"Required file not found: {BASE_PATH / 'src' / 'storage' / 'manager.py'}\")\n",
    "\n",
    "print(\"  ✓ Repository structure verified\")\n",
    "\n",
    "# Add repository to Python path\n",
    "sys.path.insert(0, str(BASE_PATH))\n",
    "print(\"  ✓ Repository added to Python path\")\n",
    "\n",
    "# ========================================================================\n",
    "# STEP 4: Import and Initialize (with error handling for PyTorch)\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: IMPORTING MODULES AND INITIALIZING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verify imports work (with PyTorch error handling)\n",
    "try:\n",
    "    from src.storage.manager import StorageManager\n",
    "    print(\"  ✓ StorageManager imported\")\n",
    "except Exception as e:\n",
    "    raise ImportError(f\"Failed to import StorageManager: {e}\")\n",
    "\n",
    "try:\n",
    "    from src.features.fusion import fuse_attention_features\n",
    "    print(\"  ✓ fuse_attention_features imported\")\n",
    "except Exception as e:\n",
    "    if \"METH_CLASS\" in str(e) or \"METH_STATIC\" in str(e) or \"torch._C\" in str(e):\n",
    "        print(f\"   PyTorch import error detected: {e}\")\n",
    "        print(\"  SOLUTION: Please restart runtime (Runtime → Restart runtime)\")\n",
    "        print(\"  Then run this cell again.\")\n",
    "        raise RuntimeError(\n",
    "            \"PyTorch import error. Please restart runtime and try again.\\n\"\n",
    "            \"Runtime → Restart runtime, then re-run this cell.\"\n",
    "        )\n",
    "    else:\n",
    "        raise ImportError(f\"Failed to import fuse_attention_features: {e}\")\n",
    "\n",
    "try:\n",
    "    from src.models.classifiers import get_classifier_dict\n",
    "    print(\"  ✓ get_classifier_dict imported\")\n",
    "except Exception as e:\n",
    "    raise ImportError(f\"Failed to import get_classifier_dict: {e}\")\n",
    "\n",
    "# Initialize StorageManager\n",
    "storage = StorageManager(\n",
    "    base_path=str(BASE_PATH),\n",
    "    data_path=str(DATA_PATH),\n",
    "    github_path=str(BASE_PATH)\n",
    ")\n",
    "print(\"  ✓ StorageManager initialized\")\n",
    "\n",
    "# ========================================================================\n",
    "# SETUP COMPLETE\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SETUP COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"  Repository: {BASE_PATH}\")\n",
    "print(f\"  Data storage: {DATA_PATH}\")\n",
    "print(f\"\\nNOTE: Data splits will be loaded per-task (task-specific splits)\")\n",
    "print(f\"      Clarity and Evasion have different splits due to majority voting\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 2\n",
    "# ==============\n",
    "# ============================================================================\n",
    "# REPRODUCIBILITY SETUP: Set Random Seeds for All Libraries\n",
    "# ============================================================================\n",
    "# This cell sets random seeds for Python, NumPy, PyTorch, and HuggingFace\n",
    "# to ensure reproducible results across all runs.\n",
    "#\n",
    "# IMPORTANT: Run this cell FIRST before any other code that uses randomness.\n",
    "# Seed value: 42 (same as used in all other parts of the pipeline)\n",
    "\n",
    "from src.utils.reproducibility import set_all_seeds\n",
    "\n",
    "# Set all random seeds to 42 for full reproducibility\n",
    "# deterministic=True ensures PyTorch operations are deterministic (slower but fully reproducible)\n",
    "set_all_seeds(seed=42, deterministic=True)\n",
    "\n",
    "print(\"✓ Reproducibility configured: All random seeds set to 42\")\n",
    "print(\"✓ PyTorch deterministic mode enabled\")\n",
    "print(\"\\nNOTE: If you encounter performance issues or non-deterministic behavior,\")\n",
    "print(\"      you can set deterministic=False in set_all_seeds() call above.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2MvLXxE9SqG6",
    "outputId": "53fa158d-a05d-4820-e696-78f5f077ad18"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✓ Reproducibility seeds set to 42\n",
      "✓ PyTorch deterministic mode enabled (may be slower)\n",
      "✓ Reproducibility configured: All random seeds set to 42\n",
      "✓ PyTorch deterministic mode enabled\n",
      "\n",
      "NOTE: If you encounter performance issues or non-deterministic behavior,\n",
      "      you can set deterministic=False in set_all_seeds() call above.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# STEP 3\n",
    "# ==============\n",
    "# ============================================================================\n",
    "# CONFIGURE MODELS, TASKS, AND CLASSIFIERS\n",
    "# ============================================================================\n",
    "# Defines the models to fuse, tasks to perform, and classifiers to train\n",
    "# Label mappings are defined for clarity (3-class) and evasion (9-class) tasks\n",
    "\n",
    "MODELS = ['bert', 'bert_political', 'bert_ambiguity', 'roberta', 'deberta', 'xlnet']\n",
    "TASKS = ['clarity', 'evasion']\n",
    "\n",
    "# Label mappings for each task\n",
    "CLARITY_LABELS = ['Ambivalent', 'Clear Non-Reply', 'Clear Reply']\n",
    "EVASION_LABELS = ['Claims ignorance', 'Clarification', 'Declining to answer',\n",
    "                  'Deflection', 'Dodging', 'Explicit',\n",
    "                  'General', 'Implicit', 'Partial/half-answer']\n",
    "\n",
    "# Initialize classifiers with fixed random seed for reproducibility\n",
    "classifiers = get_classifier_dict(random_state=42)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Models to fuse: {MODELS}\")\n",
    "print(f\"  Tasks: {TASKS}\")\n",
    "print(f\"  Classifiers: {list(classifiers.keys())}\")\n",
    "print(f\"  Fusion method: Early fusion (feature concatenation)\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2mPrlxP_SqJl",
    "outputId": "324bd6a7-c48c-43a3-8d62-db7b0517a2c1"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Configuration:\n",
      "  Models to fuse: ['bert', 'bert_political', 'bert_ambiguity', 'roberta', 'deberta', 'xlnet']\n",
      "  Tasks: ['clarity', 'evasion']\n",
      "  Classifiers: ['LogisticRegression', 'LinearSVC', 'RandomForest', 'MLP', 'XGBoost', 'LightGBM']\n",
      "  Fusion method: Early fusion (feature concatenation)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 4\n",
    "# ==============\n",
    "# ============================================================================\n",
    "# PERFORM EARLY FUSION - Feature Concatenation Only\n",
    "# ============================================================================\n",
    "# For each task, loads model-independent features once (18 features) and\n",
    "# model-dependent features from each model (7 features per model).\n",
    "# Concatenates: [18 Model-Independent | 6 Models × 7 Model-Dependent] = 60 features\n",
    "# Saves fused features for Train and Dev splits\n",
    "# NOTE: Training and evaluation will be done in the next cell (Cell 6) on Test set\n",
    "\n",
    "from src.features.extraction import get_model_independent_feature_names, get_model_dependent_feature_names\n",
    "\n",
    "for task in TASKS:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TASK: {task.upper()} - EARLY FUSION (60 FEATURES)\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    # Select appropriate label list and dataset key for this task\n",
    "    if task == 'clarity':\n",
    "        label_list = CLARITY_LABELS\n",
    "        label_key = 'clarity_label'\n",
    "    else:  # evasion\n",
    "        label_list = EVASION_LABELS\n",
    "        label_key = 'evasion_label'\n",
    "\n",
    "    # ========================================================================\n",
    "    # STEP 0: Check if fused features already exist (CHECKPOINT)\n",
    "    # ========================================================================\n",
    "    print(\"\\nStep 0: Checking for existing fused features (checkpoint)...\")\n",
    "    try:\n",
    "        X_train_fused_existing = storage.load_fused_features(MODELS, task, 'train')\n",
    "        X_dev_fused_existing = storage.load_fused_features(MODELS, task, 'dev')\n",
    "        print(f\"  ✓ Fused features already exist for {task}\")\n",
    "        print(f\"    Train: {X_train_fused_existing.shape[0]} samples, {X_train_fused_existing.shape[1]} features\")\n",
    "        print(f\"    Dev: {X_dev_fused_existing.shape[0]} samples, {X_dev_fused_existing.shape[1]} features\")\n",
    "        print(f\"  SKIPPING fusion (already done)\")\n",
    "        continue\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  → Fused features not found. Proceeding with fusion...\")\n",
    "        pass\n",
    "\n",
    "    # ========================================================================\n",
    "    # STEP 1: Load model-independent features (18 features, shared across all models)\n",
    "    # ========================================================================\n",
    "    print(\"\\nStep 1: Loading model-independent features (18 features, shared)...\")\n",
    "    try:\n",
    "        X_train_indep = storage.load_model_independent_features('train', task=task)\n",
    "        X_dev_indep = storage.load_model_independent_features('dev', task=task)\n",
    "        print(f\"  ✓ Loaded model-independent features: {X_train_indep.shape[1]} features\")\n",
    "        print(f\"    Train: {X_train_indep.shape[0]} samples\")\n",
    "        print(f\"    Dev: {X_dev_indep.shape[0]} samples\")\n",
    "    except FileNotFoundError as e:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Model-independent features not found for task '{task}'. \"\n",
    "            f\"Make sure you have run 02_feature_extraction_separate.ipynb first.\\n\"\n",
    "            f\"Error: {e}\"\n",
    "        )\n",
    "\n",
    "    # Get model-independent feature names\n",
    "    indep_feature_names = get_model_independent_feature_names()\n",
    "    assert len(indep_feature_names) == 18, f\"Expected 18 model-independent features, got {len(indep_feature_names)}\"\n",
    "\n",
    "    # ========================================================================\n",
    "    # STEP 2: Load full features from all models and extract model-dependent portion\n",
    "    # ========================================================================\n",
    "    print(\"\\nStep 2: Loading model-dependent features from each model (7 features per model)...\")\n",
    "    model_dep_features_train = {}\n",
    "    model_dep_features_dev = {}\n",
    "    model_dep_feature_names = {}\n",
    "\n",
    "    # Model-dependent feature names (same for all models)\n",
    "    dep_feature_names = get_model_dependent_feature_names()\n",
    "    assert len(dep_feature_names) == 7, f\"Expected 7 model-dependent features, got {len(dep_feature_names)}\"\n",
    "\n",
    "    for model in MODELS:\n",
    "        # Load full features (25 features: 7 model-dependent + 18 model-independent)\n",
    "        X_train_full = storage.load_features(model, task, 'train')\n",
    "        X_dev_full = storage.load_features(model, task, 'dev')\n",
    "\n",
    "        # Extract model-dependent portion (first 7 features)\n",
    "        # Feature order: [7 model-dependent | 18 model-independent]\n",
    "        X_train_dep = X_train_full[:, :7]  # First 7 features\n",
    "        X_dev_dep = X_dev_full[:, :7]\n",
    "\n",
    "        model_dep_features_train[model] = X_train_dep\n",
    "        model_dep_features_dev[model] = X_dev_dep\n",
    "        model_dep_feature_names[model] = [f\"{model}_{name}\" for name in dep_feature_names]\n",
    "\n",
    "        print(f\"  {model}: Extracted {X_train_dep.shape[1]} model-dependent features from {X_train_full.shape[1]} total features\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # STEP 3: Concatenate all features: [18 Model-Independent | 6 Models × 7 Model-Dependent]\n",
    "    # ========================================================================\n",
    "    print(\"\\nStep 3: Concatenating features (60 total features)...\")\n",
    "\n",
    "    # Concatenate model-dependent features from all models\n",
    "    model_dep_list_train = [model_dep_features_train[model] for model in MODELS]\n",
    "    model_dep_list_dev = [model_dep_features_dev[model] for model in MODELS]\n",
    "\n",
    "    X_train_dep_concat = np.hstack(model_dep_list_train)  # (N, 42)\n",
    "    X_dev_dep_concat = np.hstack(model_dep_list_dev)  # (N, 42)\n",
    "\n",
    "    # Final concatenation: [18 Model-Independent | 42 Model-Dependent]\n",
    "    X_train_fused = np.hstack([X_train_indep, X_train_dep_concat])  # (N, 60)\n",
    "    X_dev_fused = np.hstack([X_dev_indep, X_dev_dep_concat])  # (N, 60)\n",
    "\n",
    "    # Build feature names\n",
    "    fused_feature_names = indep_feature_names.copy()  # 18 model-independent\n",
    "    for model in MODELS:\n",
    "        fused_feature_names.extend(model_dep_feature_names[model])  # 7 per model\n",
    "\n",
    "    print(f\"  ✓ Fused features: {X_train_fused.shape[1]} features total\")\n",
    "    print(f\"    - Model-independent: {X_train_indep.shape[1]} features\")\n",
    "    print(f\"    - Model-dependent: {X_train_dep_concat.shape[1]} features (6 models × 7)\")\n",
    "    print(f\"    Train: {X_train_fused.shape[0]} samples\")\n",
    "    print(f\"    Dev: {X_dev_fused.shape[0]} samples\")\n",
    "    print(f\"\\n  Feature names (first 5): {fused_feature_names[:5]}\")\n",
    "    print(f\"  Feature names (last 5): {fused_feature_names[-5:]}\")\n",
    "    print(f\"\\n  Model-dependent feature examples:\")\n",
    "    for model in MODELS[:2]:  # Show first 2 models\n",
    "        print(f\"    {model}: {model_dep_feature_names[model][:3]}...\")\n",
    "\n",
    "    # Verify feature count\n",
    "    assert X_train_fused.shape[1] == 60, f\"Expected 60 features, got {X_train_fused.shape[1]}\"\n",
    "    assert len(fused_feature_names) == 60, f\"Expected 60 feature names, got {len(fused_feature_names)}\"\n",
    "\n",
    "    # ========================================================================\n",
    "    # STEP 4: Save fused features to persistent storage\n",
    "    # ========================================================================\n",
    "    print(\"\\nStep 4: Saving fused features to persistent storage...\")\n",
    "    storage.save_fused_features(\n",
    "        X_train_fused, MODELS, task, 'train',\n",
    "        fused_feature_names, fusion_method='concat_60'\n",
    "    )\n",
    "    storage.save_fused_features(\n",
    "        X_dev_fused, MODELS, task, 'dev',\n",
    "        fused_feature_names, fusion_method='concat_60'\n",
    "    )\n",
    "    print(\"  ✓ Fused features saved (Train and Dev)\")\n",
    "    print(\"  ✓ Ready for Train+Dev training and Test evaluation in next cell\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Early fusion complete for all tasks (60 features)\")\n",
    "print(f\"{'='*80}\")\n",
    "print(\"\\nSummary:\")\n",
    "print(\"  - 60 features: 18 model-independent + 42 model-dependent (6 models × 7)\")\n",
    "print(\"  - Fused features saved for Train and Dev splits\")\n",
    "print(\"  - Next cell will: Train on Train+Dev, Evaluate on Test set\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k5T6zoAUSqMQ",
    "outputId": "b2e9d6cc-090f-42aa-ce6c-5ffcd63a2657"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "================================================================================\n",
      "TASK: CLARITY - EARLY FUSION (60 FEATURES)\n",
      "================================================================================\n",
      "\n",
      "Step 0: Checking for existing fused features (checkpoint)...\n",
      "  → Fused features not found. Proceeding with fusion...\n",
      "\n",
      "Step 1: Loading model-independent features (18 features, shared)...\n",
      "  ✓ Loaded model-independent features: 18 features\n",
      "    Train: 2758 samples\n",
      "    Dev: 690 samples\n",
      "\n",
      "Step 2: Loading model-dependent features from each model (7 features per model)...\n",
      "  bert: Extracted 7 model-dependent features from 25 total features\n",
      "  bert_political: Extracted 7 model-dependent features from 25 total features\n",
      "  bert_ambiguity: Extracted 7 model-dependent features from 25 total features\n",
      "  roberta: Extracted 7 model-dependent features from 25 total features\n",
      "  deberta: Extracted 7 model-dependent features from 25 total features\n",
      "  xlnet: Extracted 7 model-dependent features from 25 total features\n",
      "\n",
      "Step 3: Concatenating features (60 total features)...\n",
      "  ✓ Fused features: 60 features total\n",
      "    - Model-independent: 18 features\n",
      "    - Model-dependent: 42 features (6 models × 7)\n",
      "    Train: 2758 samples\n",
      "    Dev: 690 samples\n",
      "\n",
      "  Feature names (first 5): ['tfidf_cosine_similarity_q_a', 'content_word_jaccard_q_a', 'question_content_coverage_in_answer', 'answer_content_word_ratio', 'refusal_pattern_match_count']\n",
      "  Feature names (last 5): ['xlnet_attention_mass_q_to_a_per_qtoken', 'xlnet_attention_mass_a_to_q_per_atoken', 'xlnet_focus_token_to_answer_strength', 'xlnet_answer_token_to_focus_strength', 'xlnet_focus_token_coverage_ratio']\n",
      "\n",
      "  Model-dependent feature examples:\n",
      "    bert: ['bert_question_model_token_count', 'bert_answer_model_token_count', 'bert_attention_mass_q_to_a_per_qtoken']...\n",
      "    bert_political: ['bert_political_question_model_token_count', 'bert_political_answer_model_token_count', 'bert_political_attention_mass_q_to_a_per_qtoken']...\n",
      "\n",
      "Step 4: Saving fused features to persistent storage...\n",
      "Saved fused features: /content/drive/MyDrive/semeval_data/features/fused/X_train_fused_bert_bert_political_bert_ambiguity_roberta_deberta_xlnet_clarity.npy\n",
      "Saved fused features: /content/drive/MyDrive/semeval_data/features/fused/X_dev_fused_bert_bert_political_bert_ambiguity_roberta_deberta_xlnet_clarity.npy\n",
      "  ✓ Fused features saved (Train and Dev)\n",
      "  ✓ Ready for Train+Dev training and Test evaluation in next cell\n",
      "\n",
      "================================================================================\n",
      "TASK: EVASION - EARLY FUSION (60 FEATURES)\n",
      "================================================================================\n",
      "\n",
      "Step 0: Checking for existing fused features (checkpoint)...\n",
      "  → Fused features not found. Proceeding with fusion...\n",
      "\n",
      "Step 1: Loading model-independent features (18 features, shared)...\n",
      "  ✓ Loaded model-independent features: 18 features\n",
      "    Train: 2758 samples\n",
      "    Dev: 690 samples\n",
      "\n",
      "Step 2: Loading model-dependent features from each model (7 features per model)...\n",
      "  bert: Extracted 7 model-dependent features from 25 total features\n",
      "  bert_political: Extracted 7 model-dependent features from 25 total features\n",
      "  bert_ambiguity: Extracted 7 model-dependent features from 25 total features\n",
      "  roberta: Extracted 7 model-dependent features from 25 total features\n",
      "  deberta: Extracted 7 model-dependent features from 25 total features\n",
      "  xlnet: Extracted 7 model-dependent features from 25 total features\n",
      "\n",
      "Step 3: Concatenating features (60 total features)...\n",
      "  ✓ Fused features: 60 features total\n",
      "    - Model-independent: 18 features\n",
      "    - Model-dependent: 42 features (6 models × 7)\n",
      "    Train: 2758 samples\n",
      "    Dev: 690 samples\n",
      "\n",
      "  Feature names (first 5): ['tfidf_cosine_similarity_q_a', 'content_word_jaccard_q_a', 'question_content_coverage_in_answer', 'answer_content_word_ratio', 'refusal_pattern_match_count']\n",
      "  Feature names (last 5): ['xlnet_attention_mass_q_to_a_per_qtoken', 'xlnet_attention_mass_a_to_q_per_atoken', 'xlnet_focus_token_to_answer_strength', 'xlnet_answer_token_to_focus_strength', 'xlnet_focus_token_coverage_ratio']\n",
      "\n",
      "  Model-dependent feature examples:\n",
      "    bert: ['bert_question_model_token_count', 'bert_answer_model_token_count', 'bert_attention_mass_q_to_a_per_qtoken']...\n",
      "    bert_political: ['bert_political_question_model_token_count', 'bert_political_answer_model_token_count', 'bert_political_attention_mass_q_to_a_per_qtoken']...\n",
      "\n",
      "Step 4: Saving fused features to persistent storage...\n",
      "Saved fused features: /content/drive/MyDrive/semeval_data/features/fused/X_train_fused_bert_bert_political_bert_ambiguity_roberta_deberta_xlnet_evasion.npy\n",
      "Saved fused features: /content/drive/MyDrive/semeval_data/features/fused/X_dev_fused_bert_bert_political_bert_ambiguity_roberta_deberta_xlnet_evasion.npy\n",
      "  ✓ Fused features saved (Train and Dev)\n",
      "  ✓ Ready for Train+Dev training and Test evaluation in next cell\n",
      "\n",
      "================================================================================\n",
      "Early fusion complete for all tasks (60 features)\n",
      "================================================================================\n",
      "\n",
      "Summary:\n",
      "  - 60 features: 18 model-independent + 42 model-dependent (6 models × 7)\n",
      "  - Fused features saved for Train and Dev splits\n",
      "  - Next cell will: Train on Train+Dev, Evaluate on Test set\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 6\n",
    "# ==============\n",
    "# ============================================================================\n",
    "# FINAL EVALUATION ON TEST SET (TYPE 3)\n",
    "# ============================================================================\n",
    "# Extract test features (60 features), train on Train+Dev, evaluate on Test\n",
    "# CRITICAL: CUDA REQUIRED - No CPU fallback. If CUDA unavailable, raises error.\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from src.features.extraction import (\n",
    "    featurize_model_independent_features,\n",
    "    featurize_model_dependent_features,\n",
    "    get_model_independent_feature_names,\n",
    "    get_model_dependent_feature_names\n",
    ")\n",
    "from src.models.classifiers import train_classifiers\n",
    "from src.evaluation.metrics import compute_all_metrics\n",
    "from src.evaluation.tables import create_final_summary_pivot, style_table_paper\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import json\n",
    "import gc  # For garbage collection\n",
    "import numpy as np\n",
    "\n",
    "# ========================================================================\n",
    "# CRITICAL: CUDA CHECK - NO CPU FALLBACK\n",
    "# ========================================================================\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\n",
    "        \" CUDA is REQUIRED for this cell. GPU runtime is mandatory.\\n\"\n",
    "        \"Please restart with GPU runtime. CPU fallback is NOT supported.\"\n",
    "    )\n",
    "\n",
    "device = torch.device('cuda')\n",
    "print(f\"✓ Device: {device}\")\n",
    "print(f\"✓ CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"✓ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Model configurations\n",
    "MODEL_CONFIGS = {\n",
    "    'bert': 'bert-base-uncased',\n",
    "    'bert_political': 'bert-base-uncased',  # Fine-tuned version\n",
    "    'bert_ambiguity': 'bert-base-uncased',  # Fine-tuned version\n",
    "    'roberta': 'roberta-base',\n",
    "    'deberta': 'microsoft/deberta-base',\n",
    "    'xlnet': 'xlnet-base-cased'\n",
    "}\n",
    "\n",
    "MODEL_MAX_LENGTHS = {\n",
    "    'bert': 512,\n",
    "    'bert_political': 512,\n",
    "    'bert_ambiguity': 512,\n",
    "    'roberta': 512,\n",
    "    'deberta': 512,\n",
    "    'xlnet': 1024\n",
    "}\n",
    "\n",
    "# ========================================================================\n",
    "# STEP 1: Create Type3 output directories (CHECKPOINT)\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: CREATE TYPE3 OUTPUT DIRECTORIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Drive directories\n",
    "test_features_dir = storage.data_path / 'results/FinalResultsType3/test'\n",
    "predictions_dir = storage.data_path / 'results/FinalResultsType3/predictions'\n",
    "tables_dir = storage.data_path / 'results/FinalResultsType3/tables'\n",
    "plots_dir = storage.data_path / 'results/FinalResultsType3/plots'\n",
    "results_dir = storage.data_path / 'results/FinalResultsType3'\n",
    "\n",
    "# Create all directories\n",
    "test_features_dir.mkdir(parents=True, exist_ok=True)\n",
    "predictions_dir.mkdir(parents=True, exist_ok=True)\n",
    "tables_dir.mkdir(parents=True, exist_ok=True)\n",
    "plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"✓ Created all Type3 output directories\")\n",
    "\n",
    "# ========================================================================\n",
    "# STEP 2: Extract or load test features (60 features) - CHECKPOINT\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: TEST FEATURE EXTRACTION (60 FEATURES)\")\n",
    "print(\"=\"*80)\n",
    "print(\"CRITICAL: If checkpoint exists, loads from Drive. Otherwise extracts on CUDA only.\")\n",
    "\n",
    "# Load sentiment pipeline for model-independent features\n",
    "print(\"\\nLoading sentiment analysis pipeline...\")\n",
    "sentiment_pipeline = None\n",
    "try:\n",
    "    from transformers import pipeline\n",
    "    # CRITICAL: CUDA only (device=0)\n",
    "    sentiment_pipeline = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "        device=0,  # CUDA only - no fallback\n",
    "        return_all_scores=True\n",
    "    )\n",
    "    print(\"  ✓ Sentiment pipeline loaded on GPU\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        f\" Failed to load sentiment pipeline on GPU: {e}\\n\"\n",
    "        \"CUDA is required. Please ensure GPU runtime is active.\"\n",
    "    )\n",
    "\n",
    "metadata_keys = {\n",
    "    'inaudible': 'inaudible',\n",
    "    'multiple_questions': 'multiple_questions',\n",
    "    'affirmative_questions': 'affirmative_questions'\n",
    "}\n",
    "\n",
    "# Store test features for each task\n",
    "test_features_60 = {}  # {task: {'test': X_test_60}}\n",
    "\n",
    "for task in TASKS:\n",
    "    print(f\"\\n{'-'*60}\")\n",
    "    print(f\"Task: {task.upper()}\")\n",
    "    print(f\"{'-'*60}\")\n",
    "\n",
    "    # CRITICAL: Reset GPU state before each task (prevent CUDA errors)\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"  ✓ GPU state reset before task\")\n",
    "\n",
    "    # Load test split\n",
    "    try:\n",
    "        test_ds = storage.load_split('test', task=task)\n",
    "        print(f\"  Test set: {len(test_ds)} samples\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"   Test split not found for {task}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # ====================================================================\n",
    "    # 2.1: Extract or load model-independent test features (18 features)\n",
    "    # ====================================================================\n",
    "    print(f\"\\n  2.1: Model-independent test features (18 features)...\")\n",
    "    test_indep_path = test_features_dir / f'X_test_independent_{task}.npy'\n",
    "\n",
    "    if test_indep_path.exists():\n",
    "        X_test_indep = np.load(test_indep_path)\n",
    "        print(f\"    ✓ Loaded from checkpoint: {X_test_indep.shape}\")\n",
    "    else:\n",
    "        print(f\"    → Extracting model-independent test features (GPU required)...\")\n",
    "        X_test_indep, _ = featurize_model_independent_features(\n",
    "            test_ds,\n",
    "            question_key='interview_question',\n",
    "            answer_key='interview_answer',\n",
    "            batch_size=32,\n",
    "            show_progress=True,\n",
    "            sentiment_pipeline=sentiment_pipeline,\n",
    "            metadata_keys=metadata_keys,\n",
    "        )\n",
    "        # Save to checkpoint\n",
    "        test_features_dir.mkdir(parents=True, exist_ok=True)\n",
    "        np.save(test_indep_path, X_test_indep)\n",
    "        print(f\"    ✓ Extracted and saved: {X_test_indep.shape}\")\n",
    "\n",
    "    # ====================================================================\n",
    "    # 2.2: Extract or load model-dependent test features (7 features per model)\n",
    "    # ====================================================================\n",
    "    print(f\"\\n  2.2: Model-dependent test features (7 features × 6 models = 42 features)...\")\n",
    "    model_dep_test_features = {}\n",
    "\n",
    "    for model_key in MODELS:\n",
    "        model_name = MODEL_CONFIGS[model_key]\n",
    "        max_seq_len = MODEL_MAX_LENGTHS[model_key]\n",
    "\n",
    "        test_dep_path = test_features_dir / f'X_test_{model_key}_dependent_{task}.npy'\n",
    "\n",
    "        if test_dep_path.exists():\n",
    "            X_test_dep = np.load(test_dep_path)\n",
    "            print(f\"    {model_key}: ✓ Loaded from checkpoint: {X_test_dep.shape}\")\n",
    "        else:\n",
    "            print(f\"    {model_key}: → Extracting model-dependent test features (GPU required)...\")\n",
    "\n",
    "            # Retry mechanism for CUDA errors\n",
    "            max_retries = 3\n",
    "            retry_count = 0\n",
    "            success = False\n",
    "\n",
    "            while retry_count < max_retries and not success:\n",
    "                try:\n",
    "                    # Aggressive GPU cleanup before each attempt\n",
    "                    torch.cuda.empty_cache()\n",
    "                    torch.cuda.synchronize()\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "                    torch.cuda.synchronize()\n",
    "\n",
    "                    if retry_count > 0:\n",
    "                        print(f\"      Retry attempt {retry_count + 1}/{max_retries}...\")\n",
    "                        import time\n",
    "                        time.sleep(2)  # Wait 2 seconds between retries\n",
    "\n",
    "                    # Load tokenizer and model\n",
    "                    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "                    model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "                    # CRITICAL: CUDA only - no CPU fallback\n",
    "                    model.to(device)\n",
    "                    model.eval()\n",
    "\n",
    "                    # Extract model-dependent features only\n",
    "                    X_test_dep, _ = featurize_model_dependent_features(\n",
    "                        test_ds,\n",
    "                        tokenizer,\n",
    "                        model,\n",
    "                        device,\n",
    "                        question_key='interview_question',\n",
    "                        answer_key='interview_answer',\n",
    "                        batch_size=8,\n",
    "                        max_sequence_length=max_seq_len,\n",
    "                        show_progress=True,\n",
    "                    )\n",
    "\n",
    "                    # Save to checkpoint immediately after successful extraction\n",
    "                    test_features_dir.mkdir(parents=True, exist_ok=True)\n",
    "                    np.save(test_dep_path, X_test_dep)\n",
    "                    print(f\"    {model_key}: ✓ Extracted and saved: {X_test_dep.shape}\")\n",
    "                    success = True\n",
    "\n",
    "                    # Aggressive GPU cleanup after successful extraction\n",
    "                    del model, tokenizer\n",
    "                    torch.cuda.empty_cache()\n",
    "                    torch.cuda.synchronize()\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "                    torch.cuda.synchronize()\n",
    "                    print(f\"    {model_key}: ✓ GPU memory cleared\")\n",
    "\n",
    "                except RuntimeError as e:\n",
    "                    error_str = str(e).lower()\n",
    "                    if \"cuda\" in error_str or \"device\" in error_str:\n",
    "                        retry_count += 1\n",
    "                        # Aggressive cleanup on error\n",
    "                        if 'model' in locals():\n",
    "                            del model\n",
    "                        if 'tokenizer' in locals():\n",
    "                            del tokenizer\n",
    "                        torch.cuda.empty_cache()\n",
    "                        torch.cuda.synchronize()\n",
    "                        gc.collect()\n",
    "                        torch.cuda.empty_cache()\n",
    "                        torch.cuda.synchronize()\n",
    "\n",
    "                        if retry_count >= max_retries:\n",
    "                            raise RuntimeError(\n",
    "                                f\" Failed to extract {model_key} features after {max_retries} retries.\\n\"\n",
    "                                f\"CUDA error: {e}\\n\"\n",
    "                                \"Please restart runtime with fresh GPU and try again.\"\n",
    "                            )\n",
    "                        print(f\"       CUDA error (attempt {retry_count}/{max_retries}): {str(e)[:100]}...\")\n",
    "                    else:\n",
    "                        # Non-CUDA error - re-raise immediately\n",
    "                        raise\n",
    "                except Exception as e:\n",
    "                    # Any other error - cleanup and re-raise\n",
    "                    if 'model' in locals():\n",
    "                        del model\n",
    "                    if 'tokenizer' in locals():\n",
    "                        del tokenizer\n",
    "                    torch.cuda.empty_cache()\n",
    "                    torch.cuda.synchronize()\n",
    "                    raise\n",
    "\n",
    "            if not success:\n",
    "                raise RuntimeError(\n",
    "                    f\" Failed to extract {model_key} features after {max_retries} retries.\\n\"\n",
    "                    \"Please restart runtime with fresh GPU and try again.\"\n",
    "                )\n",
    "\n",
    "        model_dep_test_features[model_key] = X_test_dep\n",
    "\n",
    "    # ====================================================================\n",
    "    # 2.3: Concatenate test features: [18 Model-Independent | 42 Model-Dependent]\n",
    "    # ====================================================================\n",
    "    print(f\"\\n  2.3: Concatenating test features (60 total)...\")\n",
    "\n",
    "    # Concatenate model-dependent features from all models\n",
    "    model_dep_list = [model_dep_test_features[model] for model in MODELS]\n",
    "    X_test_dep_concat = np.hstack(model_dep_list)  # (N, 42)\n",
    "\n",
    "    # Final concatenation: [18 Model-Independent | 42 Model-Dependent]\n",
    "    X_test_60 = np.hstack([X_test_indep, X_test_dep_concat])  # (N, 60)\n",
    "\n",
    "    print(f\"    ✓ Test features: {X_test_60.shape} (60 features)\")\n",
    "    print(f\"      - Model-independent: {X_test_indep.shape[1]} features\")\n",
    "    print(f\"      - Model-dependent: {X_test_dep_concat.shape[1]} features (6 models × 7)\")\n",
    "\n",
    "    # Verify feature count\n",
    "    assert X_test_60.shape[1] == 60, f\"Expected 60 features, got {X_test_60.shape[1]}\"\n",
    "\n",
    "    # Save complete test features to checkpoint\n",
    "    test_features_dir.mkdir(parents=True, exist_ok=True)\n",
    "    test_complete_path = test_features_dir / f'X_test_60feat_{task}.npy'\n",
    "    np.save(test_complete_path, X_test_60)\n",
    "    print(f\"    ✓ Saved complete test features to: {test_complete_path.name}\")\n",
    "\n",
    "    # Store for later use\n",
    "    test_features_60[task] = {\n",
    "        'test': X_test_60\n",
    "    }\n",
    "\n",
    "    # CRITICAL: Clean GPU after each task (prevent CUDA errors in next task)\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    print(f\"  ✓ GPU cleaned after task {task}\")\n",
    "\n",
    "print(\"\\n✓ Test feature extraction complete for all tasks\")\n",
    "\n",
    "# CRITICAL: Clean sentiment pipeline at the end (prevent GPU memory leak)\n",
    "if sentiment_pipeline is not None:\n",
    "    del sentiment_pipeline\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    gc.collect()\n",
    "    print(\"✓ Sentiment pipeline cleaned\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2 COMPLETE: All test features extracted/loaded successfully\")\n",
    "print(\"=\"*80)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "595a6f4c1cf64ca6ad22da4c5523cbb3",
      "883db3b211d841818ab6512ce56f9bc6",
      "423a35617b304a3aaa7d57da3e7da660",
      "10a5bc0fd4854e1785950d6ac38cd135",
      "24a1c963bd9b4ad295732471ea8b4914",
      "5d528cd9cb02426f9e9bc47f0e6ee1d8",
      "877eaa49e8894e548346de241fe77761",
      "5831fb88481340a689b2078d736857f3",
      "dc6c350903c34fcf8adf8a1b14ca3d0b",
      "07abeb03ae514b62a6e79bfa401605cf",
      "1873891befbf41abb88dbfb049abb56a",
      "c84ffb9c1f3840a68ac10f67229afbc4",
      "0483de4d60464457a2e241bbb8409c07",
      "8851926b5be244648026ad629c08feb5",
      "18eee26ddd9542c99d62c610bc4d9317",
      "8170b7ca271a41069e1c3c3a3165eb59",
      "a8130cf37e09496da725d625f99ed33c",
      "62b57c476fce4736943394f584bbd134",
      "f2bf03b46f5b4380a93f8fe42dc8d010",
      "997af15b332e42fdae49e20d2f2337e2",
      "e437e038a46849ff9df089819f937fde",
      "73f648703abb482987d3b67f022a4101",
      "f26dc19eb50b4cbda31e098215320a07",
      "e8192601aba7496f893fab4da34169c4",
      "8f01f8574c8d44f08f14745d7712eef6",
      "5e5e2b06348c4b2f9cac3e3af1b91199",
      "b0870904fac94923a4c5a48f5a8e27b5",
      "0e47a74d35be49609a20222ae994f303",
      "fa4d0bf9ca574338970ba583446b12d9",
      "d77570bb82b04af4ad6ffceb51084f9c",
      "ff4a85b3b2164963bee1f4d3f9672558",
      "139a7bd24bee4dff881af342c62225fe",
      "7f1f5635f89247c7b6f2aa7dd633fd82",
      "376f0c724feb4eaab2c18c00f55e54e0",
      "6024a5a1c5924736b96f91abdf70ee58",
      "740bd74b66b24901a64bf1194b8074b4",
      "89387f802dca4e539a6d8a6711235109",
      "fce28a5248384edf9ee692d3f3c13233",
      "dcdb78f17b1c45568b42417da71e44a2",
      "e989ad22bd404eb59faaa8f6f5030b69",
      "6b9a308b8b5b4eb69621582e549d389e",
      "38998247c0ef4edabab14aeddc98c5c7",
      "270509501a50407a931b5baf15a79af7",
      "7cfee1d0f8ff462da5acea38999220e8",
      "58db8a9d25db43fcad21b91aeb2b7bab",
      "740fd78f33944b96b5785d64386a183a",
      "d5136317d2b642eb9273fc849441a39a",
      "f1a1a102985b431cb0793d5d11dc96f0",
      "17a728013ae447ef976740e652df274a",
      "a456764f3e4f46d1821125b99a76458c",
      "7608d9b823b247dfbf93d0913f4aa8dc",
      "9e4734693f9a499db8f34c17e021ccd1",
      "ff76a1e539aa4beba070f4e96a419e16",
      "b691b567d1e04343b6539fbb2cfc682a",
      "8f3cb10e87034a478ec9824071d4b28f",
      "24a728d83b6e48e1a059bdfaa5d68fbe",
      "40d353797e2248f6a62456ec75cc0da0",
      "3e3ea2b2bea7432fae3d7b767976e0ad",
      "40af848de66d43e082d7c279948651fc",
      "6a7af5056677440eb34bce9658ee3c96",
      "682add40bea74677b90e7a0ab3be5b8e",
      "4af5771259004b64887de995813bf51f",
      "daa2b6af03de40f0ad5c13b5f2555801",
      "33006c8a2f244b0aad981e2da7c8d4a5",
      "93f8b65aea4e4dcf9419f7d61acd1d71",
      "c100461e14ac42c88d7594cb2f8b56d4"
     ]
    },
    "id": "WB8VJ0ruSqR0",
    "outputId": "1590fb8a-6365-4808-9a37-da889687a53b"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✓ Device: cuda\n",
      "✓ CUDA available: True\n",
      "✓ GPU: NVIDIA A100-SXM4-80GB\n",
      "\n",
      "================================================================================\n",
      "STEP 1: CREATE TYPE3 OUTPUT DIRECTORIES\n",
      "================================================================================\n",
      "✓ Created all Type3 output directories\n",
      "\n",
      "================================================================================\n",
      "STEP 2: TEST FEATURE EXTRACTION (60 FEATURES)\n",
      "================================================================================\n",
      "CRITICAL: If checkpoint exists, loads from Drive. Otherwise extracts on CUDA only.\n",
      "\n",
      "Loading sentiment analysis pipeline...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "595a6f4c1cf64ca6ad22da4c5523cbb3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c84ffb9c1f3840a68ac10f67229afbc4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f26dc19eb50b4cbda31e098215320a07"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "376f0c724feb4eaab2c18c00f55e54e0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58db8a9d25db43fcad21b91aeb2b7bab"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24a728d83b6e48e1a059bdfaa5d68fbe"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cuda:0\n",
      "/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  ✓ Sentiment pipeline loaded on GPU\n",
      "\n",
      "------------------------------------------------------------\n",
      "Task: CLARITY\n",
      "------------------------------------------------------------\n",
      "  ✓ GPU state reset before task\n",
      "  Test set: 308 samples\n",
      "\n",
      "  2.1: Model-independent test features (18 features)...\n",
      "    ✓ Loaded from checkpoint: (308, 18)\n",
      "\n",
      "  2.2: Model-dependent test features (7 features × 6 models = 42 features)...\n",
      "    bert: ✓ Loaded from checkpoint: (308, 7)\n",
      "    bert_political: ✓ Loaded from checkpoint: (308, 7)\n",
      "    bert_ambiguity: ✓ Loaded from checkpoint: (308, 7)\n",
      "    roberta: ✓ Loaded from checkpoint: (308, 7)\n",
      "    deberta: ✓ Loaded from checkpoint: (308, 7)\n",
      "    xlnet: ✓ Loaded from checkpoint: (308, 7)\n",
      "\n",
      "  2.3: Concatenating test features (60 total)...\n",
      "    ✓ Test features: (308, 60) (60 features)\n",
      "      - Model-independent: 18 features\n",
      "      - Model-dependent: 42 features (6 models × 7)\n",
      "    ✓ Saved complete test features to: X_test_60feat_clarity.npy\n",
      "  ✓ GPU cleaned after task clarity\n",
      "\n",
      "------------------------------------------------------------\n",
      "Task: EVASION\n",
      "------------------------------------------------------------\n",
      "  ✓ GPU state reset before task\n",
      "  Test set: 275 samples\n",
      "\n",
      "  2.1: Model-independent test features (18 features)...\n",
      "    ✓ Loaded from checkpoint: (275, 18)\n",
      "\n",
      "  2.2: Model-dependent test features (7 features × 6 models = 42 features)...\n",
      "    bert: ✓ Loaded from checkpoint: (275, 7)\n",
      "    bert_political: ✓ Loaded from checkpoint: (275, 7)\n",
      "    bert_ambiguity: ✓ Loaded from checkpoint: (275, 7)\n",
      "    roberta: ✓ Loaded from checkpoint: (275, 7)\n",
      "    deberta: ✓ Loaded from checkpoint: (275, 7)\n",
      "    xlnet: ✓ Loaded from checkpoint: (275, 7)\n",
      "\n",
      "  2.3: Concatenating test features (60 total)...\n",
      "    ✓ Test features: (275, 60) (60 features)\n",
      "      - Model-independent: 18 features\n",
      "      - Model-dependent: 42 features (6 models × 7)\n",
      "    ✓ Saved complete test features to: X_test_60feat_evasion.npy\n",
      "  ✓ GPU cleaned after task evasion\n",
      "\n",
      "✓ Test feature extraction complete for all tasks\n",
      "✓ Sentiment pipeline cleaned\n",
      "\n",
      "================================================================================\n",
      "STEP 2 COMPLETE: All test features extracted/loaded successfully\n",
      "================================================================================\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 7\n",
    "# ==============\n",
    "# ========================================================================\n",
    "# STEP 3: Train on Train+Dev and evaluate on Test (2 tasks, 6 classifiers)\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: TRAIN ON TRAIN+DEV AND EVALUATE ON TEST\")\n",
    "print(\"=\"*80)\n",
    "print(\"CRITICAL: This cell requires fused features from STEP 4.\")\n",
    "print(\"          If you see 'Fused features not found' errors,\")\n",
    "print(\"          please run STEP 4 first to create fused features.\")\n",
    "\n",
    "# Store all results for summary tables\n",
    "all_results_type3 = {}  # {task: {classifier: {metrics, predictions, probabilities}}}\n",
    "\n",
    "# Check if test features are available from STEP 6\n",
    "if 'test_features_60' not in globals() or not test_features_60:\n",
    "    print(\"\\n ERROR: test_features_60 not found!\")\n",
    "    print(\"   Please run STEP 6 first to extract test features.\")\n",
    "    raise RuntimeError(\"test_features_60 not available. Run STEP 6 first.\")\n",
    "\n",
    "for task in TASKS:\n",
    "    print(f\"\\n{'-'*80}\")\n",
    "    print(f\"TASK: {task.upper()}\")\n",
    "    print(f\"{'-'*80}\")\n",
    "\n",
    "    # Check if test features are available for this task\n",
    "    if task not in test_features_60:\n",
    "        print(f\"   Skipping {task}: Test features not available from STEP 6\")\n",
    "        print(f\"     Please ensure STEP 6 completed successfully for {task}.\")\n",
    "        continue\n",
    "\n",
    "    # Select appropriate label list and dataset key\n",
    "    if task == 'clarity':\n",
    "        label_list = CLARITY_LABELS\n",
    "        label_key = 'clarity_label'\n",
    "    else:  # evasion\n",
    "        label_list = EVASION_LABELS\n",
    "        label_key = 'evasion_label'\n",
    "\n",
    "    # Load Train+Dev fused features (60 features) - from STEP 4\n",
    "    # These were already created and saved in STEP 4\n",
    "    print(f\"\\n  Loading fused features from STEP 4...\")\n",
    "    try:\n",
    "        # Load fused features directly from STEP 4 (no need to reconstruct)\n",
    "        X_train_60 = storage.load_fused_features(MODELS, task, 'train')\n",
    "        X_dev_60 = storage.load_fused_features(MODELS, task, 'dev')\n",
    "\n",
    "        # Verify shapes\n",
    "        if X_train_60.shape[1] != 60:\n",
    "            raise ValueError(f\"Expected 60 features in train, got {X_train_60.shape[1]}\")\n",
    "        if X_dev_60.shape[1] != 60:\n",
    "            raise ValueError(f\"Expected 60 features in dev, got {X_dev_60.shape[1]}\")\n",
    "\n",
    "        print(f\"  ✓ Loaded Train fused features: {X_train_60.shape} (60 features)\")\n",
    "        print(f\"  ✓ Loaded Dev fused features: {X_dev_60.shape} (60 features)\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\n   ERROR: Fused features not found for {task}!\")\n",
    "        print(f\"  Error details: {e}\")\n",
    "        print(f\"\\n  SOLUTION:\")\n",
    "        print(f\"  1. Go back to STEP 4\")\n",
    "        print(f\"  2. Run STEP 4 completely (it will create fused features)\")\n",
    "        print(f\"  3. Wait for STEP 4 to finish successfully\")\n",
    "        print(f\"  4. Then come back and run STEP 7 again\")\n",
    "        print(f\"\\n  Expected file locations:\")\n",
    "        print(f\"    - Train: {storage.data_path}/features/fused/X_train_fused_{'_'.join(MODELS)}_{task}.npy\")\n",
    "        print(f\"    - Dev: {storage.data_path}/features/fused/X_dev_fused_{'_'.join(MODELS)}_{task}.npy\")\n",
    "        print(f\"\\n   Skipping {task} - cannot proceed without fused features.\")\n",
    "        continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n   ERROR loading train+dev features for {task}: {type(e).__name__}\")\n",
    "        print(f\"  Error: {e}\")\n",
    "        print(f\"\\n  SOLUTION:\")\n",
    "        print(f\"  1. Check if STEP 4 completed successfully\")\n",
    "        print(f\"  2. Verify file paths and permissions\")\n",
    "        print(f\"  3. Try running STEP 4 again\")\n",
    "        print(f\"\\n   Skipping {task} - cannot proceed without fused features.\")\n",
    "        continue\n",
    "\n",
    "    # Load labels\n",
    "    try:\n",
    "        train_ds = storage.load_split('train', task=task)\n",
    "        dev_ds = storage.load_split('dev', task=task)\n",
    "        test_ds = storage.load_split('test', task=task)\n",
    "\n",
    "        y_train = np.array([train_ds[i][label_key] for i in range(len(train_ds))])\n",
    "        y_dev = np.array([dev_ds[i][label_key] for i in range(len(dev_ds))])\n",
    "        y_test = np.array([test_ds[i][label_key] for i in range(len(test_ds))])\n",
    "\n",
    "        # Verify label counts match feature counts\n",
    "        if len(y_train) != X_train_60.shape[0]:\n",
    "            raise ValueError(f\"Train labels ({len(y_train)}) don't match features ({X_train_60.shape[0]})\")\n",
    "        if len(y_dev) != X_dev_60.shape[0]:\n",
    "            raise ValueError(f\"Dev labels ({len(y_dev)}) don't match features ({X_dev_60.shape[0]})\")\n",
    "        if len(y_test) != test_features_60[task]['test'].shape[0]:\n",
    "            raise ValueError(f\"Test labels ({len(y_test)}) don't match test features ({test_features_60[task]['test'].shape[0]})\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ERROR loading labels for {task}: {type(e).__name__}\")\n",
    "        print(f\"  Error: {e}\")\n",
    "        print(f\"   Skipping {task} - cannot proceed without labels.\")\n",
    "        continue\n",
    "\n",
    "    # Combine Train+Dev for final training\n",
    "    X_train_full = np.vstack([X_train_60, X_dev_60])\n",
    "    y_train_full = np.concatenate([y_train, y_dev])\n",
    "\n",
    "    print(f\"\\n  Combined Train+Dev: {X_train_full.shape[0]} samples, {X_train_full.shape[1]} features\")\n",
    "    print(f\"  Test: {len(y_test)} samples, {test_features_60[task]['test'].shape[1]} features\")\n",
    "\n",
    "    # Get test features\n",
    "    X_test_60 = test_features_60[task]['test']\n",
    "\n",
    "    # Verify test features have 60 features\n",
    "    if X_test_60.shape[1] != 60:\n",
    "        print(f\"   ERROR: Test features have {X_test_60.shape[1]} features, expected 60\")\n",
    "        print(f\"   Skipping {task} - feature mismatch.\")\n",
    "        continue\n",
    "\n",
    "    # Train all 6 classifiers and evaluate on test\n",
    "    print(f\"\\n  Training and evaluating {len(classifiers)} classifiers...\")\n",
    "    all_results_type3[task] = {}\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        print(f\"\\n    Classifier: {clf_name}\")\n",
    "\n",
    "        try:\n",
    "            # Encode labels\n",
    "            le = LabelEncoder()\n",
    "            y_train_encoded = le.fit_transform(y_train_full)\n",
    "            y_test_encoded = le.transform(y_test)\n",
    "\n",
    "            # Train classifier\n",
    "            clf.fit(X_train_full, y_train_encoded)\n",
    "\n",
    "            # Predict on test\n",
    "            y_test_pred_encoded = clf.predict(X_test_60)\n",
    "            y_test_pred = le.inverse_transform(y_test_pred_encoded)\n",
    "\n",
    "            # Get probabilities (if available)\n",
    "            if hasattr(clf, 'predict_proba'):\n",
    "                y_test_proba = clf.predict_proba(X_test_60)\n",
    "            else:\n",
    "                y_test_proba = None\n",
    "\n",
    "            # Compute metrics\n",
    "            metrics = compute_all_metrics(\n",
    "                y_test_encoded,\n",
    "                y_test_pred_encoded,\n",
    "                label_list,\n",
    "                task_name=f\"TYPE3_TEST_{task}_{clf_name}\"\n",
    "            )\n",
    "\n",
    "            # Store results\n",
    "            all_results_type3[task][clf_name] = {\n",
    "                'predictions': y_test_pred,\n",
    "                'probabilities': y_test_proba,\n",
    "                'metrics': metrics\n",
    "            }\n",
    "\n",
    "            print(f\"      Test Macro F1: {metrics.get('macro_f1', 0.0):.4f}\")\n",
    "            print(f\"      Test Accuracy: {metrics.get('accuracy', 0.0):.4f}\")\n",
    "\n",
    "            # Save HARD LABELS (predictions) to Type3 folder\n",
    "            predictions_dir.mkdir(parents=True, exist_ok=True)\n",
    "            pred_path = predictions_dir / f'pred_test_{clf_name}_{task}.npy'\n",
    "            np.save(pred_path, y_test_pred)\n",
    "            print(f\"      ✓ Saved HARD LABELS: {pred_path.name}\")\n",
    "\n",
    "            # Save SOFT LABELS (probabilities) to Type3 folder\n",
    "            if y_test_proba is not None:\n",
    "                predictions_dir.mkdir(parents=True, exist_ok=True)\n",
    "                proba_path = predictions_dir / f'proba_test_{clf_name}_{task}.npy'\n",
    "                np.save(proba_path, y_test_proba)\n",
    "                print(f\"      ✓ Saved SOFT LABELS: {proba_path.name} (shape: {y_test_proba.shape})\")\n",
    "            else:\n",
    "                print(f\"       SOFT LABELS not available for {clf_name} (classifier does not support predict_proba)\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"       ERROR training/evaluating {clf_name} for {task}: {type(e).__name__}\")\n",
    "            print(f\"      Error: {e}\")\n",
    "            print(f\"       Skipping {clf_name} for {task}\")\n",
    "            continue\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3 SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "if all_results_type3:\n",
    "    print(f\"✓ Successfully completed training/evaluation for {len(all_results_type3)} task(s)\")\n",
    "    for task, results in all_results_type3.items():\n",
    "        print(f\"  - {task}: {len(results)} classifier(s) evaluated\")\n",
    "else:\n",
    "    print(\" WARNING: No tasks were successfully completed!\")\n",
    "    print(\"   Please check the errors above and ensure:\")\n",
    "    print(\"   1. STEP 4 completed successfully (creates fused features)\")\n",
    "    print(\"   2. STEP 6 completed successfully (creates test features)\")\n",
    "    print(\"   3. All required files are accessible\")\n",
    "\n",
    "print(\"\\n✓ Training and evaluation complete for all tasks and classifiers\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Law91cXdSqUQ",
    "outputId": "d98f4bce-31a6-437e-bd4e-744d51347814"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 3: TRAIN ON TRAIN+DEV AND EVALUATE ON TEST\n",
      "================================================================================\n",
      "CRITICAL: This cell requires fused features from STEP 4.\n",
      "          If you see 'Fused features not found' errors,\n",
      "          please run STEP 4 first to create fused features.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TASK: CLARITY\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  Loading fused features from STEP 4...\n",
      "  ✓ Loaded Train fused features: (2758, 60) (60 features)\n",
      "  ✓ Loaded Dev fused features: (690, 60) (60 features)\n",
      "\n",
      "  Combined Train+Dev: 3448 samples, 60 features\n",
      "  Test: 308 samples, 60 features\n",
      "\n",
      "  Training and evaluating 6 classifiers...\n",
      "\n",
      "    Classifier: LogisticRegression\n",
      "      Test Macro F1: 0.3532\n",
      "      Test Accuracy: 0.5682\n",
      "      ✓ Saved HARD LABELS: pred_test_LogisticRegression_clarity.npy\n",
      "      ✓ Saved SOFT LABELS: proba_test_LogisticRegression_clarity.npy (shape: (308, 3))\n",
      "\n",
      "    Classifier: LinearSVC\n",
      "      Test Macro F1: 0.3702\n",
      "      Test Accuracy: 0.6526\n",
      "      ✓ Saved HARD LABELS: pred_test_LinearSVC_clarity.npy\n",
      "       SOFT LABELS not available for LinearSVC (classifier does not support predict_proba)\n",
      "\n",
      "    Classifier: RandomForest\n",
      "      Test Macro F1: 0.4312\n",
      "      Test Accuracy: 0.7013\n",
      "      ✓ Saved HARD LABELS: pred_test_RandomForest_clarity.npy\n",
      "      ✓ Saved SOFT LABELS: proba_test_RandomForest_clarity.npy (shape: (308, 3))\n",
      "\n",
      "    Classifier: MLP\n",
      "      Test Macro F1: 0.4140\n",
      "      Test Accuracy: 0.6656\n",
      "      ✓ Saved HARD LABELS: pred_test_MLP_clarity.npy\n",
      "      ✓ Saved SOFT LABELS: proba_test_MLP_clarity.npy (shape: (308, 3))\n",
      "\n",
      "    Classifier: XGBoost\n",
      "      Test Macro F1: 0.4735\n",
      "      Test Accuracy: 0.6981\n",
      "      ✓ Saved HARD LABELS: pred_test_XGBoost_clarity.npy\n",
      "      ✓ Saved SOFT LABELS: proba_test_XGBoost_clarity.npy (shape: (308, 3))\n",
      "\n",
      "    Classifier: LightGBM\n",
      "      Test Macro F1: 0.4364\n",
      "      Test Accuracy: 0.6818\n",
      "      ✓ Saved HARD LABELS: pred_test_LightGBM_clarity.npy\n",
      "      ✓ Saved SOFT LABELS: proba_test_LightGBM_clarity.npy (shape: (308, 3))\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TASK: EVASION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  Loading fused features from STEP 4...\n",
      "  ✓ Loaded Train fused features: (2758, 60) (60 features)\n",
      "  ✓ Loaded Dev fused features: (690, 60) (60 features)\n",
      "\n",
      "  Combined Train+Dev: 3448 samples, 60 features\n",
      "  Test: 275 samples, 60 features\n",
      "\n",
      "  Training and evaluating 6 classifiers...\n",
      "\n",
      "    Classifier: LogisticRegression\n",
      "      Test Macro F1: 0.0996\n",
      "      Test Accuracy: 0.1309\n",
      "      ✓ Saved HARD LABELS: pred_test_LogisticRegression_evasion.npy\n",
      "      ✓ Saved SOFT LABELS: proba_test_LogisticRegression_evasion.npy (shape: (275, 9))\n",
      "\n",
      "    Classifier: LinearSVC\n",
      "      Test Macro F1: 0.0594\n",
      "      Test Accuracy: 0.0727\n",
      "      ✓ Saved HARD LABELS: pred_test_LinearSVC_evasion.npy\n",
      "       SOFT LABELS not available for LinearSVC (classifier does not support predict_proba)\n",
      "\n",
      "    Classifier: RandomForest\n",
      "      Test Macro F1: 0.2309\n",
      "      Test Accuracy: 0.3055\n",
      "      ✓ Saved HARD LABELS: pred_test_RandomForest_evasion.npy\n",
      "      ✓ Saved SOFT LABELS: proba_test_RandomForest_evasion.npy (shape: (275, 9))\n",
      "\n",
      "    Classifier: MLP\n",
      "      Test Macro F1: 0.1967\n",
      "      Test Accuracy: 0.2727\n",
      "      ✓ Saved HARD LABELS: pred_test_MLP_evasion.npy\n",
      "      ✓ Saved SOFT LABELS: proba_test_MLP_evasion.npy (shape: (275, 9))\n",
      "\n",
      "    Classifier: XGBoost\n",
      "      Test Macro F1: 0.2141\n",
      "      Test Accuracy: 0.2400\n",
      "      ✓ Saved HARD LABELS: pred_test_XGBoost_evasion.npy\n",
      "      ✓ Saved SOFT LABELS: proba_test_XGBoost_evasion.npy (shape: (275, 9))\n",
      "\n",
      "    Classifier: LightGBM\n",
      "      Test Macro F1: 0.2253\n",
      "      Test Accuracy: 0.2764\n",
      "      ✓ Saved HARD LABELS: pred_test_LightGBM_evasion.npy\n",
      "      ✓ Saved SOFT LABELS: proba_test_LightGBM_evasion.npy (shape: (275, 9))\n",
      "\n",
      "================================================================================\n",
      "STEP 3 SUMMARY\n",
      "================================================================================\n",
      "✓ Successfully completed training/evaluation for 2 task(s)\n",
      "  - clarity: 6 classifier(s) evaluated\n",
      "  - evasion: 6 classifier(s) evaluated\n",
      "\n",
      "✓ Training and evaluation complete for all tasks and classifiers\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 8\n",
    "# ==============\n",
    "\n",
    "# ========================================================================\n",
    "# STEP 4: Generate summary tables (like notebook 5)\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: GENERATE SUMMARY TABLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create summary tables for each task\n",
    "for task in TASKS:\n",
    "    if task not in all_results_type3:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n{'-'*60}\")\n",
    "    print(f\"Task: {task.upper()}\")\n",
    "    print(f\"{'-'*60}\")\n",
    "\n",
    "    # Create summary DataFrame\n",
    "    summary_rows = []\n",
    "    for clf_name, result in all_results_type3[task].items():\n",
    "        metrics = result['metrics']\n",
    "        summary_rows.append({\n",
    "            'classifier': clf_name,\n",
    "            'task': task,\n",
    "            'macro_f1': metrics.get('macro_f1', 0.0),\n",
    "            'accuracy': metrics.get('accuracy', 0.0),\n",
    "            'macro_precision': metrics.get('macro_precision', 0.0),\n",
    "            'macro_recall': metrics.get('macro_recall', 0.0),\n",
    "        })\n",
    "\n",
    "    df_summary = pd.DataFrame(summary_rows)\n",
    "\n",
    "    # Display table\n",
    "    print(f\"\\nSummary Table for {task.upper()}:\")\n",
    "    display(df_summary.style.format(precision=4))\n",
    "\n",
    "    # Save table (ensure directory exists before saving)\n",
    "    tables_dir.mkdir(parents=True, exist_ok=True)\n",
    "    table_path = tables_dir / f'summary_{task}.csv'\n",
    "    df_summary.to_csv(table_path, index=False)\n",
    "    print(f\"  ✓ Saved table: {table_path.name}\")\n",
    "\n",
    "    # Save HTML version\n",
    "    tables_dir.mkdir(parents=True, exist_ok=True)\n",
    "    html_path = tables_dir / f'summary_{task}.html'\n",
    "    df_summary.to_html(html_path, index=False, float_format='{:.4f}'.format)\n",
    "    print(f\"  ✓ Saved HTML: {html_path.name}\")\n",
    "\n",
    "# Create combined summary (all tasks)\n",
    "print(f\"\\n{'-'*60}\")\n",
    "print(\"Combined Summary (All Tasks)\")\n",
    "print(f\"{'-'*60}\")\n",
    "\n",
    "all_summary_rows = []\n",
    "for task in TASKS:\n",
    "    if task not in all_results_type3:\n",
    "        continue\n",
    "    for clf_name, result in all_results_type3[task].items():\n",
    "        metrics = result['metrics']\n",
    "        all_summary_rows.append({\n",
    "            'classifier': clf_name,\n",
    "            'task': task,\n",
    "            'macro_f1': metrics.get('macro_f1', 0.0),\n",
    "            'accuracy': metrics.get('accuracy', 0.0),\n",
    "        })\n",
    "\n",
    "df_all_summary = pd.DataFrame(all_summary_rows)\n",
    "\n",
    "# Pivot table: Classifier × Task\n",
    "if len(df_all_summary) > 0:\n",
    "    df_pivot = df_all_summary.pivot(index='classifier', columns='task', values='macro_f1')\n",
    "\n",
    "    # Reorder columns: clarity first, then evasion\n",
    "    desired_order = ['clarity', 'evasion']\n",
    "\n",
    "    # Only include columns that exist in the pivot table\n",
    "    available_columns = [col for col in desired_order if col in df_pivot.columns]\n",
    "    # Add any remaining columns that weren't in desired_order (alphabetically)\n",
    "    remaining_columns = sorted([col for col in df_pivot.columns if col not in available_columns])\n",
    "    column_order = available_columns + remaining_columns\n",
    "\n",
    "    # Reorder columns\n",
    "    df_pivot = df_pivot[column_order]\n",
    "\n",
    "    print(\"\\nPivot Table: Classifier × Task (Macro F1)\")\n",
    "    display(df_pivot.style.format(precision=4))\n",
    "\n",
    "    # Save pivot table (ensure directory exists before saving)\n",
    "    tables_dir.mkdir(parents=True, exist_ok=True)\n",
    "    pivot_path = tables_dir / 'summary_all_tasks_pivot.csv'\n",
    "    df_pivot.to_csv(pivot_path)\n",
    "    print(f\"  ✓ Saved pivot table: {pivot_path.name}\")\n",
    "\n",
    "    # Save HTML version\n",
    "    tables_dir.mkdir(parents=True, exist_ok=True)\n",
    "    html_pivot_path = tables_dir / 'summary_all_tasks_pivot.html'\n",
    "    df_pivot.to_html(html_pivot_path, float_format='{:.4f}'.format)\n",
    "    print(f\"  ✓ Saved HTML: {html_pivot_path.name}\")\n",
    "\n",
    "# Save complete results to JSON (ensure directory exists before saving)\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "results_json_path = results_dir / 'final_results_type3.json'\n",
    "results_dict = {\n",
    "    'method': 'early_fusion_60feat',\n",
    "    'n_features': 60,\n",
    "    'feature_breakdown': {\n",
    "        'model_independent': 18,\n",
    "        'model_dependent': 42,\n",
    "        'models': len(MODELS),\n",
    "        'features_per_model': 7\n",
    "    },\n",
    "    'tasks': TASKS,\n",
    "    'classifiers': list(classifiers.keys()),\n",
    "    'results': {\n",
    "        task: {\n",
    "            clf_name: {\n",
    "                'metrics': result['metrics'],\n",
    "                'n_test': len(test_features_60[task]['test']) if task in test_features_60 else 0\n",
    "            }\n",
    "            for clf_name, result in task_results.items()\n",
    "        }\n",
    "        for task, task_results in all_results_type3.items()\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(results_json_path, 'w') as f:\n",
    "    json.dump(results_dict, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n✓ Saved complete results: {results_json_path.name}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"FINAL EVALUATION TYPE 3 COMPLETE\")\n",
    "print(f\"{'='*80}\")\n",
    "print(\"\\nSummary:\")\n",
    "print(\"  - 60 features: 18 model-independent + 42 model-dependent (6 models × 7)\")\n",
    "print(\"  - Trained on Train+Dev combined data\")\n",
    "print(\"  - Evaluated on Test set (2 tasks: clarity, evasion)\")\n",
    "print(\"  - All 6 classifiers evaluated\")\n",
    "print(\"  - Results saved to FinalResultsType3 directory\")\n",
    "print(\"\\nOutput locations:\")\n",
    "print(f\"  - Test features: {test_features_dir}\")\n",
    "print(f\"  - Predictions: {predictions_dir}\")\n",
    "print(f\"  - Tables: {tables_dir}\")\n",
    "print(f\"  - Results: {results_dir}\")"
   ],
   "metadata": {
    "id": "gHkzhR3vSqXG",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "4e547395-3d10-4508-8946-bb77358d9dd8"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 4: GENERATE SUMMARY TABLES\n",
      "================================================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Task: CLARITY\n",
      "------------------------------------------------------------\n",
      "\n",
      "Summary Table for CLARITY:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x796b6413f410>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_e8263\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e8263_level0_col0\" class=\"col_heading level0 col0\" >classifier</th>\n",
       "      <th id=\"T_e8263_level0_col1\" class=\"col_heading level0 col1\" >task</th>\n",
       "      <th id=\"T_e8263_level0_col2\" class=\"col_heading level0 col2\" >macro_f1</th>\n",
       "      <th id=\"T_e8263_level0_col3\" class=\"col_heading level0 col3\" >accuracy</th>\n",
       "      <th id=\"T_e8263_level0_col4\" class=\"col_heading level0 col4\" >macro_precision</th>\n",
       "      <th id=\"T_e8263_level0_col5\" class=\"col_heading level0 col5\" >macro_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e8263_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e8263_row0_col0\" class=\"data row0 col0\" >LogisticRegression</td>\n",
       "      <td id=\"T_e8263_row0_col1\" class=\"data row0 col1\" >clarity</td>\n",
       "      <td id=\"T_e8263_row0_col2\" class=\"data row0 col2\" >0.3532</td>\n",
       "      <td id=\"T_e8263_row0_col3\" class=\"data row0 col3\" >0.5682</td>\n",
       "      <td id=\"T_e8263_row0_col4\" class=\"data row0 col4\" >0.4351</td>\n",
       "      <td id=\"T_e8263_row0_col5\" class=\"data row0 col5\" >0.4352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8263_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e8263_row1_col0\" class=\"data row1 col0\" >LinearSVC</td>\n",
       "      <td id=\"T_e8263_row1_col1\" class=\"data row1 col1\" >clarity</td>\n",
       "      <td id=\"T_e8263_row1_col2\" class=\"data row1 col2\" >0.3702</td>\n",
       "      <td id=\"T_e8263_row1_col3\" class=\"data row1 col3\" >0.6526</td>\n",
       "      <td id=\"T_e8263_row1_col4\" class=\"data row1 col4\" >0.6477</td>\n",
       "      <td id=\"T_e8263_row1_col5\" class=\"data row1 col5\" >0.4308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8263_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e8263_row2_col0\" class=\"data row2 col0\" >RandomForest</td>\n",
       "      <td id=\"T_e8263_row2_col1\" class=\"data row2 col1\" >clarity</td>\n",
       "      <td id=\"T_e8263_row2_col2\" class=\"data row2 col2\" >0.4312</td>\n",
       "      <td id=\"T_e8263_row2_col3\" class=\"data row2 col3\" >0.7013</td>\n",
       "      <td id=\"T_e8263_row2_col4\" class=\"data row2 col4\" >0.8971</td>\n",
       "      <td id=\"T_e8263_row2_col5\" class=\"data row2 col5\" >0.4269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8263_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e8263_row3_col0\" class=\"data row3 col0\" >MLP</td>\n",
       "      <td id=\"T_e8263_row3_col1\" class=\"data row3 col1\" >clarity</td>\n",
       "      <td id=\"T_e8263_row3_col2\" class=\"data row3 col2\" >0.4140</td>\n",
       "      <td id=\"T_e8263_row3_col3\" class=\"data row3 col3\" >0.6656</td>\n",
       "      <td id=\"T_e8263_row3_col4\" class=\"data row3 col4\" >0.5752</td>\n",
       "      <td id=\"T_e8263_row3_col5\" class=\"data row3 col5\" >0.4042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8263_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e8263_row4_col0\" class=\"data row4 col0\" >XGBoost</td>\n",
       "      <td id=\"T_e8263_row4_col1\" class=\"data row4 col1\" >clarity</td>\n",
       "      <td id=\"T_e8263_row4_col2\" class=\"data row4 col2\" >0.4735</td>\n",
       "      <td id=\"T_e8263_row4_col3\" class=\"data row4 col3\" >0.6981</td>\n",
       "      <td id=\"T_e8263_row4_col4\" class=\"data row4 col4\" >0.7154</td>\n",
       "      <td id=\"T_e8263_row4_col5\" class=\"data row4 col5\" >0.4512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8263_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e8263_row5_col0\" class=\"data row5 col0\" >LightGBM</td>\n",
       "      <td id=\"T_e8263_row5_col1\" class=\"data row5 col1\" >clarity</td>\n",
       "      <td id=\"T_e8263_row5_col2\" class=\"data row5 col2\" >0.4364</td>\n",
       "      <td id=\"T_e8263_row5_col3\" class=\"data row5 col3\" >0.6818</td>\n",
       "      <td id=\"T_e8263_row5_col4\" class=\"data row5 col4\" >0.5925</td>\n",
       "      <td id=\"T_e8263_row5_col5\" class=\"data row5 col5\" >0.4353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  ✓ Saved table: summary_clarity.csv\n",
      "  ✓ Saved HTML: summary_clarity.html\n",
      "\n",
      "------------------------------------------------------------\n",
      "Task: EVASION\n",
      "------------------------------------------------------------\n",
      "\n",
      "Summary Table for EVASION:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x796b3c97b080>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_c511f\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c511f_level0_col0\" class=\"col_heading level0 col0\" >classifier</th>\n",
       "      <th id=\"T_c511f_level0_col1\" class=\"col_heading level0 col1\" >task</th>\n",
       "      <th id=\"T_c511f_level0_col2\" class=\"col_heading level0 col2\" >macro_f1</th>\n",
       "      <th id=\"T_c511f_level0_col3\" class=\"col_heading level0 col3\" >accuracy</th>\n",
       "      <th id=\"T_c511f_level0_col4\" class=\"col_heading level0 col4\" >macro_precision</th>\n",
       "      <th id=\"T_c511f_level0_col5\" class=\"col_heading level0 col5\" >macro_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c511f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c511f_row0_col0\" class=\"data row0 col0\" >LogisticRegression</td>\n",
       "      <td id=\"T_c511f_row0_col1\" class=\"data row0 col1\" >evasion</td>\n",
       "      <td id=\"T_c511f_row0_col2\" class=\"data row0 col2\" >0.0996</td>\n",
       "      <td id=\"T_c511f_row0_col3\" class=\"data row0 col3\" >0.1309</td>\n",
       "      <td id=\"T_c511f_row0_col4\" class=\"data row0 col4\" >0.1257</td>\n",
       "      <td id=\"T_c511f_row0_col5\" class=\"data row0 col5\" >0.2651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c511f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c511f_row1_col0\" class=\"data row1 col0\" >LinearSVC</td>\n",
       "      <td id=\"T_c511f_row1_col1\" class=\"data row1 col1\" >evasion</td>\n",
       "      <td id=\"T_c511f_row1_col2\" class=\"data row1 col2\" >0.0594</td>\n",
       "      <td id=\"T_c511f_row1_col3\" class=\"data row1 col3\" >0.0727</td>\n",
       "      <td id=\"T_c511f_row1_col4\" class=\"data row1 col4\" >0.2107</td>\n",
       "      <td id=\"T_c511f_row1_col5\" class=\"data row1 col5\" >0.2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c511f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c511f_row2_col0\" class=\"data row2 col0\" >RandomForest</td>\n",
       "      <td id=\"T_c511f_row2_col1\" class=\"data row2 col1\" >evasion</td>\n",
       "      <td id=\"T_c511f_row2_col2\" class=\"data row2 col2\" >0.2309</td>\n",
       "      <td id=\"T_c511f_row2_col3\" class=\"data row2 col3\" >0.3055</td>\n",
       "      <td id=\"T_c511f_row2_col4\" class=\"data row2 col4\" >0.2621</td>\n",
       "      <td id=\"T_c511f_row2_col5\" class=\"data row2 col5\" >0.2503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c511f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c511f_row3_col0\" class=\"data row3 col0\" >MLP</td>\n",
       "      <td id=\"T_c511f_row3_col1\" class=\"data row3 col1\" >evasion</td>\n",
       "      <td id=\"T_c511f_row3_col2\" class=\"data row3 col2\" >0.1967</td>\n",
       "      <td id=\"T_c511f_row3_col3\" class=\"data row3 col3\" >0.2727</td>\n",
       "      <td id=\"T_c511f_row3_col4\" class=\"data row3 col4\" >0.2047</td>\n",
       "      <td id=\"T_c511f_row3_col5\" class=\"data row3 col5\" >0.2421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c511f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c511f_row4_col0\" class=\"data row4 col0\" >XGBoost</td>\n",
       "      <td id=\"T_c511f_row4_col1\" class=\"data row4 col1\" >evasion</td>\n",
       "      <td id=\"T_c511f_row4_col2\" class=\"data row4 col2\" >0.2141</td>\n",
       "      <td id=\"T_c511f_row4_col3\" class=\"data row4 col3\" >0.2400</td>\n",
       "      <td id=\"T_c511f_row4_col4\" class=\"data row4 col4\" >0.2144</td>\n",
       "      <td id=\"T_c511f_row4_col5\" class=\"data row4 col5\" >0.2351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c511f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c511f_row5_col0\" class=\"data row5 col0\" >LightGBM</td>\n",
       "      <td id=\"T_c511f_row5_col1\" class=\"data row5 col1\" >evasion</td>\n",
       "      <td id=\"T_c511f_row5_col2\" class=\"data row5 col2\" >0.2253</td>\n",
       "      <td id=\"T_c511f_row5_col3\" class=\"data row5 col3\" >0.2764</td>\n",
       "      <td id=\"T_c511f_row5_col4\" class=\"data row5 col4\" >0.2240</td>\n",
       "      <td id=\"T_c511f_row5_col5\" class=\"data row5 col5\" >0.2576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  ✓ Saved table: summary_evasion.csv\n",
      "  ✓ Saved HTML: summary_evasion.html\n",
      "\n",
      "------------------------------------------------------------\n",
      "Combined Summary (All Tasks)\n",
      "------------------------------------------------------------\n",
      "\n",
      "Pivot Table: Classifier × Task (Macro F1)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x796b3c97a6c0>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_89b59\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >task</th>\n",
       "      <th id=\"T_89b59_level0_col0\" class=\"col_heading level0 col0\" >clarity</th>\n",
       "      <th id=\"T_89b59_level0_col1\" class=\"col_heading level0 col1\" >evasion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >classifier</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_89b59_level0_row0\" class=\"row_heading level0 row0\" >LightGBM</th>\n",
       "      <td id=\"T_89b59_row0_col0\" class=\"data row0 col0\" >0.4364</td>\n",
       "      <td id=\"T_89b59_row0_col1\" class=\"data row0 col1\" >0.2253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89b59_level0_row1\" class=\"row_heading level0 row1\" >LinearSVC</th>\n",
       "      <td id=\"T_89b59_row1_col0\" class=\"data row1 col0\" >0.3702</td>\n",
       "      <td id=\"T_89b59_row1_col1\" class=\"data row1 col1\" >0.0594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89b59_level0_row2\" class=\"row_heading level0 row2\" >LogisticRegression</th>\n",
       "      <td id=\"T_89b59_row2_col0\" class=\"data row2 col0\" >0.3532</td>\n",
       "      <td id=\"T_89b59_row2_col1\" class=\"data row2 col1\" >0.0996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89b59_level0_row3\" class=\"row_heading level0 row3\" >MLP</th>\n",
       "      <td id=\"T_89b59_row3_col0\" class=\"data row3 col0\" >0.4140</td>\n",
       "      <td id=\"T_89b59_row3_col1\" class=\"data row3 col1\" >0.1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89b59_level0_row4\" class=\"row_heading level0 row4\" >RandomForest</th>\n",
       "      <td id=\"T_89b59_row4_col0\" class=\"data row4 col0\" >0.4312</td>\n",
       "      <td id=\"T_89b59_row4_col1\" class=\"data row4 col1\" >0.2309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89b59_level0_row5\" class=\"row_heading level0 row5\" >XGBoost</th>\n",
       "      <td id=\"T_89b59_row5_col0\" class=\"data row5 col0\" >0.4735</td>\n",
       "      <td id=\"T_89b59_row5_col1\" class=\"data row5 col1\" >0.2141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  ✓ Saved pivot table: summary_all_tasks_pivot.csv\n",
      "  ✓ Saved HTML: summary_all_tasks_pivot.html\n",
      "\n",
      "✓ Saved complete results: final_results_type3.json\n",
      "\n",
      "================================================================================\n",
      "FINAL EVALUATION TYPE 3 COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Summary:\n",
      "  - 60 features: 18 model-independent + 42 model-dependent (6 models × 7)\n",
      "  - Trained on Train+Dev combined data\n",
      "  - Evaluated on Test set (2 tasks: clarity, evasion)\n",
      "  - All 6 classifiers evaluated\n",
      "  - Results saved to FinalResultsType3 directory\n",
      "\n",
      "Output locations:\n",
      "  - Test features: /content/drive/MyDrive/semeval_data/results/FinalResultsType3/test\n",
      "  - Predictions: /content/drive/MyDrive/semeval_data/results/FinalResultsType3/predictions\n",
      "  - Tables: /content/drive/MyDrive/semeval_data/results/FinalResultsType3/tables\n",
      "  - Results: /content/drive/MyDrive/semeval_data/results/FinalResultsType3\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 9\n",
    "# ==============\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY TABLES: Clarity → EvasionBasedClarity → Annotator 1/2/3\n",
    "# ============================================================================\n",
    "\n",
    "from src.models.hierarchical import evasion_to_clarity, evaluate_hierarchical_approach\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY TABLES GENERATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ========================================================================\n",
    "# STEP 1: Collect All Evaluation Results\n",
    "# ========================================================================\n",
    "print(\"\\nStep 1: Evaluating all clarity variants...\")\n",
    "\n",
    "all_evaluation_results = {}  # {task_name: {classifier: {metrics}}}\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 1.1 Direct Clarity\n",
    "# ------------------------------------------------------------------------\n",
    "if 'clarity' in all_results_type3:\n",
    "    all_evaluation_results['clarity'] = {\n",
    "        clf: {'metrics': res['metrics']}\n",
    "        for clf, res in all_results_type3['clarity'].items()\n",
    "    }\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 1.2 Evasion → Clarity + Annotator-Based Clarity\n",
    "# ------------------------------------------------------------------------\n",
    "if 'evasion' in all_results_type3:\n",
    "    print(\"\\nProcessing evasion-based evaluations...\")\n",
    "\n",
    "    test_ds = storage.load_split('test', task='evasion')\n",
    "\n",
    "    y_clarity_true = np.array(\n",
    "        [test_ds[i]['clarity_label'] for i in range(len(test_ds))]\n",
    "    )\n",
    "\n",
    "    le_clarity = LabelEncoder()\n",
    "    y_clarity_true_enc = le_clarity.fit_transform(y_clarity_true)\n",
    "\n",
    "    clarity_labels = CLARITY_LABELS\n",
    "    n_test = len(test_ds)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Evasion-Based Clarity\n",
    "    # ----------------------------\n",
    "    all_evaluation_results['evasion_based_clarity'] = {}\n",
    "\n",
    "    for clf, res in all_results_type3['evasion'].items():\n",
    "        y_evasion_pred = res['predictions']\n",
    "\n",
    "        if len(y_evasion_pred) != n_test:\n",
    "            continue\n",
    "\n",
    "        hierarchical_metrics = evaluate_hierarchical_approach(\n",
    "            np.zeros(n_test, dtype=int),\n",
    "            y_evasion_pred,\n",
    "            y_clarity_true_enc,\n",
    "            EVASION_LABELS,\n",
    "            clarity_labels\n",
    "        )\n",
    "\n",
    "        # Extract macro precision and recall from classification_report\n",
    "        classification_report_dict = hierarchical_metrics.get('classification_report', {})\n",
    "        macro_avg = classification_report_dict.get('macro avg', {})\n",
    "        macro_precision = macro_avg.get('precision', 0.0)\n",
    "        macro_recall = macro_avg.get('recall', 0.0)\n",
    "\n",
    "        # Create metrics dict with all required fields\n",
    "        metrics_dict = {\n",
    "            'accuracy': hierarchical_metrics.get('accuracy', 0.0),\n",
    "            'macro_f1': hierarchical_metrics.get('macro_f1', 0.0),\n",
    "            'macro_precision': macro_precision,\n",
    "            'macro_recall': macro_recall,\n",
    "            'weighted_f1': hierarchical_metrics.get('weighted_f1', 0.0),\n",
    "        }\n",
    "\n",
    "        all_evaluation_results['evasion_based_clarity'][clf] = {\n",
    "            'metrics': metrics_dict\n",
    "        }\n",
    "\n",
    "    # ----------------------------\n",
    "    # Annotator-Based Clarity\n",
    "    # ----------------------------\n",
    "    annotator_sources = {\n",
    "        'annotator1_based_clarity': 'annotator1',\n",
    "        'annotator2_based_clarity': 'annotator2',\n",
    "        'annotator3_based_clarity': 'annotator3',\n",
    "    }\n",
    "\n",
    "    for task_name, col in annotator_sources.items():\n",
    "        y_ann_evasion = np.array(\n",
    "            [test_ds[i][col] for i in range(n_test)]\n",
    "        )\n",
    "\n",
    "        y_ann_clarity = np.array(\n",
    "            [evasion_to_clarity(str(x)) for x in y_ann_evasion]\n",
    "        )\n",
    "        y_ann_clarity_enc = le_clarity.transform(y_ann_clarity)\n",
    "\n",
    "        all_evaluation_results[task_name] = {}\n",
    "\n",
    "        for clf, res in all_results_type3['evasion'].items():\n",
    "            y_evasion_pred = res['predictions']\n",
    "\n",
    "            if len(y_evasion_pred) != n_test:\n",
    "                continue\n",
    "\n",
    "            hierarchical_metrics = evaluate_hierarchical_approach(\n",
    "                np.zeros(n_test, dtype=int),\n",
    "                y_evasion_pred,\n",
    "                y_ann_clarity_enc,\n",
    "                EVASION_LABELS,\n",
    "                clarity_labels\n",
    "            )\n",
    "\n",
    "            # Extract macro precision and recall from classification_report\n",
    "            classification_report_dict = hierarchical_metrics.get('classification_report', {})\n",
    "            macro_avg = classification_report_dict.get('macro avg', {})\n",
    "            macro_precision = macro_avg.get('precision', 0.0)\n",
    "            macro_recall = macro_avg.get('recall', 0.0)\n",
    "\n",
    "            # Create metrics dict with all required fields\n",
    "            metrics_dict = {\n",
    "                'accuracy': hierarchical_metrics.get('accuracy', 0.0),\n",
    "                'macro_f1': hierarchical_metrics.get('macro_f1', 0.0),\n",
    "                'macro_precision': macro_precision,\n",
    "                'macro_recall': macro_recall,\n",
    "                'weighted_f1': hierarchical_metrics.get('weighted_f1', 0.0),\n",
    "            }\n",
    "\n",
    "            all_evaluation_results[task_name][clf] = {\n",
    "                'metrics': metrics_dict\n",
    "            }\n",
    "\n",
    "print(\"\\n✓ All evaluations collected\")\n",
    "\n",
    "# ========================================================================\n",
    "# STEP 2: Build Summary DataFrame\n",
    "# ========================================================================\n",
    "print(\"\\nStep 2: Creating summary tables...\")\n",
    "\n",
    "TASK_ORDER = [\n",
    "    'clarity',\n",
    "    'evasion_based_clarity',\n",
    "    'annotator1_based_clarity',\n",
    "    'annotator2_based_clarity',\n",
    "    'annotator3_based_clarity'\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for task in TASK_ORDER:\n",
    "    if task not in all_evaluation_results:\n",
    "        continue\n",
    "    for clf, res in all_evaluation_results[task].items():\n",
    "        m = res['metrics']\n",
    "        rows.append({\n",
    "            'classifier': clf,\n",
    "            'task': task,\n",
    "            'macro_f1': m.get('macro_f1', 0.0),\n",
    "            'accuracy': m.get('accuracy', 0.0),\n",
    "            'macro_precision': m.get('macro_precision', 0.0),\n",
    "            'macro_recall': m.get('macro_recall', 0.0),\n",
    "        })\n",
    "\n",
    "df_summary = pd.DataFrame(rows).drop_duplicates(\n",
    "    subset=['classifier', 'task'],\n",
    "    keep='first'\n",
    ")\n",
    "\n",
    "# ========================================================================\n",
    "# STEP 3: Pivot Table (Classifier × Tasks) — ORDER FIXED\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY TABLE: Classifier × Tasks (Macro F1)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_pivot = (\n",
    "    df_summary\n",
    "    .pivot(index='classifier', columns='task', values='macro_f1')\n",
    "    .reindex(columns=[t for t in TASK_ORDER if t in df_summary['task'].unique()])\n",
    ")\n",
    "\n",
    "display(df_pivot.style.format(precision=4))\n",
    "\n",
    "tables_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_pivot.to_csv(tables_dir / 'final_summary_classifier_wise.csv')\n",
    "df_pivot.to_html(\n",
    "    tables_dir / 'final_summary_classifier_wise.html',\n",
    "    float_format='{:.4f}'.format\n",
    ")\n",
    "\n",
    "print(\"✓ Saved pivot tables\")\n",
    "\n",
    "# ========================================================================\n",
    "# STEP 4: Detailed Table\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED SUMMARY TABLE: All Metrics\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "display(df_summary.style.format(precision=4))\n",
    "\n",
    "df_summary.to_csv(\n",
    "    tables_dir / 'final_summary_detailed.csv',\n",
    "    index=False\n",
    ")\n",
    "df_summary.to_html(\n",
    "    tables_dir / 'final_summary_detailed.html',\n",
    "    index=False,\n",
    "    float_format='{:.4f}'.format\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY TABLES COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Tasks order: {', '.join([t for t in TASK_ORDER if t in df_summary['task'].unique()])}\")"
   ],
   "metadata": {
    "id": "DCuLllM2SqZk",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "a6087830-4cf2-4243-caf2-4099ca762f01"
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY TABLES GENERATION\n",
      "================================================================================\n",
      "\n",
      "Step 1: Evaluating all clarity variants...\n",
      "\n",
      "Processing evasion-based evaluations...\n",
      "\n",
      "✓ All evaluations collected\n",
      "\n",
      "Step 2: Creating summary tables...\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY TABLE: Classifier × Tasks (Macro F1)\n",
      "================================================================================\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x796b87f21af0>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_4754d\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >task</th>\n",
       "      <th id=\"T_4754d_level0_col0\" class=\"col_heading level0 col0\" >clarity</th>\n",
       "      <th id=\"T_4754d_level0_col1\" class=\"col_heading level0 col1\" >evasion_based_clarity</th>\n",
       "      <th id=\"T_4754d_level0_col2\" class=\"col_heading level0 col2\" >annotator1_based_clarity</th>\n",
       "      <th id=\"T_4754d_level0_col3\" class=\"col_heading level0 col3\" >annotator2_based_clarity</th>\n",
       "      <th id=\"T_4754d_level0_col4\" class=\"col_heading level0 col4\" >annotator3_based_clarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >classifier</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4754d_level0_row0\" class=\"row_heading level0 row0\" >LightGBM</th>\n",
       "      <td id=\"T_4754d_row0_col0\" class=\"data row0 col0\" >0.4364</td>\n",
       "      <td id=\"T_4754d_row0_col1\" class=\"data row0 col1\" >0.4374</td>\n",
       "      <td id=\"T_4754d_row0_col2\" class=\"data row0 col2\" >0.4481</td>\n",
       "      <td id=\"T_4754d_row0_col3\" class=\"data row0 col3\" >0.4403</td>\n",
       "      <td id=\"T_4754d_row0_col4\" class=\"data row0 col4\" >0.4307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4754d_level0_row1\" class=\"row_heading level0 row1\" >LinearSVC</th>\n",
       "      <td id=\"T_4754d_row1_col0\" class=\"data row1 col0\" >0.3702</td>\n",
       "      <td id=\"T_4754d_row1_col1\" class=\"data row1 col1\" >0.1213</td>\n",
       "      <td id=\"T_4754d_row1_col2\" class=\"data row1 col2\" >0.1132</td>\n",
       "      <td id=\"T_4754d_row1_col3\" class=\"data row1 col3\" >0.1168</td>\n",
       "      <td id=\"T_4754d_row1_col4\" class=\"data row1 col4\" >0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4754d_level0_row2\" class=\"row_heading level0 row2\" >LogisticRegression</th>\n",
       "      <td id=\"T_4754d_row2_col0\" class=\"data row2 col0\" >0.3532</td>\n",
       "      <td id=\"T_4754d_row2_col1\" class=\"data row2 col1\" >0.2327</td>\n",
       "      <td id=\"T_4754d_row2_col2\" class=\"data row2 col2\" >0.2087</td>\n",
       "      <td id=\"T_4754d_row2_col3\" class=\"data row2 col3\" >0.2437</td>\n",
       "      <td id=\"T_4754d_row2_col4\" class=\"data row2 col4\" >0.2327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4754d_level0_row3\" class=\"row_heading level0 row3\" >MLP</th>\n",
       "      <td id=\"T_4754d_row3_col0\" class=\"data row3 col0\" >0.4140</td>\n",
       "      <td id=\"T_4754d_row3_col1\" class=\"data row3 col1\" >0.4876</td>\n",
       "      <td id=\"T_4754d_row3_col2\" class=\"data row3 col2\" >0.4875</td>\n",
       "      <td id=\"T_4754d_row3_col3\" class=\"data row3 col3\" >0.4792</td>\n",
       "      <td id=\"T_4754d_row3_col4\" class=\"data row3 col4\" >0.4818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4754d_level0_row4\" class=\"row_heading level0 row4\" >RandomForest</th>\n",
       "      <td id=\"T_4754d_row4_col0\" class=\"data row4 col0\" >0.4312</td>\n",
       "      <td id=\"T_4754d_row4_col1\" class=\"data row4 col1\" >0.3875</td>\n",
       "      <td id=\"T_4754d_row4_col2\" class=\"data row4 col2\" >0.3960</td>\n",
       "      <td id=\"T_4754d_row4_col3\" class=\"data row4 col3\" >0.3527</td>\n",
       "      <td id=\"T_4754d_row4_col4\" class=\"data row4 col4\" >0.3901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4754d_level0_row5\" class=\"row_heading level0 row5\" >XGBoost</th>\n",
       "      <td id=\"T_4754d_row5_col0\" class=\"data row5 col0\" >0.4735</td>\n",
       "      <td id=\"T_4754d_row5_col1\" class=\"data row5 col1\" >0.4255</td>\n",
       "      <td id=\"T_4754d_row5_col2\" class=\"data row5 col2\" >0.4422</td>\n",
       "      <td id=\"T_4754d_row5_col3\" class=\"data row5 col3\" >0.4185</td>\n",
       "      <td id=\"T_4754d_row5_col4\" class=\"data row5 col4\" >0.4191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✓ Saved pivot tables\n",
      "\n",
      "================================================================================\n",
      "DETAILED SUMMARY TABLE: All Metrics\n",
      "================================================================================\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x796bc4862a20>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f446f\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f446f_level0_col0\" class=\"col_heading level0 col0\" >classifier</th>\n",
       "      <th id=\"T_f446f_level0_col1\" class=\"col_heading level0 col1\" >task</th>\n",
       "      <th id=\"T_f446f_level0_col2\" class=\"col_heading level0 col2\" >macro_f1</th>\n",
       "      <th id=\"T_f446f_level0_col3\" class=\"col_heading level0 col3\" >accuracy</th>\n",
       "      <th id=\"T_f446f_level0_col4\" class=\"col_heading level0 col4\" >macro_precision</th>\n",
       "      <th id=\"T_f446f_level0_col5\" class=\"col_heading level0 col5\" >macro_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f446f_row0_col0\" class=\"data row0 col0\" >LogisticRegression</td>\n",
       "      <td id=\"T_f446f_row0_col1\" class=\"data row0 col1\" >clarity</td>\n",
       "      <td id=\"T_f446f_row0_col2\" class=\"data row0 col2\" >0.3532</td>\n",
       "      <td id=\"T_f446f_row0_col3\" class=\"data row0 col3\" >0.5682</td>\n",
       "      <td id=\"T_f446f_row0_col4\" class=\"data row0 col4\" >0.4351</td>\n",
       "      <td id=\"T_f446f_row0_col5\" class=\"data row0 col5\" >0.4352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f446f_row1_col0\" class=\"data row1 col0\" >LinearSVC</td>\n",
       "      <td id=\"T_f446f_row1_col1\" class=\"data row1 col1\" >clarity</td>\n",
       "      <td id=\"T_f446f_row1_col2\" class=\"data row1 col2\" >0.3702</td>\n",
       "      <td id=\"T_f446f_row1_col3\" class=\"data row1 col3\" >0.6526</td>\n",
       "      <td id=\"T_f446f_row1_col4\" class=\"data row1 col4\" >0.6477</td>\n",
       "      <td id=\"T_f446f_row1_col5\" class=\"data row1 col5\" >0.4308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f446f_row2_col0\" class=\"data row2 col0\" >RandomForest</td>\n",
       "      <td id=\"T_f446f_row2_col1\" class=\"data row2 col1\" >clarity</td>\n",
       "      <td id=\"T_f446f_row2_col2\" class=\"data row2 col2\" >0.4312</td>\n",
       "      <td id=\"T_f446f_row2_col3\" class=\"data row2 col3\" >0.7013</td>\n",
       "      <td id=\"T_f446f_row2_col4\" class=\"data row2 col4\" >0.8971</td>\n",
       "      <td id=\"T_f446f_row2_col5\" class=\"data row2 col5\" >0.4269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f446f_row3_col0\" class=\"data row3 col0\" >MLP</td>\n",
       "      <td id=\"T_f446f_row3_col1\" class=\"data row3 col1\" >clarity</td>\n",
       "      <td id=\"T_f446f_row3_col2\" class=\"data row3 col2\" >0.4140</td>\n",
       "      <td id=\"T_f446f_row3_col3\" class=\"data row3 col3\" >0.6656</td>\n",
       "      <td id=\"T_f446f_row3_col4\" class=\"data row3 col4\" >0.5752</td>\n",
       "      <td id=\"T_f446f_row3_col5\" class=\"data row3 col5\" >0.4042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f446f_row4_col0\" class=\"data row4 col0\" >XGBoost</td>\n",
       "      <td id=\"T_f446f_row4_col1\" class=\"data row4 col1\" >clarity</td>\n",
       "      <td id=\"T_f446f_row4_col2\" class=\"data row4 col2\" >0.4735</td>\n",
       "      <td id=\"T_f446f_row4_col3\" class=\"data row4 col3\" >0.6981</td>\n",
       "      <td id=\"T_f446f_row4_col4\" class=\"data row4 col4\" >0.7154</td>\n",
       "      <td id=\"T_f446f_row4_col5\" class=\"data row4 col5\" >0.4512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_f446f_row5_col0\" class=\"data row5 col0\" >LightGBM</td>\n",
       "      <td id=\"T_f446f_row5_col1\" class=\"data row5 col1\" >clarity</td>\n",
       "      <td id=\"T_f446f_row5_col2\" class=\"data row5 col2\" >0.4364</td>\n",
       "      <td id=\"T_f446f_row5_col3\" class=\"data row5 col3\" >0.6818</td>\n",
       "      <td id=\"T_f446f_row5_col4\" class=\"data row5 col4\" >0.5925</td>\n",
       "      <td id=\"T_f446f_row5_col5\" class=\"data row5 col5\" >0.4353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_f446f_row6_col0\" class=\"data row6 col0\" >LogisticRegression</td>\n",
       "      <td id=\"T_f446f_row6_col1\" class=\"data row6 col1\" >evasion_based_clarity</td>\n",
       "      <td id=\"T_f446f_row6_col2\" class=\"data row6 col2\" >0.2327</td>\n",
       "      <td id=\"T_f446f_row6_col3\" class=\"data row6 col3\" >0.3236</td>\n",
       "      <td id=\"T_f446f_row6_col4\" class=\"data row6 col4\" >0.2529</td>\n",
       "      <td id=\"T_f446f_row6_col5\" class=\"data row6 col5\" >0.4213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_f446f_row7_col0\" class=\"data row7 col0\" >LinearSVC</td>\n",
       "      <td id=\"T_f446f_row7_col1\" class=\"data row7 col1\" >evasion_based_clarity</td>\n",
       "      <td id=\"T_f446f_row7_col2\" class=\"data row7 col2\" >0.1213</td>\n",
       "      <td id=\"T_f446f_row7_col3\" class=\"data row7 col3\" >0.1491</td>\n",
       "      <td id=\"T_f446f_row7_col4\" class=\"data row7 col4\" >0.5600</td>\n",
       "      <td id=\"T_f446f_row7_col5\" class=\"data row7 col5\" >0.3700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_f446f_row8_col0\" class=\"data row8 col0\" >RandomForest</td>\n",
       "      <td id=\"T_f446f_row8_col1\" class=\"data row8 col1\" >evasion_based_clarity</td>\n",
       "      <td id=\"T_f446f_row8_col2\" class=\"data row8 col2\" >0.3875</td>\n",
       "      <td id=\"T_f446f_row8_col3\" class=\"data row8 col3\" >0.4145</td>\n",
       "      <td id=\"T_f446f_row8_col4\" class=\"data row8 col4\" >0.5384</td>\n",
       "      <td id=\"T_f446f_row8_col5\" class=\"data row8 col5\" >0.4183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_f446f_row9_col0\" class=\"data row9 col0\" >MLP</td>\n",
       "      <td id=\"T_f446f_row9_col1\" class=\"data row9 col1\" >evasion_based_clarity</td>\n",
       "      <td id=\"T_f446f_row9_col2\" class=\"data row9 col2\" >0.4876</td>\n",
       "      <td id=\"T_f446f_row9_col3\" class=\"data row9 col3\" >0.5927</td>\n",
       "      <td id=\"T_f446f_row9_col4\" class=\"data row9 col4\" >0.6889</td>\n",
       "      <td id=\"T_f446f_row9_col5\" class=\"data row9 col5\" >0.4558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_f446f_row10_col0\" class=\"data row10 col0\" >XGBoost</td>\n",
       "      <td id=\"T_f446f_row10_col1\" class=\"data row10 col1\" >evasion_based_clarity</td>\n",
       "      <td id=\"T_f446f_row10_col2\" class=\"data row10 col2\" >0.4255</td>\n",
       "      <td id=\"T_f446f_row10_col3\" class=\"data row10 col3\" >0.5709</td>\n",
       "      <td id=\"T_f446f_row10_col4\" class=\"data row10 col4\" >0.5478</td>\n",
       "      <td id=\"T_f446f_row10_col5\" class=\"data row10 col5\" >0.4027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_f446f_row11_col0\" class=\"data row11 col0\" >LightGBM</td>\n",
       "      <td id=\"T_f446f_row11_col1\" class=\"data row11 col1\" >evasion_based_clarity</td>\n",
       "      <td id=\"T_f446f_row11_col2\" class=\"data row11 col2\" >0.4374</td>\n",
       "      <td id=\"T_f446f_row11_col3\" class=\"data row11 col3\" >0.6073</td>\n",
       "      <td id=\"T_f446f_row11_col4\" class=\"data row11 col4\" >0.5005</td>\n",
       "      <td id=\"T_f446f_row11_col5\" class=\"data row11 col5\" >0.4218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_f446f_row12_col0\" class=\"data row12 col0\" >LogisticRegression</td>\n",
       "      <td id=\"T_f446f_row12_col1\" class=\"data row12 col1\" >annotator1_based_clarity</td>\n",
       "      <td id=\"T_f446f_row12_col2\" class=\"data row12 col2\" >0.2087</td>\n",
       "      <td id=\"T_f446f_row12_col3\" class=\"data row12 col3\" >0.2800</td>\n",
       "      <td id=\"T_f446f_row12_col4\" class=\"data row12 col4\" >0.2191</td>\n",
       "      <td id=\"T_f446f_row12_col5\" class=\"data row12 col5\" >0.3818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_f446f_row13_col0\" class=\"data row13 col0\" >LinearSVC</td>\n",
       "      <td id=\"T_f446f_row13_col1\" class=\"data row13 col1\" >annotator1_based_clarity</td>\n",
       "      <td id=\"T_f446f_row13_col2\" class=\"data row13 col2\" >0.1132</td>\n",
       "      <td id=\"T_f446f_row13_col3\" class=\"data row13 col3\" >0.1345</td>\n",
       "      <td id=\"T_f446f_row13_col4\" class=\"data row13 col4\" >0.5445</td>\n",
       "      <td id=\"T_f446f_row13_col5\" class=\"data row13 col5\" >0.3398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_f446f_row14_col0\" class=\"data row14 col0\" >RandomForest</td>\n",
       "      <td id=\"T_f446f_row14_col1\" class=\"data row14 col1\" >annotator1_based_clarity</td>\n",
       "      <td id=\"T_f446f_row14_col2\" class=\"data row14 col2\" >0.3960</td>\n",
       "      <td id=\"T_f446f_row14_col3\" class=\"data row14 col3\" >0.4255</td>\n",
       "      <td id=\"T_f446f_row14_col4\" class=\"data row14 col4\" >0.5274</td>\n",
       "      <td id=\"T_f446f_row14_col5\" class=\"data row14 col5\" >0.4101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_f446f_row15_col0\" class=\"data row15 col0\" >MLP</td>\n",
       "      <td id=\"T_f446f_row15_col1\" class=\"data row15 col1\" >annotator1_based_clarity</td>\n",
       "      <td id=\"T_f446f_row15_col2\" class=\"data row15 col2\" >0.4875</td>\n",
       "      <td id=\"T_f446f_row15_col3\" class=\"data row15 col3\" >0.5745</td>\n",
       "      <td id=\"T_f446f_row15_col4\" class=\"data row15 col4\" >0.6870</td>\n",
       "      <td id=\"T_f446f_row15_col5\" class=\"data row15 col5\" >0.4515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_f446f_row16_col0\" class=\"data row16 col0\" >XGBoost</td>\n",
       "      <td id=\"T_f446f_row16_col1\" class=\"data row16 col1\" >annotator1_based_clarity</td>\n",
       "      <td id=\"T_f446f_row16_col2\" class=\"data row16 col2\" >0.4422</td>\n",
       "      <td id=\"T_f446f_row16_col3\" class=\"data row16 col3\" >0.5709</td>\n",
       "      <td id=\"T_f446f_row16_col4\" class=\"data row16 col4\" >0.5678</td>\n",
       "      <td id=\"T_f446f_row16_col5\" class=\"data row16 col5\" >0.4209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_f446f_row17_col0\" class=\"data row17 col0\" >LightGBM</td>\n",
       "      <td id=\"T_f446f_row17_col1\" class=\"data row17 col1\" >annotator1_based_clarity</td>\n",
       "      <td id=\"T_f446f_row17_col2\" class=\"data row17 col2\" >0.4481</td>\n",
       "      <td id=\"T_f446f_row17_col3\" class=\"data row17 col3\" >0.6000</td>\n",
       "      <td id=\"T_f446f_row17_col4\" class=\"data row17 col4\" >0.5181</td>\n",
       "      <td id=\"T_f446f_row17_col5\" class=\"data row17 col5\" >0.4359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_f446f_row18_col0\" class=\"data row18 col0\" >LogisticRegression</td>\n",
       "      <td id=\"T_f446f_row18_col1\" class=\"data row18 col1\" >annotator2_based_clarity</td>\n",
       "      <td id=\"T_f446f_row18_col2\" class=\"data row18 col2\" >0.2437</td>\n",
       "      <td id=\"T_f446f_row18_col3\" class=\"data row18 col3\" >0.3636</td>\n",
       "      <td id=\"T_f446f_row18_col4\" class=\"data row18 col4\" >0.2868</td>\n",
       "      <td id=\"T_f446f_row18_col5\" class=\"data row18 col5\" >0.4364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_f446f_row19_col0\" class=\"data row19 col0\" >LinearSVC</td>\n",
       "      <td id=\"T_f446f_row19_col1\" class=\"data row19 col1\" >annotator2_based_clarity</td>\n",
       "      <td id=\"T_f446f_row19_col2\" class=\"data row19 col2\" >0.1168</td>\n",
       "      <td id=\"T_f446f_row19_col3\" class=\"data row19 col3\" >0.1455</td>\n",
       "      <td id=\"T_f446f_row19_col4\" class=\"data row19 col4\" >0.5587</td>\n",
       "      <td id=\"T_f446f_row19_col5\" class=\"data row19 col5\" >0.3680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_f446f_row20_col0\" class=\"data row20 col0\" >RandomForest</td>\n",
       "      <td id=\"T_f446f_row20_col1\" class=\"data row20 col1\" >annotator2_based_clarity</td>\n",
       "      <td id=\"T_f446f_row20_col2\" class=\"data row20 col2\" >0.3527</td>\n",
       "      <td id=\"T_f446f_row20_col3\" class=\"data row20 col3\" >0.3636</td>\n",
       "      <td id=\"T_f446f_row20_col4\" class=\"data row20 col4\" >0.5276</td>\n",
       "      <td id=\"T_f446f_row20_col5\" class=\"data row20 col5\" >0.4098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_f446f_row21_col0\" class=\"data row21 col0\" >MLP</td>\n",
       "      <td id=\"T_f446f_row21_col1\" class=\"data row21 col1\" >annotator2_based_clarity</td>\n",
       "      <td id=\"T_f446f_row21_col2\" class=\"data row21 col2\" >0.4792</td>\n",
       "      <td id=\"T_f446f_row21_col3\" class=\"data row21 col3\" >0.6109</td>\n",
       "      <td id=\"T_f446f_row21_col4\" class=\"data row21 col4\" >0.6796</td>\n",
       "      <td id=\"T_f446f_row21_col5\" class=\"data row21 col5\" >0.4584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_f446f_row22_col0\" class=\"data row22 col0\" >XGBoost</td>\n",
       "      <td id=\"T_f446f_row22_col1\" class=\"data row22 col1\" >annotator2_based_clarity</td>\n",
       "      <td id=\"T_f446f_row22_col2\" class=\"data row22 col2\" >0.4185</td>\n",
       "      <td id=\"T_f446f_row22_col3\" class=\"data row22 col3\" >0.6036</td>\n",
       "      <td id=\"T_f446f_row22_col4\" class=\"data row22 col4\" >0.5361</td>\n",
       "      <td id=\"T_f446f_row22_col5\" class=\"data row22 col5\" >0.3953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_f446f_row23_col0\" class=\"data row23 col0\" >LightGBM</td>\n",
       "      <td id=\"T_f446f_row23_col1\" class=\"data row23 col1\" >annotator2_based_clarity</td>\n",
       "      <td id=\"T_f446f_row23_col2\" class=\"data row23 col2\" >0.4403</td>\n",
       "      <td id=\"T_f446f_row23_col3\" class=\"data row23 col3\" >0.6473</td>\n",
       "      <td id=\"T_f446f_row23_col4\" class=\"data row23 col4\" >0.4933</td>\n",
       "      <td id=\"T_f446f_row23_col5\" class=\"data row23 col5\" >0.4246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_f446f_row24_col0\" class=\"data row24 col0\" >LogisticRegression</td>\n",
       "      <td id=\"T_f446f_row24_col1\" class=\"data row24 col1\" >annotator3_based_clarity</td>\n",
       "      <td id=\"T_f446f_row24_col2\" class=\"data row24 col2\" >0.2327</td>\n",
       "      <td id=\"T_f446f_row24_col3\" class=\"data row24 col3\" >0.3236</td>\n",
       "      <td id=\"T_f446f_row24_col4\" class=\"data row24 col4\" >0.2529</td>\n",
       "      <td id=\"T_f446f_row24_col5\" class=\"data row24 col5\" >0.4213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_f446f_row25_col0\" class=\"data row25 col0\" >LinearSVC</td>\n",
       "      <td id=\"T_f446f_row25_col1\" class=\"data row25 col1\" >annotator3_based_clarity</td>\n",
       "      <td id=\"T_f446f_row25_col2\" class=\"data row25 col2\" >0.1128</td>\n",
       "      <td id=\"T_f446f_row25_col3\" class=\"data row25 col3\" >0.1455</td>\n",
       "      <td id=\"T_f446f_row25_col4\" class=\"data row25 col4\" >0.2267</td>\n",
       "      <td id=\"T_f446f_row25_col5\" class=\"data row25 col5\" >0.3657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_f446f_row26_col0\" class=\"data row26 col0\" >RandomForest</td>\n",
       "      <td id=\"T_f446f_row26_col1\" class=\"data row26 col1\" >annotator3_based_clarity</td>\n",
       "      <td id=\"T_f446f_row26_col2\" class=\"data row26 col2\" >0.3901</td>\n",
       "      <td id=\"T_f446f_row26_col3\" class=\"data row26 col3\" >0.4182</td>\n",
       "      <td id=\"T_f446f_row26_col4\" class=\"data row26 col4\" >0.5428</td>\n",
       "      <td id=\"T_f446f_row26_col5\" class=\"data row26 col5\" >0.4202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_f446f_row27_col0\" class=\"data row27 col0\" >MLP</td>\n",
       "      <td id=\"T_f446f_row27_col1\" class=\"data row27 col1\" >annotator3_based_clarity</td>\n",
       "      <td id=\"T_f446f_row27_col2\" class=\"data row27 col2\" >0.4818</td>\n",
       "      <td id=\"T_f446f_row27_col3\" class=\"data row27 col3\" >0.5855</td>\n",
       "      <td id=\"T_f446f_row27_col4\" class=\"data row27 col4\" >0.6833</td>\n",
       "      <td id=\"T_f446f_row27_col5\" class=\"data row27 col5\" >0.4496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_f446f_row28_col0\" class=\"data row28 col0\" >XGBoost</td>\n",
       "      <td id=\"T_f446f_row28_col1\" class=\"data row28 col1\" >annotator3_based_clarity</td>\n",
       "      <td id=\"T_f446f_row28_col2\" class=\"data row28 col2\" >0.4191</td>\n",
       "      <td id=\"T_f446f_row28_col3\" class=\"data row28 col3\" >0.5636</td>\n",
       "      <td id=\"T_f446f_row28_col4\" class=\"data row28 col4\" >0.5412</td>\n",
       "      <td id=\"T_f446f_row28_col5\" class=\"data row28 col5\" >0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f446f_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_f446f_row29_col0\" class=\"data row29 col0\" >LightGBM</td>\n",
       "      <td id=\"T_f446f_row29_col1\" class=\"data row29 col1\" >annotator3_based_clarity</td>\n",
       "      <td id=\"T_f446f_row29_col2\" class=\"data row29 col2\" >0.4307</td>\n",
       "      <td id=\"T_f446f_row29_col3\" class=\"data row29 col3\" >0.6000</td>\n",
       "      <td id=\"T_f446f_row29_col4\" class=\"data row29 col4\" >0.4932</td>\n",
       "      <td id=\"T_f446f_row29_col5\" class=\"data row29 col5\" >0.4155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY TABLES COMPLETE\n",
      "================================================================================\n",
      "Tasks order: clarity, evasion_based_clarity, annotator1_based_clarity, annotator2_based_clarity, annotator3_based_clarity\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "shUrU_uakArH"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}